[
  
  {
    "title": "클라우드 서비스",
    "url": "/posts/%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EC%84%9C%EB%B9%84%EC%8A%A4%EC%9D%98-%ED%8A%B9%EC%A7%95/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-11-02 12:11:11 +0900",
    





    
    "snippet": "클라우드 컴퓨팅의 유형• 퍼블릭(Public ) 클라우드사용자는 컴퓨팅 리소스를 “소유 하지 않음” 인터넷을 통해 제공 가상화기술로만든서비스를그대로사용• 프라이빗(Private) 클라우드특정 조직내에서 컴퓨팅 리소스를 “소유” 사설(Private)네트워크를 통해 제공 • 가상컴퓨팅기술을직접구축            유형      설명           ...",
    "content": "클라우드 컴퓨팅의 유형• 퍼블릭(Public ) 클라우드사용자는 컴퓨팅 리소스를 “소유 하지 않음” 인터넷을 통해 제공 가상화기술로만든서비스를그대로사용• 프라이빗(Private) 클라우드특정 조직내에서 컴퓨팅 리소스를 “소유” 사설(Private)네트워크를 통해 제공 • 가상컴퓨팅기술을직접구축            유형      설명                  퍼블릭(Public) 클라우드      사용자는 컴퓨팅 리소스를 “소유 하지 않음” 인터넷을 통해 제공              프라이빗(Private) 클라우드      특정 조직내에서 컴퓨팅 리소스를 “소유” 프라이빗 네트워크를 통해 제공              하이브리드(Hybrid) 클라우드      퍼블릭 클라우드와 프라이빗 클라우드 또는 데이터센터 간 네트워크를 연결 데이터 및 애플리케이션을 공유              멀티(Multi) 클라우드      다수의 퍼블릭 클라우드를 사용 e.g. AWS + GCP + Azure      클라우드 서비스 제공업체 (CSP, Cloud Service Provider)            국내      해외                  naver      aws              hnh cloud      azure              kt cloud      ibm cloud              gabia      oracle              kakao      alibaba                     tencent      탄력성/민첩성 리소스에 대해 필요할 때 언제든 늘리고, 줄일 수 있음확장성 물리 서버를 확장하려면 시간이 오래 걸리는 반면, 클라우드는 즉시 확장이 가능사용한 만큼 지불 전기 요금처럼 사용 한 만큼 과금 되며, 비용 예측이 가능고 가용성 유지 관리 간소화내결함성 및 재해복구 클라우드 백업 및 클라우드 DR 구성으로 데이터 손상 등 긴급 상황에 대처 가능고가용성 손쉬운 다중 가용영역 설정에 따라 고 가용성을 보장유지 관리 간소화 물리적인 리소스를 유지할 필요가 없고, 부분적으로 클라우드 CSP벤더에 위임클라우드 서비스 모델 (IaaS/PaaS/SaaS)기존 인프라와의 차이점            항목      On-Premise      Cloud                  인프라 운영/보안      사용자가 모두 운영하고 관리      공동 책임 모델이 적용              구축 및 배포      자원 구축/배포 시간이 길다      단 시간에 인프라 구성이 가능              탄력성/확장성      서버증설시예산및시간이소요      몇번의 클릭으로 서버 증설 가능              비용지출 방식      자본 지출 : Capital Expense(CAPEX)      운영 지출 : Operation Expense(OPEX)              네트워크 트래픽      인터넷 공급자(ISP) 회선 계약 따라 회선속도 및 트래픽 용량을 사전에 설정      회선속도나용량을정할수없음 트래픽을 사용한만큼 지출 (outbound)              오픈소스      모든 오픈소스 Application을 스스로 구축      Pre-built 된 오픈소스 Application을 즉시 사용      "
  },
  
  {
    "title": "multer를 사용해 이미지 업로드하기",
    "url": "/posts/multer/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-11-01 12:00:00 +0900",
    





    
    "snippet": "multer를 사용해 이미지 업로드하기사용자가 보낸 파일데이터를 노드 익스프레스 서버에서 처리해서 특정한 폴더에 업로드하고 사용하에게 보여주기위해서Multer는 파일 업로드를 위해 사용되는 multipart/form-data 를 다루기 위한 node.js 의 미들웨어 입니다. 효율성을 최대화 하기 위해 busboy 를 기반으로 하고 있습니다.주: Mu...",
    "content": "multer를 사용해 이미지 업로드하기사용자가 보낸 파일데이터를 노드 익스프레스 서버에서 처리해서 특정한 폴더에 업로드하고 사용하에게 보여주기위해서Multer는 파일 업로드를 위해 사용되는 multipart/form-data 를 다루기 위한 node.js 의 미들웨어 입니다. 효율성을 최대화 하기 위해 busboy 를 기반으로 하고 있습니다.주: Multer는 multipart (multipart/form-data)가 아닌 폼에서는 동작하지 않습니다.multer 객체를 만들어주고업로드를 설정해준다업로드폴더를 사용자가 실제로 접근해야하기 위해 스태틱을 해준다aws s3에"
  },
  
  {
    "title": "ER_NOT_SUPPORTED_AUTH_MODE",
    "url": "/posts/mysql-error/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-20 13:12:12 +0900",
    





    
    "snippet": "ER_NOT_SUPPORTED_AUTH_MODE‘Client does not support authentication protocol requested by server; consider upgrading MySQL client’,mysql의 default_authentication_plugin은 mysql_native_password였다하지만 mys...",
    "content": "ER_NOT_SUPPORTED_AUTH_MODE‘Client does not support authentication protocol requested by server; consider upgrading MySQL client’,mysql의 default_authentication_plugin은 mysql_native_password였다하지만 mysql 8 부터 보안이 강화된 caching_sha2_password로 변경되면서mysql 모듈이cha2 방식을 지원하지 못해 node.js에서 db 연동이 안되었다.###      caching_sha2_password 방식을 지원하는 mysql2 모듈을 사용한다        default_authentication_plugin(기본 인증 플러그인)을 mysql_native_password으로 다운그레이드 한다.  플러그인을 바꿔 준다"
  },
  
  {
    "title": "Cidr",
    "url": "/posts/cidr/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-19 01:34:00 +0900",
    





    
    "snippet": "#아이피 주소에서 사용할 수 없는 주소가 두가지가 존재한다",
    "content": "#아이피 주소에서 사용할 수 없는 주소가 두가지가 존재한다"
  },
  
  {
    "title": "TypeError Cannot read properties of null (reading 'addEventListener')",
    "url": "/posts/2023-10-17/",
    "categories": "",
    "tags": "",
    "date": "2023-10-17 21:55:00 +0900",
    





    
    "snippet": "TypeError: Cannot read properties of null (reading ‘addEventListener’)에러 원인  script를 body의 상단에 작성하게 되면, 간혹 html이 로드 되기 전에 script를 먼저 불러와버리는 경우가 생긴다.  addEventListener을 부여할 DOM을 찾지 못하게 되어 에러가 발생해결 방...",
    "content": "TypeError: Cannot read properties of null (reading ‘addEventListener’)에러 원인  script를 body의 상단에 작성하게 되면, 간혹 html이 로드 되기 전에 script를 먼저 불러와버리는 경우가 생긴다.  addEventListener을 부여할 DOM을 찾지 못하게 되어 에러가 발생해결 방법1. script는 body태그의 가장 아래에 작성2. window.onload = function(){} 을 사용한다.window.onload = function(){} 함수는 웹브라우저의 모든 구성요소에 대한 로드가 끝났을 때 브라우저에 의해서 호출되는 함수로,해당 부분에 넣으면 HTML을 모두 로드한 뒤에 함수를 호출한다.head태그 내부에 script 영역을 참조하는 부분이 있지만, window.onload 함수 내부에 문제가 되는 함수를 넣어줌으로써 해결할 수 있다.window.onload = function () {  var hw = document.getElementById(\"hw\");  hw.addEventListener(\"click\", function () {    alert(\"Hello world\");  });};3. deferScript 태그DOM이 생성될 때, Script 태그를 만나면 DOM 생성을 멈추고 Script를 실행한다.src 속성을 포함한 외부 스크립트를 만났을 때에도 마찬가지이다.해당 스크립트를 다운 받고 실행할 때 까지 Script 태그 아래에 선언된 DOM 요소들은 대기해야 한다.  여기서 DOM 생성을 중단하지 않고, 스크립트를 동시에 내려받게 할 수 있는 방법으로defer, async가 있다.출처https://velog.io/@ahn-sujin/Uncaught-TypeError-Cannot-read-property-addEventListener-of-nullhttps://gobae.tistory.com/110#DOM%–%EC%–%-D%EC%–%B-%–%EC%A-%–%EB%-B%A-%EC%-D%B-%–%EC%-D%BC%EC%–%B-%EB%–%-C%EB%-B%A-%EB%A-%B-%–%EC%–%B-%EB%–%A-%–%EB%AC%B-%EC%A-%-C%EA%B-%–%–%EB%B-%-C%EC%–%-D%ED%–%–%EB%-A%–%EA%B-%—"
  },
  
  {
    "title": "Are HTTP headers case-sensitive?",
    "url": "/posts/api-%ED%85%8C%EC%8A%A4%ED%8A%B8/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-16 21:55:00 +0900",
    





    
    "snippet": "프론트엔드없이 api 테스트Postman을 다운로드하지 않아서 MacBook의 기본 curl 명령을 사용하여 API를 테스트메소드, 헤더 , 바디 넣어서 POST 요청1. Content-Type application/x-www-form-urlencoded  테스트하기위해-X (–request &lt;GET,POST,PUT,PATH,DELETE&gt; ...",
    "content": "프론트엔드없이 api 테스트Postman을 다운로드하지 않아서 MacBook의 기본 curl 명령을 사용하여 API를 테스트메소드, 헤더 , 바디 넣어서 POST 요청1. Content-Type application/x-www-form-urlencoded  테스트하기위해-X (–request &lt;GET,POST,PUT,PATH,DELETE&gt; 요청시 사용할 메소드)-d (–data  )  -H (--header &lt;POST의 기본 Content-Type 은 application/x-www-form-urlencoded 이다  출처: https://inpa.tistory.com/entry/LINUX-📚-CURL-명령어-사용법-다양한-예제로-정리#curl_http_메서드 [Inpa Dev 👨‍💻:티스토리]&gt;)POST의 기본 타입 넣었더니 db에 Null이 찍힘2. body에 넣을 데이터가 text/html 인줄알았는데 null이 찍힘curl -I localhost:3000/registerHTTP/1.1 200 OKX-Powered-By: ExpressContent-Type: text/html; charset=utf-8Content-Length: 1542ETag: W/\"606-Q85bpMcLB39mgcBvBduYykU274I\"Date: Wed, 24 Jan 2024 16:00:23 GMTConnection: keep-aliveKeep-Alive: timeout=53. “Content-Type: application/json”fetch 를 사용할때 서버로부터 json 데이터를 받기 위해서 res.json()을 사용출처: https://haeguri.github.io/2018/12/30/compare-response-json-send-func/바디에 “Content-Type: application/json” 헤더를 넣었더니 값이 제대로 저장되었다.헤더는 대소문자를 구별하는가?curl localhost:3000/register -X POST -d '{\"id\":\"test\",\"pw\":\"1234\",\"name\":\"test\"}' -H 'content-type: application/json'{\"success\":true}%curl localhost:3000/register -X post -d '{\"id\":\"123\",\"pw\":\"123\",\"name\":\"123\"}' -H 'content-type: text/html'  post 소문자로 실패curl localhost:3000/register -d '{\"id\":\"123\",\"pw\":\"123\",\"name\":\"123\"}' -H 'content-type: text/html'{\"success\":true}%//데이터를 보내면 알아서 메소드 인식해줌HTTP 프로토콜은 헤더 이름의 대소문자를 구별하지 않습니다. 따라서 “content-type”과 “Content-Type”은 동일하게 처리됩니다. 이는 HTTP/1.1 스펙에 명시되어 있습니다.클라이언트가 서버로 HTTP 요청을 보낼 때, 헤더의 이름을 지정할 때에도 대소문자를 마음대로 사용할 수 있습니다. 서버는 이를 구분하지 않고 처리할 것이라 기대할 수 있습니다.요약하자면, HTTP 표준에 따르면 헤더의 대소문자는 구별되지 않지만, 실제로는 구현체에 따라 다를 수 있으므로 주의가 필요합니다."
  },
  
  {
    "title": "AWS 자격증",
    "url": "/posts/awssaa/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-15 21:55:00 +0900",
    





    
    "snippet": "한 조직에서 다양한 프로세스를 조율하기 위해 마이크로서비스 아키텍처를 사용하는 온라인 저축 계좌 애플리케이션을 구현했습니다. 오케스트레이션 프로세스 중 하나는 저축 계좌 생성을 위한 다양한 API 호출을 오케스트레이션하는 “계정 생성”입니다. 성능상의 이유로 API 오케스트레이션은 동기 및 비동기 호출이 혼합되어 있습니다. 특정 비동기 호출이 실패할 ...",
    "content": "한 조직에서 다양한 프로세스를 조율하기 위해 마이크로서비스 아키텍처를 사용하는 온라인 저축 계좌 애플리케이션을 구현했습니다. 오케스트레이션 프로세스 중 하나는 저축 계좌 생성을 위한 다양한 API 호출을 오케스트레이션하는 “계정 생성”입니다. 성능상의 이유로 API 오케스트레이션은 동기 및 비동기 호출이 혼합되어 있습니다. 특정 비동기 호출이 실패할 때 시스템을 일관성 없는 상태로 남겨두는 것이 관찰되었습니다. 예를 들어 예금 계좌는 생성되었지만 고객 정보는 생성되지 않았을 수 있습니다. 아키텍트로서 시스템의 최고의 내구성을 보장하기 위해 무엇을 하시겠습니까?saa귀하는 중요한 애플리케이션을 aws에 배포할 책임이 있습니다. 악의적인 활동을 식별하기 위해 웹 애플리케이션로그를 모니터링 해야 합니다cloudwatchvpc의 프라이빗 서브넷에서 호스팅되는 인스턴스가 있습니다. 인터넷에서 업데이트를 다운로드하려면 인스턴스가 필요합니다. 설계자로서 가장 효율적이고 안전한 it운영 팀에 어떤 변화를 제안하시겠습니까?A. 새 퍼블릭 서브넷을 만들고 인스턴스를 해당 서브넷으로 이동합니다B. 새 ec2 인스턴스를 생성하여 업데이트를 별도로 다운로드한 다음 필요한 인스턴스로 푸시합니다.C. NAT 게이트웨이를 사용하여 프라이빗 서브넷의 인스턴스가 업데이트를 다운로드하도록 허용합니다.D. 프라이빗 서브넷의 인스턴스가 업데이트를 다운로드 할 수 있도록 인터넷에 대한 vpc 링크를 생성합니다.당신은 모바일 앱과 웹사이트를 통해 판매할 스톡 이미지와 비디오를 제작하는 미디어 회사에서 일하는 솔루션 설계자입니다. 앱과 웹사이트에서 사용자는 자신이 구매한 스톡 콘텐츠에만 액세스 할 수 있습니다. 콘텐츠는 s3 버킷에 저장됩니다. 사용자가 구매한 여러 파일에 대한 액세스를 제한해야 합니다 또한 스톡 콘텐츠(여러사용자가 구매가능)의 특성으로 인해 각 스톡 항목의 url을 변경하고 싶지 않습니다 귀하의 시나리오에 가장 적합한 액세스 제어 옵션은 무엇입니까?SAA associatedit 회사는 최근 웹서버가 sqs대기열의 메시지를 통해 애플리케이션 서버와 통신할 수 있도록SAA웹사이트는 elastic load balancer 뒤에 있는 두개의 ec2 인스턴스에서 호스팅 됩니다 웹사이트의 응답 시간이 크게 느려지고 대기 시간으로 인해 고객의 주문이 줄어 듭니다 문제 해결을 통해 ec2 인스턴스 중 하나에 장애가 발생했으며 현재 하나의 인스턴스만 실행되고 있는 것으로 나타났습니다애플리케이션은 다음 vpc 아키텍처로 구성됩니다elb뒤의 여러 az에 있는 ec2 인스턴스ec2 인스턴스는 auto scaling 그룹을 통해 시작됩니다인터넷에서 업데이트를 다운로드 하기 위해 모든 az의 인스턴스에 대해 하나의 nat 게이트웨이가 있습니다.가용성에 기반한 아키텍처의 병목 현상은 무엇입니까?대기열 및 메시징 개념saa미디어 회사는 aws에서 관계형 데이터 베이스를 호스팅할 계획입닏다 그들은 수동 개입 없이 가변적이고 예측할수없는 워크로드를 처리할수 있고 애플리케이션의 사용자 트래픽에 따라 컴퓨팅 용량을 확장 및 축소할수있는 rds 제품군의 데이터 베이스를 원합니다a. amazon aurorab. amazonc. amazon aurora serverlesssaa1gb-3gb 범위의 대용량 파일을 aws s3 버킷에 업로드하고있습니다 사용자가 다운로드 중에 잠재적 손상을 식별하기 위해 체크섬의 유효성을 검사할 수 있도록 조직에는 전체 파일을 읽어 파일의 해시 체크섬을 계산해야 하는 요구사항이 있습니다 이를 위해 lambda함수를 생성하고 s3알림을 통해 트리거되도록 했습니다 그러나 요청 시가니SAA1GB – 3GB 범위의 대용량 파일을 AWS S3 버킷에 업로드하고 있습니다. 사용자가 다운로드 중에 잠재적 손상을 식별하기 위해 체크섬의 유효성을 검사할 수 있도록 조직에는 전체 파일을 읽어 파일의 해시 체크섬을 계산해야 하는 요구 사항이 있습니다. 이를 위해 Lambda 함수를 생성하고 S3 알림을 통해 트리거되도록 했습니다. 그러나 요청 시간이 초과되었습니다. 그 이유는 무엇입니까?A. Lambda 함수는 128MB의 최소 메모리로 구성됩니다.B. Lambda 함수는 NAT 게이트웨이 또는 VPC 엔드포인트 없이 프라이빗 VPC에서 실행되도록 설정됩니다.C. 환경 변수에 S3 버킷 이름을 설정하지 않았습니다.D. Lambda 함수는 S3 버킷과 다른 리전에서 생성됩니다.Cassandra를 실행하려면 여러 EC2 인스턴스를 시작해야 합니다. Cassandra에는 대규모 분산 및 복제 워크로드가 있으며 EC2 배치 그룹을 사용하여 인스턴스를 시작할 계획입니다. 트래픽은 여러 파티션에 고르게 분산되어야 하며 각 파티션에는 여러 인스턴스가 포함되어야 합니다. 요구 사항을 달성하기 위해 다음 배치 그룹 중 어느 것을 사용하시겠습니까?A. 클러스터 배치 그룹B. 스프레드 배치 그룹C. 파티션 배치 그룹D. 네트워크 배치 그룹aws 컴퓨팅 서비스와 적합한 용례ENAEFAENIEN의 차이를 공부스토리지 서비스와 적합한 용례EFS"
  },
  
  {
    "title": "Ec2 보안 평가 6",
    "url": "/posts/ec2-%EB%B3%B4%EC%95%88-%ED%8F%89%EA%B0%80-6/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-14 21:55:00 +0900",
    





    
    "snippet": "amazon inspectoraws 컴퓨팅 자원의 네트워크 액세스 가능성 및 해당 인스턴스에서 실행되는 애플리케이션의 보안 상태를 테스트하여 보안과 규정 준수 수준을 향상시키는 자동화된 보안 수준 점검 기능을 제공amazon ec2ecr repo &amp; container imagelambda",
    "content": "amazon inspectoraws 컴퓨팅 자원의 네트워크 액세스 가능성 및 해당 인스턴스에서 실행되는 애플리케이션의 보안 상태를 테스트하여 보안과 규정 준수 수준을 향상시키는 자동화된 보안 수준 점검 기능을 제공amazon ec2ecr repo &amp; container imagelambda"
  },
  
  {
    "title": "Ddos 방어",
    "url": "/posts/ddos-%EB%B0%A9%EC%96%B4/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-13 21:55:00 +0900",
    





    
    "snippet": "DDoS (분산 서비스 거부 공격)● 악성 코드에 감염된 컴퓨터, 라우터, IoT 장치 및 기타 엔드 포인트의 분산된 그룹으로 이루어진 여러 소스를 사용하여 대상을 압도하는 패킷 또는 요청을 생성하는 공격tcp 3way handshake",
    "content": "DDoS (분산 서비스 거부 공격)● 악성 코드에 감염된 컴퓨터, 라우터, IoT 장치 및 기타 엔드 포인트의 분산된 그룹으로 이루어진 여러 소스를 사용하여 대상을 압도하는 패킷 또는 요청을 생성하는 공격tcp 3way handshake"
  },
  
  {
    "title": "Aws 네트워크 보안3",
    "url": "/posts/aws-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%883/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-12 21:55:00 +0900",
    





    
    "snippet": "어플리케이션의 위협 보호owasp의도하지않은악성SQL문자를삽입해웹사이트를 통해 데이터베이스를 비정상적으로 조작하거나 정보를 출력하는 해킹 기법예) 나는 ‘모든 회원’이야. 내 정보를 줘예) 나는 ‘모든 회원’이야. 내 정보를 다 지워 줘Sample code:https://www.owasp.org/index.php/Testing_for_SQL_Injec...",
    "content": "어플리케이션의 위협 보호owasp의도하지않은악성SQL문자를삽입해웹사이트를 통해 데이터베이스를 비정상적으로 조작하거나 정보를 출력하는 해킹 기법예) 나는 ‘모든 회원’이야. 내 정보를 줘예) 나는 ‘모든 회원’이야. 내 정보를 다 지워 줘Sample code:https://www.owasp.org/index.php/Testing_for_SQL_Injection_( OTG-INPVAL-005) 3. 어플리케이션 위협보호● SQLinjection방지  동적 SQL 사용을 가급적 제한  입력 값에 적절한 검증 절차를 적용하고 위험한 값은 위험하지 않은 값으로 치환, 입력 값이 허용 범위내에있는지사전조치  데이터베이스의 여러 리턴 및 에러 메시지 외부 노출 금지  웹 보안 취약점을 주기적으로 점검 및 Secure Coding 지향  웹 방화벽 사용웹 공격 : Cross Site Scripting공격자에 의해 작성된 스크립트가 다른 사용자에게 전달되고 해당 스크립트로 페이지가 깨지거나 쿠키 및 개인 정보를 특정 사이트로 탈취하는 공격  공격자가 취약한 웹사이트에 악의적인 스크립트를 주입  희생자 (일반 사용자)가 웹사이트에서 악의적인 스크립트를 트리거  희생자의 브라우저에서 악의적인 스크립트가 실행되어 희생자가모르는 사이 주요 데이터들이 공격자에게 전송  어플리케이션 위협보호● Cross Site Scripting 방지1) 내용 입력란에 HTML 태그와 자바 스크립트를 금지2) 문제성이 있는 입력 데이터를 오류 메시지와 함께 출력하지 않도록 Encoding, Escape 활용3) 웹 보안 취약점을 주기적으로 점검 및 Secure Coding 지향4) 웹 방화벽 사용aws waf규칙 생성방법      amazon manged rule자체 규칙을 작성하지 않고 일반적인 애플리케이션 취약성 또는 기타 원치 않는 트래픽에 대한 보호를 제공하는 aws 관리형 서비스wcu 1500안에서aws threat research team trt에서 관리하고 유지하는 규칙 세트amazon        custom rule        aws marketplace  waf full 로깅"
  },
  
  {
    "title": "Aws 네트워크보안2",
    "url": "/posts/aws-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EB%B3%B4%EC%95%882/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-11 21:55:00 +0900",
    





    
    "snippet": "2 네트워크 격리 및 접근제어vpc를 보안관점으로 뜯어보면네트워크 보호의 시작 vpc (virtual private cloud)private networkaws 특정 iam user랑보안그룹 (security group)인스턴스 단위상태 저장(stateful)동적 구성최소 권한 원칙네트워크 접근 제어 리스트 (NACL) network access co...",
    "content": "2 네트워크 격리 및 접근제어vpc를 보안관점으로 뜯어보면네트워크 보호의 시작 vpc (virtual private cloud)private networkaws 특정 iam user랑보안그룹 (security group)인스턴스 단위상태 저장(stateful)동적 구성최소 권한 원칙네트워크 접근 제어 리스트 (NACL) network access control list서브넷 단위상태 비저장(stateless)최소 권한 원칙보안그룹을 보안디도스 공격이 들어올때 서브넷단위로 막아준다vpc 보안계층 security group &amp; NACLvpc 엔드포인트gateway endpointss3, dynamoDBmanaged prefix라우팅 최적화internet endpointskinesis datastream, glue 외private ENIendpoint service(aws privateLink)장점 보안, 비용, NACL를 태우는것보다 저렴 트래픽 처리 비용 비쌈vpc prefix list트래픽 모니터링 -vpc flow lognetwork reachability analyzer(network manager)  한 vpc 내의 두 엔드포인트 또는 여러 vpc 내의 엔드포인트 간에 연결 가능성 문제를 해결하는 네트워크 진단 도구  소스와 대상 사이의 가상 네트워크 경로에 대한 홉별 세부 정보를 생성  대상에 연결할 수 없는 경우 차단 구성 요소를 식별"
  },
  
  {
    "title": "Aws 네트워크 보안1",
    "url": "/posts/aws-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B4%EC%95%881/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-10 21:55:00 +0900",
    





    
    "snippet": "인프라보안에 중심에있는 네트워크 보안온프로미스처럼 격리된 공간을 만들수있기 때문에정통적인 데이터 센터들과기존의 네트워크 보안에 대해 잘아는분들은아주 간단한 네트워크 아키텍처디폴트 vpc안에 어플리케이션 구성 alb 정적컨텐츠 s3에 구성악의적인 행위자는 언제나 약한 부분을 공략다양한 네트워크 공격osi 7 레이어는 네트워크의 기본네트워크 프로토콜 통신...",
    "content": "인프라보안에 중심에있는 네트워크 보안온프로미스처럼 격리된 공간을 만들수있기 때문에정통적인 데이터 센터들과기존의 네트워크 보안에 대해 잘아는분들은아주 간단한 네트워크 아키텍처디폴트 vpc안에 어플리케이션 구성 alb 정적컨텐츠 s3에 구성악의적인 행위자는 언제나 약한 부분을 공략다양한 네트워크 공격osi 7 레이어는 네트워크의 기본네트워크 프로토콜 통신하는 구조를 7계층으로 분리해놓은ip 통신 3층tcp udp 4층http 7층공격은 물리적인네트워크 보호를 위한 레이어objective: 확장성이 뛰어나고 안전하며 편하게 모니터링 할 수 있는 ddos 보호 애플리케이션을 구축네트워크 격리 vpc네트워크 접근 제어 security group &amp; NACL네트워크 방화벽 aws network firewall service어플리케이션 위협 보호 aws wafddos 방어 aws shield"
  },
  
  {
    "title": "Iam 실습 2",
    "url": "/posts/iam-%EC%8B%A4%EC%8A%B5-2/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-09 21:55:00 +0900",
    





    
    "snippet": "aws sso 구성aws single sign on  1번 계정에서 aws organization 구성  1번 계정의 organization에서 2번 계정 초대  1번 계정에서 aws sso 구성ㄱ. 사용자/ 그룹/ 권한 세트 생성ㄴ. 계정에 사용자 및 권한 추가  2번 계정에서 sso 로그인 테스트  cli에서 sso로 로그인 테스트자격 증명 소스 ...",
    "content": "aws sso 구성aws single sign on  1번 계정에서 aws organization 구성  1번 계정의 organization에서 2번 계정 초대  1번 계정에서 aws sso 구성ㄱ. 사용자/ 그룹/ 권한 세트 생성ㄴ. 계정에 사용자 및 권한 추가  2번 계정에서 sso 로그인 테스트  cli에서 sso로 로그인 테스트자격 증명 소스 선택자격 증명 센터 디렉토리, active directory, 외부 자격 증명 공급자iam 유저를 생성하지 않고도 사람 사용자가 접근을 할 수 있었음sso의 장점은 로컬에서 iam user 크레덴션을 설정하지않아도 바로 롤을 assume 할 수 있다.엑세스키 로컬에 심어주지 않아서 보안적으로 더욱 좋다..다양한 써드파티 추가해서 업그레이드 할 수 있다.자원삭제aws ssoorganization 멤버 삭제iam user / iam role 삭세iam identity center설정 관리 IAM 자격 증명 센터 구성 삭제"
  },
  
  {
    "title": "Iam 실습 1",
    "url": "/posts/iam-%EC%8B%A4%EC%8A%B5-1/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-08 21:55:00 +0900",
    





    
    "snippet": "aws iam 실습cross account role 실행aws sso 구성cross account role 실행 시나리오iam user의 권한을 가지고 role assumeaws account 준비1번 어카운트에서 iam user 생성iam user에 정책 연결2번 어카운트에서 iam user가 assume할 iam role 생성콘솔에서 role sw...",
    "content": "aws iam 실습cross account role 실행aws sso 구성cross account role 실행 시나리오iam user의 권한을 가지고 role assumeaws account 준비1번 어카운트에서 iam user 생성iam user에 정책 연결2번 어카운트에서 iam user가 assume할 iam role 생성콘솔에서 role switch 테스트aws cli 에서 role switch 테스트cross account role 실행 시나리오 절차aws cli 에서 role switch 테스트aws cli 구성: https://docs.aws.amazon.com/ko_kr/cli/latest/userguide/getting-started-install.htmlaws 권한 세팅aws configureaws configure listaws sts get-caller-identityaws sts assume-role –role-arn “arn:aws:iam::&lt; 2번째 어카운트 id &gt;:role/cross-accounter-role” –role-session-name &lt;iamtest(아무거나)&gt;aws sts get-caller-identityaws s3 lsaws s3 rb s3://mybucket1234"
  },
  
  {
    "title": "AWS 접근제어#6 IAM 관리",
    "url": "/posts/aws-%EC%A0%91%EA%B7%BC%EC%A0%9C%EC%96%B46/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-07 21:55:00 +0900",
    





    
    "snippet": "IAM 관리IAM policy 작성 툴iam visual editor &amp; policy generator:iam policy simulatorhttps://policydIAM 샘플 정책 활용aws지정 날짜 범위 동안의 액세스 허용지정 날짜 범위 동안 mfa를 사용하는 경우 특정 액세스를 허용소스 ip주소를 바탕으로 aws에 대한 액세스 거부정책예...",
    "content": "IAM 관리IAM policy 작성 툴iam visual editor &amp; policy generator:iam policy simulatorhttps://policydIAM 샘플 정책 활용aws지정 날짜 범위 동안의 액세스 허용지정 날짜 범위 동안 mfa를 사용하는 경우 특정 액세스를 허용소스 ip주소를 바탕으로 aws에 대한 액세스 거부정책예제: aws codecommit프로그램 방식으로 콘솔에서 aws codecommit 리포지토리에 대한 read 액세스 허용정책예제 aws data pipeline사용자가 생성하지 않은 파이프라인에 대한 액세스 거부정책예제: amazon dynamodb특정 amazon dynamodb 테이블에 대한 액세스 허용iam access advisoriam에 대해 서비스에서 마지막으로 액세스한 데이터를 조회불필요한 권한을 제거하고 least privileged를 유지할 수 있음access advisors3,ec2,iam,lambda management action 에 대해서는 action단위로 조회가능fine-grained s3 버킷 정책을 위해 활용data action cloudtrail에서 명시적으로 체크해야됨iam credential report계정의 모든 사용자와 암호, 액세스 키 ,mfa 디바이스 등 자격 증명 상태에 대한 보고서감사 및 규정 준수에 활용할수있다다운을 정기적으로하거나 자동화 (mfa 활성화 여부)iam access analyzer리소스에 대한 public 혹은 cross-account 접근을 검사하여 과도하게 권한이 주어진 자원을 판별해주는 기능analyzer 결과로 내 계정 내, 외부에서 액세스 가능한 리소스 리스트를 보여주고, next step을 제안리전별로 따로 만들어야된다iam role, s3, lambda, kms key, sqs qeue상시 모니터링/탐색으로 정책이 변경되는 순간 탐지 security hub로 전달iam access analyzer 확장console에서 bucket access 프리뷰, validate, public &amp; cross account access, policy validation, policy generation클라욷드트레일로그를 기반으로 실제로 접근했던 api목록을 뽑아준다 정책을 만들어준다iam 정책 생성 자동화iam 사용자 -&gt; 임의의 iam policy 생성 후 업로드 -&gt; AWS CODEPIPEline오픈소스를 활용한 iam 권한 관리policy_sentry: iam least privilege policy generator 도구parliament: iam linting library로, 작성한 정책 리뷰 (예: 잘못된 json, 필수 요소 누락 등)netflix aardvark/repokid:access advisor 기반으로 정보를 조회하고 불필요한 권한을 제거iamctl: 두개의 계정에서 iam 역할 및 정책을 추출하고 비교하고 차이점과 통계를보고cloudsplaininng컴플라이언스 체크: aws config rulesconfig: aws 리소스의 변경사항을 추적하고 감사하는 서비스config rules: 해당 변경 사항이 기준 정책에 위반될 때, 대응 규칙 실행(경보, 차단 등 aws lambda 활용)보안 위협 탐지: amazon GuardDutyAPI 활동 기록 및 감사: AWS CloudTrailaws api 요청의 처리내역을 로깅하는 서비스"
  },
  
  {
    "title": "AWS 접근제어#5 운영자를 위한 AWS STS",
    "url": "/posts/aws-%EC%A0%91%EA%B7%BC%EC%A0%9C%EC%96%B45/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-06 21:55:00 +0900",
    





    
    "snippet": "로컬 aws 자격증명cli credential 구성 방법./aws/credentials|해야 할 일|해서는 안 될 일||—|—||자격 증명 파일 사용| 루트계정 자격증명사용||aws security token service(aws sts)의 임시 자격 증명 사용|코드에 aws 자격증명삽입||iam 역할 사용(선호)|git repository, wiki...",
    "content": "로컬 aws 자격증명cli credential 구성 방법./aws/credentials|해야 할 일|해서는 안 될 일||—|—||자격 증명 파일 사용| 루트계정 자격증명사용||aws security token service(aws sts)의 임시 자격 증명 사용|코드에 aws 자격증명삽입||iam 역할 사용(선호)|git repository, wiki와 같이 공개된 위치에 자격증명저장|"
  },
  
  {
    "title": "AWS 접근제어#4 AWS STS",
    "url": "/posts/aws-%EC%A0%91%EA%B7%BC%EC%A0%9C%EC%96%B44/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-05 21:55:00 +0900",
    





    
    "snippet": "AWS STS(Simple Token Service)AWS 리소스에 대한 액세스를 제어할 수 있는 임시 보안 자격증명을 생성하여 보안 주체에 전달해주는 서비스보안주체(사용자 혹은 역할)는 sts를 호출할 수 있는 명시적인 권한이 있어야함.STS API요청에 대한 응답에는 temp credential이 포함되어 있음access keysecret keys...",
    "content": "AWS STS(Simple Token Service)AWS 리소스에 대한 액세스를 제어할 수 있는 임시 보안 자격증명을 생성하여 보안 주체에 전달해주는 서비스보안주체(사용자 혹은 역할)는 sts를 호출할 수 있는 명시적인 권한이 있어야함.STS API요청에 대한 응답에는 temp credential이 포함되어 있음access keysecret keysession token: temp credential을 사용하기 위해 api 요청에 제출해야하는 토큰.세션토큰을 사용해 임시 보안 자격 증명의 유효성을 검증15초~최대 12시간까지 지속가능https://sts.amazonaws.com 라는 글로벌 단일 엔드포인트를 default로 사용리전별 aws sts엔드포인트를 사용하여 지연 시간을 줄이고, 중복으로 구축하고, 세션 토큰 유효성을 높일수있음쿼리 api sdk cli를 통해 sts 호출 가능aws sts api            AWS STS API      호출할 수 있는 사용자      사용사례                  AssumeRoleWithSAML      IAM 사용자 기존 임시보안 자격 증명이 있는 IAM역할      기존 IAM 사용자가 아직 액세스 권한이 없는 AWS 리소스에 접근              AssumeRoleWithSAML      유효한 ID provider에서 받은 인증이 포함된 SAML 응답을 전달할 수 있는 (외부) 사용자      SAML 2.0과 호환되는 엔터프라이즈 자격 증명 공급자 (window AD, OpenLDAP)을 통한 연동      aws sts assume role request 예시"
  },
  
  {
    "title": "Aws 접근제어3",
    "url": "/posts/aws-%EC%A0%91%EA%B7%BC%EC%A0%9C%EC%96%B43/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-04 21:55:00 +0900",
    





    
    "snippet": "",
    "content": ""
  },
  
  {
    "title": "AWS 접근제어#3 IAM Policy",
    "url": "/posts/aws-%EC%A0%91%EA%B7%BC%EC%A0%9C%EC%96%B42/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-03 12:11:11 +0900",
    





    
    "snippet": "AWS IAM policy의 JSON 구조{    \"version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow(허용) 또는 Deny(차단)\",            \"Action\": [                ... 어떤 행위를?            ],        ...",
    "content": "AWS IAM policy의 JSON 구조{    \"version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow(허용) 또는 Deny(차단)\",            \"Action\": [                ... 어떤 행위를?            ],            \"Resource\": [                ... 어떤 객체(리소스)들에 대해?            ],            \"Condtion\": {                ... 어떤 조건에서?(optional)            }        }    ]}예제: DynamoDB로 부터 데이터 읽기{    \"version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow(허용) 또는 Deny(차단)\",            \"Action\": [                ... 어떤 행위를? \"dynamodb:*\"            ],            \"Resource\": [                ... 어떤 객체(리소스)들에 대해? \"*\"            ],            \"Condtion\": {                ... 어떤 조건에서?(optional)            }        }    ]}{    \"version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow(허용) 또는 Deny(차단)\",            \"Action\": [                \"dynamodb:GetItem\",                \"dynamodb:PutItem\"            ],            \"Resource\": [                \"*\"            ],            \"Condtion\": {                ... 어떤 조건에서?(optional)            }        }    ]}{    \"version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow\",            \"Action\": [                \"dynamodb:GetItem\",                \"dynamodb:PutItem\"            ],            \"Resource\": [                \"arn:aws:dynamodb:ap-northeast-2:&lt;accountidd&gt;:table/example\"            ],        }    ]}리소스와 ARN(Amazon Resuouce Name)리소스: aws 상의 관리 대상 자원들 예들 들어 s3버킷, dynamoDB테이블,EC2인스턴스, VPC등 IAM 보안주체들도 ARN이 부여된ARN: a fully-qualified name for that resource, used throughout AWS   \"arn:aws:dynamodb:ap-northeast-2:&lt;accountid&gt;:table/example\"    service         region         accountid   service-specific name    리소스와 Amazon Resource NameResource 또는 NotResource(여집합, 규정된 것 제외하고 나머지)를 지원“Resouce”: “arn:aws:s3:::mybucket/”“NotResource”: “arn:aws:s3:::mybucket/”“Resouce”: [“arn:aws:s3:::my_bucket/*”, “arn:aws:dynamodb:ap-northeast-2::table/test\"]특정리전에 있는 전체 인스턴스\"Resouce\":\"arn:aws:ec2:ap-northeast-2::instace/\\*\",아이피조건걸기{    \"version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow(허용) 또는 Deny(차단)\",            \"Action\": [                \"dynamodb:GetItem\",                \"dynamodb:PutItem\"            ],            \"Resource\": [                \"*\"            ],            \"Condtion\": {                \"IpAddress\": {                    \"aws:SourceIp\": \"1.1.1.1\"                },            }        }    ]}정책 condition특정 시간때에 특정 IP 주소의 요청만 허용하거나 거부하고자 싶은면?“Condition”: {“DateGreaterThan”: {“aws:CurrentTime”: “2023-12-23T11:00:00Z”},“DateLessThan”: {“aws:CurrentTime”: “2023-12-23T15:00:00Z”},“IpAddress”: {“aws:SourceIp”: [“192.0.2.0/24”, “203.0.113.0/24”]}}다음조건을 만족할 경우, 사용자가 자원에 접근하는 것을 허용,{“12/23/2023오전 11시 이후”,AND“12/23/23023 오후 3시까지”,IP주소 192.0.2.0/24OR203.0.113.0/24 대역} 에서정책변수{    \"version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow\",            \"Action\": [\"s3:ListBuckete\"],            \"Resource\": [\"arn:aws:s3:::mybucket\"],            \"Condtion\": {\"String\": {\"s3:prefix\": [\"sanghoon/*\"]}}        },        {            \"Action\": [                \"s3:GetObject\",                \"s3:PutObject\"            ],            \"Effect\": \"Allow\",            \"Resource\": [\"arn:aws:s3:::mybucket/sanghoon/*\"]        }    ]}정책변수$(Condition Key)형식으로 변수화사용자마다 고유한 정책 사본을 만들 필요 없이 여러 사용자에게 작용하도록 정책을 일반화정책 변수는 Resource 요소 / Conditon 요소의 문자열 비교에 사용 가능이 정책을 평가할 때는 IAM이 정책 변수를 실제 요청의 string으로 대체{    \"version\": \"2012-10-17\",    \"Statement\": [        {            \"Effect\": \"Allow\",            \"Action\": [\"s3:ListBuckete\"],            \"Resource\": [\"arn:aws:s3:::mybucket\"],            \"Condtion\": {\"String\": {\"s3:prefix\": [\"${aws:username}/*\"]}}        },        {            \"Action\": [                \"s3:GetObject\",                \"s3:PutObject\"            ],            \"Effect\": \"Allow\",            \"Resource\": [\"arn:aws:s3:::mybucket/${aws:username}/*\"]        },    ]}iam policy정책종류            정책      설명      포맷      정의 및 관리                  Identitiy-based 정책      IAM 보안 주체(iam사용자,iam 그룹의 사용자집합,iam 역할)에 할당되어 해당 주체의 권한을 규정      JSON      IAM              Resource-based 정책      정책이 할당될 리소스를 기준으로 어떤 보안 주체가 할 수 있(없)는 작업을 규정.      JSON      개별서비스들              IAM Permisiion Boundary 정책      IAM 보안 주체 별로 획득할 수 있는 권한의 최대치를 규정      JSON      IAM              Organization SCP      Oragnization의 OU 또는 개별 어카운트 별로 권한의 최대치를 규정 주로 Root 어카운트의 권한을 제한 시킬 때 사용.      JSON      Organization              Session 정책      임시 자격증명의 기존 퍼미션을 해당 세션에 대해서만 제한할 때 사용 AssumeRole*,GetFederationToken API의 파라미터로 전달됨      JSON      STS              ACL 정책      리소스 기주능로 정의하며, 주로 Cross-Account 간의 리소스 고유시, 보안주체에 대한 접근을 규정      XML      개별서비스들              Endpoint 정책      VPC G/W Endpoint에 적용되는 접근제어 정책.일종의 Reesource-based 정책      JSON      VPC      Identity based 와 resource based policy"
  },
  
  {
    "title": "AWS 접근제어#1",
    "url": "/posts/aws-%EC%A0%91%EA%B7%BC%EC%A0%9C%EC%96%B4/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-02 11:00:00 +0900",
    





    
    "snippet": "2 aws iam의 인증과 인가identity: iam user의인증credential장기 iam user, root, 일반적으로 장기는 취약임시iam 사용자에게는 상시 자격증명(acceess key/secret access key페어)이 부여rest api, cli, sdk등을 통해 활용identity: iam role의 인증(인스터스, 기타aws서...",
    "content": "2 aws iam의 인증과 인가identity: iam user의인증credential장기 iam user, root, 일반적으로 장기는 취약임시iam 사용자에게는 상시 자격증명(acceess key/secret access key페어)이 부여rest api, cli, sdk등을 통해 활용identity: iam role의 인증(인스터스, 기타aws서비스)iam role 에는 임시 자격증명이 부여  access key  secret access key  security token(with time limit)identity: iam role의 인증(외부사용자)cross accountaws role(역할)장기크레덴셜을 로테이션하지않는이상 서버의 하드코딩하면 위험롤은 임시자격증명access key 없이 arn으로 사용해서 위험이 없음trusted entities권한의 위임 체계를 지원권한정책(해당 역할에 부여될 권한을 규정) + 신뢰정책(해당 역할을 할 수 있는 보안주체 규정)동일 또는 타 어카운트, aws 서비스(ec2,람다 등), 외부인증연계(Federated) 사용자에 부여수임(assumerole) 조건으로 MFA를 지원함IAM 역할을 수임한 IAM 사용자에게는 본래 권한 대신 IAM역할에서 규정된 권한으로 대체AWS IAM Role vs UserIAM Role을 이용하는 경우는자동홛된 프로세스에서aws 서비스들 사이에서인증연계된 외부 사용자들이임시 자격증명으로 인증IAM User을 이용하는 경우는실사용자 기준으로 통제할때상시 자격증명으로 인증IAM Group으로 관리 가능AWS IAM GroupIAM 권한을 한꺼번에 주기 위한 용도임그룹간 포함(Nested)관계는 불가자동 소속되는 기본 그룹은 없음IAM 사용자는 복수개의 그룹에 소속 가능(최대 10개)IAM Group은 보안 주체가 아님Access Management: IAM의 인가모든 AWS 서비스는 접근제어 정책을 기반으로 인가매 API호출시, 적용된 정책을 통해 인가 수행정책은 IAM 역할/사용자/그룹, AWS 리소스, 임시 자격증명 세션, OU 등에 적용할 수 있음AWS Root 어카운트는 기본적으로 AWS 리소스에 대한 모든 권한을 가짐AWS 정책은 기본 디폴트 Deny명시적 Allow &lt; 명시적 Deny의 우선순위AWS API 요청의 인증 단계보안주체가 콘솔, API, CLI를 통해 전송한 요청들은 다음 단계에 따라 평가되고 허용 여부가 판단:요청자 인증 - 익명 요청을 허용하는 S3, Cognito 등 일부 서비스가 있음요청 컨텍스트 수집 요청 주체, 요청된 리소스 및 관련 데이터, 요청된 작업, 환경 데이터(IP,시간대)등을 수집하고 적합한 접근제어 정책(들)을 찾음접근제어 정책 평가()요청의 허용/거부 결정()AWS API 요청의 성공 조건IAM 보안 주체의 적법한 서명값이 포함되어 있고(인증)AND정책(policy)에 의해 해당 요청이 정확하게 인가되어야함IAM 기본 요약  Root(Super User)                    모든 서비스에 대한 접근(권한 조정 불가)                    콘솔과 API에 대한 접근                    빌링 및 고객 지원(Customer Support)에 대한 접근              IAM Users                    특정 서비스에 대한 접근                    콘솔과 API에 대한 선택적 접근                    고객 지원(Customer Support)에 대한 접근                    Password / Long term credential 사용              IAM Group                    IAM 사용자 관리 편리성을 제공                    권한을 한꺼번에 주기 위한 용도                    IAM사용자는 복수개의 그룹에 속할 수 있음              IAM Role                    특정 서비스에 대한 접근                    콘솔과 API에 대한 선택적 접근                    고객 지원(Customer Support)에 대한 접근                    temp credential 사용              Policy                    권한은 요청이 허용되거나 거붇되는지 여부를 결정                    JSON 문서로 작성            "
  },
  
  {
    "title": "AWS-IAM",
    "url": "/posts/aws-iam/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-10-01 12:00:00 +0900",
    





    
    "snippet": "aws iamaws consoleaws cliaws sdk어떤방식으로든 api로 이루어진다 물론 리소르끼리의 응답도 api매 api호출마다, aws cli 및 sdk 등에도 처리되는 인증 절차access key로 요청 주체 (principal)을 인증secret key hmac 서명값을 검증X-Amz-Security-Token:Authorization...",
    "content": "aws iamaws consoleaws cliaws sdk어떤방식으로든 api로 이루어진다 물론 리소르끼리의 응답도 api매 api호출마다, aws cli 및 sdk 등에도 처리되는 인증 절차access key로 요청 주체 (principal)을 인증secret key hmac 서명값을 검증X-Amz-Security-Token:Authorization:AWS4-HMAC-SHA256credentialsignatureaws iamI(identity): aws로 요청을 할 수 있는 보안주체(Principal)를 AWS 어카운트 내에 생성AM(Access Management): 누가 어떤 리소스들에 대해 어떤 일을 할 수 있는 권한을 가지느지를 정의IAM은 AWS전체의 권한 통제 시스템권한 제어는 인증과 인가 outhentiation authenticationiam 보안주체 (principal)aws 어카운트 내에 정의된 요청 주체(identity)CloudTrail “userIdentity” 요소 기준, 다음사용자 유형을 구별:root-api 요청이 aws acccount 자격증명을사용iam User - api 요청이 ima user의 자격증명을 사용assume role- api 요청이 aws sts AssumeRole을 통해 역할로 획득된 임시보안 자격증명을 사용Federated User - api 요청이 AWS STS GetFederation Token을 통해 획득한 임시 보안 자격증명을 사용AWS Account-다른 AWS Account에서 요청AWS Service AWS 서비스에 속한 AWS 계정을 통해 요청SAML이나 WebIdentity Federation을 하는 경우:SAMLUser- SAML 어설션이 이루어지는 요청WebIDentitiyUser- 웹자격 증명 연동 제공업체로 이루어지는 요청"
  },
  
  {
    "title": "aws 보안 \\#3",
    "url": "/posts/aws-%EB%B3%B4%EC%95%88-3/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-09-30 11:00:00 +0900",
    





    
    "snippet": "aws 보안 공동 책임 모델aws와 고객이 함께 만들어가야되는사용자가 커스터마이즈가 가능할수록 고객의 책임이 커짐aws의 보안을 위한 노력 : compliance 를 주기적으로 승인받는다pci,feedramp,hipaa(미국,의료),k-isms(한국)그래서 aws와 사용자의 영역이 다르고 사용자가 늘 사용할때 책임자의 영역에 들어가있으므로 주의해야된다...",
    "content": "aws 보안 공동 책임 모델aws와 고객이 함께 만들어가야되는사용자가 커스터마이즈가 가능할수록 고객의 책임이 커짐aws의 보안을 위한 노력 : compliance 를 주기적으로 승인받는다pci,feedramp,hipaa(미국,의료),k-isms(한국)그래서 aws와 사용자의 영역이 다르고 사용자가 늘 사용할때 책임자의 영역에 들어가있으므로 주의해야된다.4.aws 보안 빌딩 블록aws well-architected보안  사용자 접근제어, 탐지보안, 인프라보안, 데이터보안, 침해대응사용자 접근제어console,cli,api다중의접근제어매커니즘 개별권한관리권한을 사용하는운영자동화를위하면 cli api결국 api를 통해 프로덕션이 되기 때문에 api를 어떻식으로 보호인프라보안기존의 온프레미스랑 비슷여러레이어로 나누어서 보호 다양한 레벨을 아우를수있는ddos방어 aws shield어플리케이션 위협 보호 aws waf네트워크 방화면 aws network firewall service네트워크 접근 제어 security group NACL네트워크 격리 aws vpc탐지제어 침해대응로깅뿐만아니라 realtime 모니터링을 통해여러계츠으이 로그를 중앙집중식aws cloudtailamazon cloudwatch eventamazon guarddutyamazon cloudwatchaws configamazon s3amazon s3 glacieramazon athenaamazon inspectoraws security hubamazon클라우드 환경에서 보안 업무를 한다는 것은..결코 쉬운일이 아님기존보안에 대한 기본을 알아야된다새로운 클라우드환경의 이해새로운 공격 형태에 대한 이해devsecops의 구현compliance 어느 기업도 피할수없는과정gameday(해커톤)개발속도에만취중한사람의보안의식고취시키기계속채워나가야되는 업무,"
  },
  
  {
    "title": "aws 보안 \\#2",
    "url": "/posts/aws-%EB%B3%B4%EC%95%88-2/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-09-29 11:00:00 +0900",
    





    
    "snippet": "보안 침해 사례Capital One(2019) AWS보안 안전성 도마위에SSRF 취약점으로 ec2 메타데이터 접근랜섬웨어블록체인 채굴개인정보 유출클라우드는 위험하다AWS AZUER 퍼블릭 클라우드라서 개인정보를 둘수없다SSRF(Server-Side Request Forgeery)어플리케이션에 비해 많은 권한비정상적인 api 요청 기능를 안씀개발자의 부...",
    "content": "보안 침해 사례Capital One(2019) AWS보안 안전성 도마위에SSRF 취약점으로 ec2 메타데이터 접근랜섬웨어블록체인 채굴개인정보 유출클라우드는 위험하다AWS AZUER 퍼블릭 클라우드라서 개인정보를 둘수없다SSRF(Server-Side Request Forgeery)어플리케이션에 비해 많은 권한비정상적인 api 요청 기능를 안씀개발자의 부주의함클라우드 환경사고 95% 고객실수가 기인클라우드 보안의 진짜 위험개발과 운영의 기준이 모호개발속도가 빨라짐 보안이 뒤처짐on-prem 보안 vs 클라우드 보안ApI 기반 웹서비스로 제공되는 클라우드API 기반 접근 제어 (iam) 퍼블릭하게 열려있는 웹사이트 기반 특성상 워크로드 가장 깊은곳 침범네트워크기반으로 되는 on-premAPI 기반 탐지 및 자동화 (api추적용이) 어떤 기능이 필요한지 파악하고 서비스들을 활용 빌딩블록을 만든다"
  },
  
  {
    "title": "aws 보안 \\#1",
    "url": "/posts/aws%EB%B3%B4%EC%95%88/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-09-28 11:00:00 +0900",
    





    
    "snippet": "클라우드상에서의 보안aws 보안 overview aws 보안의 필요성과 고려사항aws 접근제어 iam을 중심으로 한 aws wjqrmswpdjaws 네트워크 보안 다양한 네트워크 계층에서 고민해야하는 aws보안aws 보안 탐지 및 자동화 aws 계정 전반에 대한 보안 위협 탐지 및 자동화 전략DevSecOps on aws DevOps영역에서의 보안클라...",
    "content": "클라우드상에서의 보안aws 보안 overview aws 보안의 필요성과 고려사항aws 접근제어 iam을 중심으로 한 aws wjqrmswpdjaws 네트워크 보안 다양한 네트워크 계층에서 고민해야하는 aws보안aws 보안 탐지 및 자동화 aws 계정 전반에 대한 보안 위협 탐지 및 자동화 전략DevSecOps on aws DevOps영역에서의 보안클라우드 보안과 온프렘 보안의 차이클라우드 상에서의 보안 고려사항클라우드 보안 빌딩 블록보안아키텍처의 구성devops 보안의 무지 무시 하면 위험"
  },
  
  {
    "title": "모니터링 알람과 자동화#3",
    "url": "/posts/monitoring3/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-09-27 12:11:11 +0900",
    





    
    "snippet": "Datadog Metric Querymetrics Explorer를 통해 Dashborad나 Widget을 만들기 전, metric을 조회해 볼 수 있는 기능이 있음Metric Summary 탭에서 지원하는 Metric 조회 가능시간 단위, 찾는 Metric 조건, 집계 함수 등을 수정하면서 Metric 확인APM Based Metric, Log Ba...",
    "content": "Datadog Metric Querymetrics Explorer를 통해 Dashborad나 Widget을 만들기 전, metric을 조회해 볼 수 있는 기능이 있음Metric Summary 탭에서 지원하는 Metric 조회 가능시간 단위, 찾는 Metric 조건, 집계 함수 등을 수정하면서 Metric 확인APM Based Metric, Log Based Metric, Custom Metric도 조회Datadog APIdatadog에서 지원하는 대부분의 기능을 API로 제공java, python, typescript 등 언어에 대한 SDK를 공식적으로 지원해줌Datadog에서 발급하는 API Key, APP Key를 활용하여 API 사용짧은 주기로 호출 하는 경우, Rate limit이 걸릴 수 있음 API 별로 다름Slack으로 Datadog Metric 조회"
  },
  
  {
    "title": "S3 beckend",
    "url": "/posts/s3-key/",
    "categories": "Blogging",
    "tags": "s3",
    "date": "2023-09-26 12:00:00 +0900",
    





    
    "snippet": "s3Terraform generates key names that include the values of the bucket and key variables.This backend also supports state locking and consistency checking via Dynamo DB, which can be enabled by sett...",
    "content": "s3Terraform generates key names that include the values of the bucket and key variables.This backend also supports state locking and consistency checking via Dynamo DB, which can be enabled by setting the dynamodb_table field to an existing DynamoDB table name.terraform {  required_version = \"&gt;= 1.0.0\"  backend \"s3\" {    bucket         = s3.bucket    key            = s3.key    region         = \"ap-northeast-2\"    encrypt        = true    dynamodb_table = \"terraform-lock\"  }}  tip: there  Note:"
  },
  
  {
    "title": "모니터링 알람과 자동화#2",
    "url": "/posts/monitoring2/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-09-25 12:11:11 +0900",
    





    
    "snippet": "datadog을 활용해서alert모니터링 하는 특정 metric의 이상 현상을 알림으로 받기 위한 기능예를들어 급격히 증가하는 HTTP 400/500 Error와 db cpu metric 값을 올라갔을때 엮어 상황 유추 가능특정 조건을 걸어 단일 alert으로 생성 여러 단일 alert으로 복합 조건인 alert을 생성 가능어떤 상황이 발생했는지를 알...",
    "content": "datadog을 활용해서alert모니터링 하는 특정 metric의 이상 현상을 알림으로 받기 위한 기능예를들어 급격히 증가하는 HTTP 400/500 Error와 db cpu metric 값을 올라갔을때 엮어 상황 유추 가능특정 조건을 걸어 단일 alert으로 생성 여러 단일 alert으로 복합 조건인 alert을 생성 가능어떤 상황이 발생했는지를 알림 채널(email, slack, pageduty등)을 통해 알림을 받음이를 통해 예외 상황 대응을 빠르게 할 수 있음incident서비스 장애나 인프라 장애가 발생했을때 단순히 문제를 해결하는 것이 다가 아님다시 발생하지 않도록 예방책과 왜 문제가 일어났는지에 대한 분석이 필요monitor, slo, metrics들을 종합적으로 분석이를 incident화 시켜서 관리incident가 발생 시, 필요한 인원에 대한 slack channel, alert 생성당시 상황에 해당하는 metric 그래프, warning과 monitor의 alert을 시간 순으로 나열postmoterm(부검,회고)으로 이어지는 구조로 구성slosli를 이용해 목표로 하는 서비스 수준 목표(SLO)까지 지킬 수 있도록 지정SLO는 SRE의 핵심 같은 수준의 서비스를 사용자에게 제공하기 위한 목표값앞선 모니터 기반 SLO와 메트릭 기반 SLO, Error Budget, Burn Rate를 설정SLO설정을 통해서는 Metric으로 사용가능 Dashboard로 사용이를 하나의 Metric으로 Monitor를 활용해 설정한 값 중 특정 조건이 해당되면 Alert를 발생monitor 알람 slack으로 받기"
  },
  
  {
    "title": "모니터링 알람과 자동화#1",
    "url": "/posts/monitoring1/",
    "categories": "Blogging",
    "tags": "",
    "date": "2023-09-24 12:11:11 +0900",
    





    
    "snippet": "대부분의 모니터링 솔루션에는 Alert 기능이 존재모니터링 대상에서 일어나는 여러 사건을 매번 확인할수없음따라서 이를 rule 혹은 policy로 만들어서 사용즉, 특정 조건에 만족하게 되면 어떤 현상이 일어난 것으로 인지대응할 수 있도록 알람Email, SMS, SNS 등을 활용cloudwatch는 모니터링이 되는 대부분 서비스에 대해 알람 제공lb...",
    "content": "대부분의 모니터링 솔루션에는 Alert 기능이 존재모니터링 대상에서 일어나는 여러 사건을 매번 확인할수없음따라서 이를 rule 혹은 policy로 만들어서 사용즉, 특정 조건에 만족하게 되면 어떤 현상이 일어난 것으로 인지대응할 수 있도록 알람Email, SMS, SNS 등을 활용cloudwatch는 모니터링이 되는 대부분 서비스에 대해 알람 제공lb나 ec2 status, billing 등 다양한 지표를 알람 지표로 제공복합 조건에 대한 알람도 제공발생한 알람은 sns의 특정 topic으로 publish 이를 가져가서 사용하는 곳에서 보낼 대상으로 구현이 필요grafan와 연결된 모둔 data source에 대해 알람 지표로 제공연결된 데이터 소스에 따라 지표를 다르게 평가 prometheus는 PromQL, MySQLdms SQL 등으로 지표를 평가외부의 AlertManager를 Datasource로 사용 모니터링 및 Alert 발생을 한곳에서 관리최근에는 Enterprise 버전에서만 제공되는 기능도 추가모니터링 대상이 되는 Application에 Rule을 적용해서 알람제공preset으로 제공되는 rule에 대해서만 가능 발생한 alarm을 Db에 저장알람 대상은 기본적으로 email과 sms(interface제공), webhook 사용가능다른 모니터링 tool에 비해 많은 기능을 지원하지 않음"
  },
  
  {
    "title": "SaaS를 활용한 모니터링(Sumo Logic)#2",
    "url": "/posts/SaaS-04/",
    "categories": "Blogging, devops",
    "tags": "Sumo Logic",
    "date": "2023-09-22 12:11:11 +0900",
    





    
    "snippet": "sumo logic integration과 AWS infrastructure monitoring사용자 AWS계정에 sumo logic에서 사용할 iam role 생성Role-based access (recommended)key accesskey access policy document{  \"Version\": \"2012-10-17\",  \"Statemen...",
    "content": "sumo logic integration과 AWS infrastructure monitoring사용자 AWS계정에 sumo logic에서 사용할 iam role 생성Role-based access (recommended)key accesskey access policy document{  \"Version\": \"2012-10-17\",  \"Statement\": [    {      \"Action\": [        \"cloudwatch:ListMetrics\",        \"cloudwatch:GetMetricStatistics\",        \"ec2:DescribeeInstance\",        \"tag:GetResource\"      ],      \"Effect\": \"Allow\",      \"Resource\": \"*\"    }  ]}sumo logic에서는 해당 iam role을 사용하여 지정된 서비스 metrics 수집sumo logic installed collectors와 application log monitoringdocker, ec2 환경(linux)에 installed collector 설치application의 log를 sumo logic으로 전달, 대시보드에서 조회"
  },
  
  {
    "title": "SaaS를 활용한 모니터링(Sumo Logic)#1",
    "url": "/posts/SaaS-03/",
    "categories": "Blogging, devops",
    "tags": "Sumo Logic",
    "date": "2023-09-21 12:11:11 +0900",
    





    
    "snippet": "Sumo Logic클라우드 기반의 데이터 모니터링 및 분석 SaaS 플랫폼  인프라, 클라우드, 어플리케이션, 로그 및 CI/CD, 보안 모니터링 제공  SIM(Security Information Monitoring), SEM(Security Event Management)을 지원하는 SIEM(보안 정보 및 이벤트 관리) 솔루션 제공  다양한 CSP...",
    "content": "Sumo Logic클라우드 기반의 데이터 모니터링 및 분석 SaaS 플랫폼  인프라, 클라우드, 어플리케이션, 로그 및 CI/CD, 보안 모니터링 제공  SIM(Security Information Monitoring), SEM(Security Event Management)을 지원하는 SIEM(보안 정보 및 이벤트 관리) 솔루션 제공  다양한 CSP(AWS, Azure, GCP등) 지원Sumo Logic Components  Installed Collectors          Agent 방식으로 Host의 Metric과 지정된 Path의 Log를 수집        Hosted Collectors          AWS, GCP, Azure 등 클라우드에 위치해 있으며 별다른 설치 없이 Role이나 Access key 기반으로 서비스 데이터를 수집하는 Collector      sumo logic data tier  continuous tier          실시간으로 모니터링 되어야 하는 데이터를 Continuous Tier로 지정      Application log, Security log, access log      대시보드, 모니터(알람) 지원        frequent tier          비교적 자주 검색하는 데이터를 Frequent Tier로 지정      개발 및 테스트 로그, 제품 분석 데이터 등      대시보드, 모니터(알람) 지원 하지 않음        infrequent tier          거의 조회하지 않는 데이터를 Infrequent tier로 지정                  간헐적이거나 재현하기 어려운 데이터 (디버그로그 ,os로그, 스레드 덤프)          Data Forwar, 대시보드, 모니터(알람) 지원 하지 않음                    "
  },
  
  {
    "title": "SaaS를 활용한 모니터링(Datadog)#2",
    "url": "/posts/SaaS-02/",
    "categories": "Blogging, devops",
    "tags": "Datadog",
    "date": "2023-09-20 13:00:00 +0900",
    





    
    "snippet": "SaaS를 활용한 모니터링(Datadog) #2구축방법Datadog integration AWS infrastructure monitoring  사용자 AWS 계정에 datadog에서 사용한 iam role 생성DatadogIntegretionRole{    \"Version\": \"2012-10-17\",    \"Statement\": [        \"E...",
    "content": "SaaS를 활용한 모니터링(Datadog) #2구축방법Datadog integration AWS infrastructure monitoring  사용자 AWS 계정에 datadog에서 사용한 iam role 생성DatadogIntegretionRole{    \"Version\": \"2012-10-17\",    \"Statement\": [        \"Effect\": \"Allow\",        \"Principal\": {            \"AWS\": \"arn:aws:iam::&lt;my_id&gt;\"        },        \"Action\": \"sts:AssumRole\",        \"Condition\": {            \"StringEquals\": {                \"sts:ExternalId\": \"&lt;YOUR_AWS_EXTERNAL_ID Integrations&gt;\"            }        }    ]}권한{  \"Version\": \"2012-10-17\",  \"Statement\": [    {      \"Action\": [        \"apigateway:GET\",        \"autoscaling:Describe*\",        \"backup:List*\",        \"budgets:ViewBudget\",        \"cloudfront:GetDistributionConfig\",        \"cloudfront:ListDistributions\",        \"cloudtrail:DescribeTrails\",        \"cloudtrail:GetTrailStatus\",        \"cloudtrail:LookupEvents\",        \"cloudwatch:Describe*\",        \"cloudwatch:Get*\",        \"cloudwatch:List*\",        \"codedeploy:List*\",        \"codedeploy:BatchGet*\",        \"directconnect:Describe*\",        \"dynamodb:List*\",        \"dynamodb:Describe*\",        \"ec2:Describe*\",        \"ec2:GetTransitGatewayPrefixListReferences\",        \"ec2:SearchTransitGatewayRoutes\",        \"ecs:Describe*\",        \"ecs:List*\",        \"elasticache:Describe*\",        \"elasticache:List*\",        \"elasticfilesystem:DescribeFileSystems\",        \"elasticfilesystem:DescribeTags\",        \"elasticfilesystem:DescribeAccessPoints\",        \"elasticloadbalancing:Describe*\",        \"elasticmapreduce:List*\",        \"elasticmapreduce:Describe*\",        \"es:ListTags\",        \"es:ListDomainNames\",        \"es:DescribeElasticsearchDomains\",        \"events:CreateEventBus\",        \"fsx:DescribeFileSystems\",        \"fsx:ListTagsForResource\",        \"health:DescribeEvents\",        \"health:DescribeEventDetails\",        \"health:DescribeAffectedEntities\",        \"kinesis:List*\",        \"kinesis:Describe*\",        \"lambda:GetPolicy\",        \"lambda:List*\",        \"logs:DeleteSubscriptionFilter\",        \"logs:DescribeLogGroups\",        \"logs:DescribeLogStreams\",        \"logs:DescribeSubscriptionFilters\",        \"logs:FilterLogEvents\",        \"logs:PutSubscriptionFilter\",        \"logs:TestMetricFilter\",        \"organizations:Describe*\",        \"organizations:List*\",        \"rds:Describe*\",        \"rds:List*\",        \"redshift:DescribeClusters\",        \"redshift:DescribeLoggingStatus\",        \"route53:List*\",        \"s3:GetBucketLogging\",        \"s3:GetBucketLocation\",        \"s3:GetBucketNotification\",        \"s3:GetBucketTagging\",        \"s3:ListAllMyBuckets\",        \"s3:PutBucketNotification\",        \"ses:Get*\",        \"sns:List*\",        \"sns:Publish\",        \"sqs:ListQueues\",        \"states:ListStateMachines\",        \"states:DescribeStateMachine\",        \"support:DescribeTrustedAdvisor*\",        \"support:RefreshTrustedAdvisorCheck\",        \"tag:GetResources\",        \"tag:GetTagKeys\",        \"tag:GetTagValues\",        \"xray:BatchGetTraces\",        \"xray:GetTraceSummaries\"      ],      \"Effect\": \"Allow\",      \"Resource\": \"*\"    }  ]}  datadog에서는 해당 iam role을 사용하여 지정된 서비스 metrics 수집Datadog Agent를 활용한 Application Performance Monitoring"
  },
  
  {
    "title": "SaaS를 활용한 모니터링(Datadog)#1",
    "url": "/posts/SaaS-01/",
    "categories": "Blogging, devops",
    "tags": "Datadog",
    "date": "2023-09-19 01:34:00 +0900",
    





    
    "snippet": "SaaS를 활용한 모니터링(Datadog)#1오픈소스를 활용한 모니터링 콜렉터 에이전트를 직접 관리SaaS를 이용한 모니터링이란?사용자들은 별도의 관리 서버나 대시보드 없이 SaaS 솔루션의 Endpoint로 Agent를 통해 데이터를 전송만 하면 시각화  수집된 데이터이 보관주기를 지정해서 사용  대부분 host 당 요금제로 과금하는 형태가 많음  ...",
    "content": "SaaS를 활용한 모니터링(Datadog)#1오픈소스를 활용한 모니터링 콜렉터 에이전트를 직접 관리SaaS를 이용한 모니터링이란?사용자들은 별도의 관리 서버나 대시보드 없이 SaaS 솔루션의 Endpoint로 Agent를 통해 데이터를 전송만 하면 시각화  수집된 데이터이 보관주기를 지정해서 사용  대부분 host 당 요금제로 과금하는 형태가 많음  최근 클라우드 환경에서 인프라와 어플리케이션, 로그 , DB를 종합적으로 볼 수 있는 솔루션으이 상용이 대세  전통적인 서버 관련 모니터링 뿐만 아니라 UX 까지 모니터링 할수 있음SaaS 모니터링 솔루션엔 뭐가 있을까?  Datadog  NewRelic  Dynatrace  Sumologic  Splunk  whatap(한국기업)Datadog서버, DB, 클라우드 서비스 등에 대한 다양한 모니터링을 제공하는 클라우드 모니터링 애플리케이션을 대표하는 SaaS  서버 상태, DB 쿼리 모니터링, 로그 모니터링  UX, CI, Security 영역까지 확대  다양한 CSP(AWS, Azure, GCP 등) 지원  Custom Metric과 다양한 형태의 Alert 지원(Infrastructure)네트워크나 Host, Container, Process 등 인프라와 관련된 모니터링 기능을 제공  integration을 통해 특정 CSP와 연동하면 host 정보를 수집하여 Map 형태로 나타낼 수 있음.  Serverless와 관련된 서비스에 대해서도 모니터링 가능(library import)  클라우드 비용에 대한 모니터링도 제공(APM) Application Performence Mornitoring어플리케이션에 특정 Library를 같이 올려서 어플리케이션에 대한 실행 메소드나 성능을 모니터링  실시간으로 서비스에 대한 요청, 응답시간, 메소드 실행 흐름 등을 모니터링  Log, RUM(Realtime User Mornitoring) ui쪽 모니터링,synthetic tests(api 모니터링)와 (APM)Trace를 연동하여 특정 시점에 대한 모니터링이 쉬움  Database monitoring 기능으로 사용하고 있는 DB의 Slow query, query plan 등모니터링 3-tier 아키텍처에서 병목지점을 빠르게 찾을 수 있음(Logs)Agent를 통해 어플리케이션의 Log를 수집해서 모니터링  단순 Log 모니터링부터 Log와 Trace를 엮어서 사용자에게 제공  이를 통해 서비스 장애 발생 시, 사용자는 해당 시점에 어떤 Log가 있었는지에 대해 분석하기가 쉬움  Observalbilty Pipelines을 제공해서 수집된 데이터들은 다른 모니터링 대상으로 정보를 가공할 수 있는 기능도 제공(UX)사용자 앞단에서 특정 API를 호출했을때, UI로부터 시작되는 로직의 모니터링이나 사용자의 행동에 따른 세션 등을 모니터링  Real Useer Monitoring을 통해 사용자가 어느 국가에서 들어왔는지, 혹은 어떤 페이지에 오래 머물렀는지 등 다양한 모니터링 지표를 js를 통해 수집  세션 리플레이 기능을 통해 UX를 고도화시킬 수 있음  다양한 테스트 기능 지원(Monitors)수집되는 데이터를 특정한 조건을 걸어 해당 조건이 된 경우, 알람을 발생시키는 기능  이를 활용해서 갑자기 값이 변하는 경우, 이상 징후 감지 기능을 할 수 있음  장애 발생 시, Incident에 대해 정리하기 용이  SLI를 정해서 SLO를 지키기 위해 모니터링 기능"
  },
  
  {
    "title": "모니터링",
    "url": "/posts/2023-05-05/",
    "categories": "dev",
    "tags": "",
    "date": "2023-08-18 00:37:41 +0900",
    





    
    "snippet": "왜 안돼",
    "content": "왜 안돼"
  },
  
  {
    "title": "파서 만들기",
    "url": "/posts/%ED%8C%8C%EC%84%9C-%EB%A7%8C%EB%93%A4%EA%B8%B0/",
    "categories": "dev",
    "tags": "",
    "date": "2023-08-17 00:00:00 +0900",
    





    
    "snippet": "nginx 로그 분석여기엔 어떤 정보들이 담겨있나요?자바스크립트 언어를 이용해 한 줄로부터 출발지 IP, HTTP 메서드, 응답 코드, 주소, 접속 시간을 추출해 낼 수 있나요? 10.0.210.17 - - [28/Nov/2022:11:33:28 +0900] \"GET /hello HTTP/1.1\" 200 615 \"-\" \"curl/7.84.0\" \"-\"표...",
    "content": "nginx 로그 분석여기엔 어떤 정보들이 담겨있나요?자바스크립트 언어를 이용해 한 줄로부터 출발지 IP, HTTP 메서드, 응답 코드, 주소, 접속 시간을 추출해 낼 수 있나요? 10.0.210.17 - - [28/Nov/2022:11:33:28 +0900] \"GET /hello HTTP/1.1\" 200 615 \"-\" \"curl/7.84.0\" \"-\"표준 입력으로부터 들어오는 로그가, JSON의 형태로 변환되어 표준 출력으로 나오게 만들어야 합니다.스트링을 배열로 파싱const text = '[1, 2, 3]'const parsed = text.slice(1, -1).split(',').map(chunk =&gt; +chunk.trim())배열을 문자열로 파싱const array = [1, 2, 3]const serialized = '[' + array.join(',') + ']'문자열에서 원하는 형태로 가공하는 것을 파싱(Parsing)이라고 하고, 객체에서 문자열로 바꾸는 과정을 시리얼라이즈(Serialize / 직렬화)한다고 합니다. 파싱을 하기 위해서는 파서(Parser)를 만들어야하고, 시리얼라이즈하기 위해서는 시리얼라이저(Serializer)를 만들어야 합니다.위의 예시처럼 규칙이 단순하다면, 문자열 함수를 통해 쉽게 처리가 가능합니다. 하지만 복잡한 규칙을 만들어야 한다면 어떻게 될까요?const text = '[1, 2, 3, [4, 5]]'// parsed = ?const parsed = JSON.parse(text)const array = [1, 2, 3, [4, 5]]// serialized = ?const serialized = JSON.stringify(array)단순히 재귀를 추가했을 뿐인데 어떻게 만들어야 할지 바로 감이 오지 않습니다.그런데 자바스크립트의 내장 함수인 JSON.stringify, JSON.parse는 이 작업을 해주고 있고, 우리는 쉽게 가져다 쓰고 있습니다.이 우리 눈에 익숙한 JSON.stringify, JSON.parse를 직접 구현하면서 파서와 시리얼라이저의 원리를 알아보도록 하겠습니다. :-)시리얼라이저(JSON.stringify) 만들기내장 함수 JSON.stringify와 동일하게 동작하는 stringify 함수 즉, 시리얼라이저를 만들어봅시다.시리얼라이저를 만들기에 앞서 JSON의 구조를 살펴보겠습니다. JSON은 스칼라 자료형 string, number, boolean, null 4개, 여기에 배열(array)과 객체(object)가 추가된 총 6개의 자료형을 지원합니다.여기서 가장 단순한 자료형인 스칼라 자료형(string, number, boolean, null)을 먼저 작성해봅시다.function stringify(value) {  if (value === null) {    return \"null\"  }  if (typeof value === \"number\") {    return `${value}`  }  if (typeof value === \"boolean\") {    return value ? \"true\" : \"false\"  }  if (typeof value === \"string\") {    return `\"${value.replace('\"', '\\\\\"')}\"` // \" 문자는 escape 해야합니다.  }}// test scalarconsole.log(stringify(null) === \"null\") // trueconsole.log(stringify(true) === \"true\") // trueconsole.log(stringify(false) === \"false\") // trueconsole.log(stringify(\"hello\") === \"\\\"hello\\\"\") // trueconsole.log(stringify(\"he\\\"llo\") === \"\\\"he\\\\\\\"llo\\\"\") // true그 다음은 배열(array)을 만들어 봅시다. 배열내부는 재귀함수를 활용하면 쉽게 처리할 수 있습니다.function stringify(value) {  /* ...생략... */  if (Array.isArray(value)) {    return `[${value.map(stringify).join(\",\")}]` // 재귀함수  }}// test arrayconsole.log(stringify([1,2,3]) === \"[1,2,3]\") // trueconsole.log(stringify([1,[1,2,3],3]) === \"[1,[1,2,3],3]\") // trueconsole.log(stringify([true, false, \"hello\", null]) === \"[true,false,\\\"hello\\\",null]\") // true그리고 마지막으로 객체(object)를 만들어봅시다. 위에 스칼라 자료형과 배열을 처리했기 때문에 그외의 케이스는 전부 객체(object)라고 생각해도 괜찮습니다. 물론, 함수(function)도 있긴 한데, 여기서는 무시하겠습니다.function stringify(value) {  /* ...생략... */  // 키 값의 \" 문자는 이스케이프 합니다. val 부분은 재귀함수로 처리합니다.  return `{${Object.entries(value).map(([k, v]) =&gt; `\"${k.replace('\"', '\\\\\"')}\":${stringify(v)}`).join(\",\")}}`}// test objectconsole.log(stringify({foo: \"hello\"}) === \"{\\\"foo\\\":\\\"hello\\\"}\") // trueconsole.log(stringify({  foo: \"string!\",  bar: 30.3333,  baz: true,  qux: {    foo: {},    bar: {      foo: \"string!!!\",    },    baz: 20.2222,  }}) === \"{\\\"foo\\\":\\\"string!\\\",\\\"bar\\\":30.3333,\\\"baz\\\":true,\\\"qux\\\":{\\\"foo\\\":{},\\\"bar\\\":{\\\"foo\\\":\\\"string!!!\\\"},\\\"baz\\\":20.2222}}\") // true내장함수 JSON.stringify와 동일하게 동작하는 stringify를 쉽게 만들 수 있었습니다.시리얼라이저 확장하기JSON 중에는 좀 더 많은 기능을 지원하는 JSON5라는 표준이 있습니다. 위에서 만든 함수를 확장하여 JSON5와 같이 number타입인 Infinity, NaN을 추가로 구현해봅시다. 또, JSON5에서는 지원하지 않는 정규표현식 자료형도 지원하도록 개선해봅시다.Infinite, -Infinity, NaN를 추가합니다. 이 3가지 값은 모두 number 타입이니 해당하는 부분을 수정합니다.function stringify(value) {  /* ...생략... */  if (typeof value === \"number\") {    if (Number.isNaN(value)) {      return \"NaN\"    }    if (!Number.isFinite(value)) {      return value &gt; 0 ? \"Infinity\" : \"-Infinity\"    }    return `${value}`  }  /* ...생략... */}// test infinity &amp; nanconsole.log(stringify(Infinity) === \"Infinity\") // trueconsole.log(stringify(-Infinity) === \"-Infinity\") // trueconsole.log(stringify(NaN) === \"NaN\") // trueconsole.log(stringify({foo: Infinity}) === \"{\\\"foo\\\":Infinity}\") // true정규표현식은 instanceof를 통해 확인할 수 있습니다. 또한 toString 메서드를 통해 쉽게 string으로 변환할 수 있습니다.function stringify(value) {  /* ...생략... */  if (Array.isArray(value)) {    return `[${value.map(stringify).join(\",\")}]`  }  if (value instanceof RegExp) {    return value.toString()  }  return `{${Object.entries(value).map(([k, v]) =&gt; `\"${k.replace('\"', '\\\\\"')}\":${stringify(v)}`).join(\",\")}}`}// test regexpconsole.log(stringify(/asdf/) === \"/asdf/\") // trueconsole.log(stringify(new RegExp(\"asdf\")) === \"/asdf/\") // trueconsole.log(stringify(/asdf/gi) === \"/asdf/gi\") // trueconsole.log(stringify(new RegExp(\"asdf\", \"gi\")) === \"/asdf/gi\") // true제대로 동작하는지 한번 돌려봅시다.stringify({  string: \"foo\",  number: 30,  number2: 3.14156,  true: true,  false: false,  null: null,  infinity: Infinity,  ninfinity: -Infinity,  nan: NaN,  re: /hello/gi,  array: [1,2,3],  object: {    foo: \"hello\"  }})// {\"string\":\"foo\",\"number\":30,\"number2\":3.14156,\"true\":true,\"false\":false,\"null\":null,\"infinity\":Infinity,\"ninfinity\":-Infinity,\"nan\":NaN,\"re\":/hello/gi,\"array\":[1,2,3],\"object\":{\"foo\":\"hello\"}}전체 소스는 Github에서 확인할 수 있습니다.이 시리얼라이즈를 통해서 만들어진 문자열은 해석할 수 있는 파서가 없어 아직은 자바스크립트 객체로 바꿀 수 없습니다. 시리얼라이저에 비해 파서를 만드는 작업은 더 복잡합니다. 하지만, 이 작업은 프로그래밍의 꽃인 컴파일러를 만드는 과정 중의 일부일 뿐입니다. 파서를 만드는 일은 곧 컴파일러의 동작을 이해하게 되고, 이로서 프로그래밍 그 자체를 더 잘 알게되는 계기가 될 것입니다.파서는 2편에서 만들어보도록 하겠습니다. :-)https://wan2.land/posts/2020/02/11/make-parser-1/"
  },
  
  {
    "title": "Terraform User Data",
    "url": "/posts/terraform-user-data/",
    "categories": "Blogging",
    "tags": "Terraform",
    "date": "2023-08-08 12:11:11 +0900",
    





    
    "snippet": "  **NOTE**: For accounts created after May 31, 2023, the EC2 console only supports creating Auto Scaling groups with launch templates. Creating Auto Scaling groups with launch configurations is not...",
    "content": "  **NOTE**: For accounts created after May 31, 2023, the EC2 console only supports creating Auto Scaling groups with launch templates. Creating Auto Scaling groups with launch configurations is not recommended but still available via the CLI and API until December 31, 2023.테라폼으로 오토스케일 만들었는데launch configurations가 더이상 추천되지 않는다고 해서launch template 으로 다시 만들었다  Error creating EC2 Launch Template (acg_launch_template): InvalidUserData.Malformed: Invalid BASE64 encoding of user data.resource \"aws_launch_template\" \"name\" {    name = \"acg_launch_template\"    image_id = \"ami-04599ab1182cd7961\"    instance_type = \"t2.micro\"    vpc_security_group_ids = [aws_security_group.inastance.id]    key_name = local.key_name    user_data = filebase64(\"userdata.sh\")    block_device_mappings {        device_name =            ebs {            volume_size = 8            }        }}쉘스크립트로 만든 유저데이터파일을 file(“userdata.sh”) 넣어줬는데런치템플릿에서는 base64로 엔코딩을 해줘야되는것 같다file을 넣어주고 싶으면 filebase64()EOF (End Of File)user_data = &lt;&lt;EOF#! /bin/bashsudo yum install -y httpdsudo service httpd startEOF"
  },
  
  {
    "title": "포스트 쉘스크립트 만들기",
    "url": "/posts/%ED%8F%AC%EC%8A%A4%ED%8A%B8-%EC%89%98%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8-%EB%A7%8C%EB%93%A4%EA%B8%B0/",
    "categories": "dev",
    "tags": "",
    "date": "2023-07-06 00:00:00 +0900",
    





    
    "snippet": "포스트 쉘스크립트 만들기블로그에 글을 포스트 할때 마다 포스트 양식을 복사 붙여넣기 하는게 너무 귀찮다쉘스크립트를 만들어보자# 블로그 포스트의 제목을 입력 받습니다.read -p \"포스트 제목을 입력하세요: \" title# 카테고리 선택을 위한 선택지를 배열로 선언합니다.options=(\"dev\" \"writer\")# 선택을 위한 대화상자를 출력하고 선...",
    "content": "포스트 쉘스크립트 만들기블로그에 글을 포스트 할때 마다 포스트 양식을 복사 붙여넣기 하는게 너무 귀찮다쉘스크립트를 만들어보자# 블로그 포스트의 제목을 입력 받습니다.read -p \"포스트 제목을 입력하세요: \" title# 카테고리 선택을 위한 선택지를 배열로 선언합니다.options=(\"dev\" \"writer\")# 선택을 위한 대화상자를 출력하고 선택을 받습니다.category=$(osascript -e 'button returned of (display dialog \"포스트 카테고리를 선택하세요:\" buttons {\"dev\", \"writer\"} default button 1)')# 선택이 취소되었을 경우 스크립트를 종료합니다.if [[ $category == \"false\" ]]; then    echo \"카테고리 선택이 취소되었습니다.\"    exit 1fi# 댓글을 허용할지 여부를 입력 받습니다.comments=$(osascript -e 'button returned of (display dialog \"댓글을 허용하시겠습니까?\" buttons {\"true\", \"false\"} default button 1)')# 블로그 포스트의 파일명을 생성합니다.filename=\"_posts/$(date +\"%Y-%m-%d\")-$(echo \"$title\" | tr \" \" -).md\"# 블로그 포스트 파일을 생성하고 헤더 정보를 추가합니다.echo \"---\" &gt; \"$filename\"echo \"title: $title\" &gt;&gt; \"$filename\"echo \"categories: [$category]\" &gt;&gt; \"$filename\"echo \"comments: $comments\" &gt;&gt; \"$filename\"echo \"---\" &gt;&gt; \"$filename\"echo \"블로그 포스트 파일이 생성되었습니다. 파일명: $filename\"이제 쉘스크립트를 실행해서 포스트 양식을 만들어 줄 수 있다"
  },
  
  {
    "title": "파이널 회고 작성5",
    "url": "/posts/%ED%8C%8C%EC%9D%B4%EB%84%90-%ED%9A%8C%EA%B3%A0%EC%9E%91%EC%84%B1-5/",
    "categories": "writing",
    "tags": "",
    "date": "2023-06-28 00:00:00 +0900",
    





    
    "snippet": "파이널 마무리 하며2주동안 파이널을 했는데 아무것도 없이 처음부터 시작해보니 너무 어려웠다. 잘몰라서 의견도 잘 안말하고  그런편인데 팀장님이 팀원들과 소통을 잘하셔서 갈피를 못잡고 있을때 뭘 해야되는지 정해주는 부분도 있어서 좋았고 또 팀원들의 소중함을 느꼈다부족했던 부분프론트엔드 처음으로 만들어봤는데 무슨 언어를 어떤 프레임웍스를 시작해서 라우트 ...",
    "content": "파이널 마무리 하며2주동안 파이널을 했는데 아무것도 없이 처음부터 시작해보니 너무 어려웠다. 잘몰라서 의견도 잘 안말하고  그런편인데 팀장님이 팀원들과 소통을 잘하셔서 갈피를 못잡고 있을때 뭘 해야되는지 정해주는 부분도 있어서 좋았고 또 팀원들의 소중함을 느꼈다부족했던 부분프론트엔드 처음으로 만들어봤는데 무슨 언어를 어떤 프레임웍스를 시작해서 라우트 넣어주고 코드 짜고 로그인 input 버튼 새로 알게 된것도 많았다데이터베이스 스키마 설계하고 어떤 데이터베이스를 쓸건지 crud 구현엔 어떤 데이터베이스를 쓸건지 crud 구현엔 mysql을 사용했고, rds를 사용했다. 또한, 시스템 전반에 가용성, 내결함성, 확장성, 보안성이 고려된 서비스들이 포함되어야 하는 인프라 요구사항을 충족하기 위해 다양한 AWS 서비스를 이용하였다. 이러한 인프라 구성과 함께, 시스템 메트릭 또는 저장된 데이터에 대한 하나 이상의 시각화된 모니터링 시스템도 구축하고 이제까지 배웠던걸 모두 합쳐서 해보니까 제대로 공부 하지못하지 않았나그래서 트러블슈팅을 할때도 에러도 gpt에게 너무 의존 했고 다른 레퍼런스찾아보고 팀원들에게 물어 보는게 문제 해결에 더 가까워 질 수 있을 것같다는 생각했다  혼자서 시간만 무지 써버렸다.협업에 깃이 중요하다고 말하듯이 이번에 깃 브런치를 따로 만들어서 작업을 진행했는데 이게 내 브런치에서 다른사람껄 가져오고 하면 충돌이 발생해서 포크한 레포를 지워버리고 다시 받기를 반복하고 점점 커밋도 안하게되어 현업을 잘 못한것같습니다 더 해봐야 할 것 같다kanban보드로 팀원이 지금 무슨 일을 하고 있는지 알수있어서 좋은 것같고 칸반을 작성안하면 뭐하는지 모르기 때문에 상황을 보기에 좋은 기능 같다 .문서화를 통한 기록은 팀 프로젝트에서 중요한 역할을 하는데, 이를 통해 정보의 공유와 협업을 원활하게 할 수 있으며, 팀원들의 업무 흐름을 파악하고 조율하는 데 도움이 되는 것 같다."
  },
  
  {
    "title": "파이널 회고 작성4",
    "url": "/posts/%ED%8C%8C%EC%9D%B4%EB%84%90-%ED%9A%8C%EA%B3%A0%EC%9E%91%EC%84%B1-4/",
    "categories": "writing",
    "tags": "",
    "date": "2023-06-28 00:00:00 +0900",
    





    
    "snippet": "✅ 서버리스 프레임워크로 람다 만들기serverless sqs worker 템플릿을 사용후 기록가져오는 람다 함수 작성db 접속 후 데이터 가져오기 성공sqs에 보내는 메세지를 실패해서 에러가 자꾸 뜸…sendMessage 부분에서 타임아웃거의 모든 시간을 람다와 보냈지만 해결 하지 못했는데 재환님이 해결하셨다… 자세한건 재환님 블로그를 봐야겠다..",
    "content": "✅ 서버리스 프레임워크로 람다 만들기serverless sqs worker 템플릿을 사용후 기록가져오는 람다 함수 작성db 접속 후 데이터 가져오기 성공sqs에 보내는 메세지를 실패해서 에러가 자꾸 뜸…sendMessage 부분에서 타임아웃거의 모든 시간을 람다와 보냈지만 해결 하지 못했는데 재환님이 해결하셨다… 자세한건 재환님 블로그를 봐야겠다.."
  },
  
  {
    "title": "파이널 회고 작성3",
    "url": "/posts/%ED%8C%8C%EC%9D%B4%EB%84%90-%ED%9A%8C%EA%B3%A0-%EC%9E%91%EC%84%B1-3/",
    "categories": "writing",
    "tags": "",
    "date": "2023-06-28 00:00:00 +0900",
    





    
    "snippet": "✅ 시각화된 모니터링 시스템이 구축시스템 메트릭 또는 저장된 데이터에 대한 하나 이상의 시각화된 모니터링 시스템이 구축되어야합니다.우리 아키텍처에서 병목구간이 생기는 지점 대회신청 구간이라고 생각  esc 백엔드 api 매트릭을 수집하기 위해서 ecs-exporter, cloudwatch-exporter,프로메테우스, 그라파나private ec2에 설...",
    "content": "✅ 시각화된 모니터링 시스템이 구축시스템 메트릭 또는 저장된 데이터에 대한 하나 이상의 시각화된 모니터링 시스템이 구축되어야합니다.우리 아키텍처에서 병목구간이 생기는 지점 대회신청 구간이라고 생각  esc 백엔드 api 매트릭을 수집하기 위해서 ecs-exporter, cloudwatch-exporter,프로메테우스, 그라파나private ec2에 설치🤔private ec2에 실행중인 그라파나 포트 4000 http://localhost:4000으로 연결후 접속되는걸 확인 로컬에서 실행하려면 어떻게 하는지 모르겠음참고한 레퍼런스 https://rohan-j-tiwari.medium.com/grafana-installation-on-amazon-private-ec2-instance-36dda72299d2프라이빗 서브넷에 있는 ec2에 연결해야 함으로 로드 밸런서를 만들어 줘야된다고 해서 따라 했는데 실페재환님이 로컬에서 cloudwatch insight를 통해서 그라파나로 시각화 할 수 있다고 했음 "
  },
  
  {
    "title": "파이널 회고 작성2",
    "url": "/posts/%ED%8C%8C%EC%9D%B4%EB%84%90-%ED%9A%8C%EA%B3%A0-%EC%9E%91%EC%84%B1/",
    "categories": "writing",
    "tags": "",
    "date": "2023-06-27 00:00:00 +0900",
    





    
    "snippet": "private subnet 에 있는 ec2 ssh 연결하기🤔 private subnet에 있는 mysql에 연결이 안된다.🤔 private subnet에 있는 ec2 ssh 접속이 안된다.모니터링을 구현할때 ecs-exporter, cloudwatch-exporter의 매트릭을 프로메테우스에서 가져와서 grafana를 이용해 시각화하려함.같은 vpc에...",
    "content": "private subnet 에 있는 ec2 ssh 연결하기🤔 private subnet에 있는 mysql에 연결이 안된다.🤔 private subnet에 있는 ec2 ssh 접속이 안된다.모니터링을 구현할때 ecs-exporter, cloudwatch-exporter의 매트릭을 프로메테우스에서 가져와서 grafana를 이용해 시각화하려함.같은 vpc에 설치하려고 ec2 인스턴스에 접속을 하려고 했었는데 당연히 private subnet에 연결할수가없었음✅  bastion같은 vpc의 서브넷들끼리는 nat gateway 통신 가능public subnet에 ec2를 생성 - public key 생성private subnet에 ec2를 생성 - private key 생성public ec2 ssh 접속후 private ec2 ssh 접속을 하기 위해 private key를 public ec2로 복사    scp -i [Bastion-EC2키페어경로] [업로드할파일] [user id]@[ec2 public IP]:[저장경로]private ec2 ssh 접속 완료"
  },
  
  {
    "title": "파이널 회고 작성",
    "url": "/posts/%ED%8C%8C%EC%9D%B4%EB%84%90-%ED%9A%8C%EA%B3%A0-%EC%9E%91%EC%84%B1-2/",
    "categories": "writing",
    "tags": "",
    "date": "2023-06-27 00:00:00 +0900",
    





    
    "snippet": "시나리오 1: 대회 결과 기록 시스템회사는 개인 사용자와 대회 주최자를 위한 마라톤 대회 결과 기록 시스템을 구축하려고 합니다.여러분은 회사 내 데브옵스 팀의 일원으로 인프라를 구축하고, 테스트 시스템을 구성해서 인프라 작동을 확인해야합니다.기능 요구사항  개인 사용자와 대회주최자는 로그인 기능을 통해 토큰을 발급받을 수 있습니다.토큰을 사용하는 로직...",
    "content": "시나리오 1: 대회 결과 기록 시스템회사는 개인 사용자와 대회 주최자를 위한 마라톤 대회 결과 기록 시스템을 구축하려고 합니다.여러분은 회사 내 데브옵스 팀의 일원으로 인프라를 구축하고, 테스트 시스템을 구성해서 인프라 작동을 확인해야합니다.기능 요구사항  개인 사용자와 대회주최자는 로그인 기능을 통해 토큰을 발급받을 수 있습니다.토큰을 사용하는 로직 구현이 어렵다면 유저 데이터베이스에 접근해서 일치하는 사용자 정보가 있는 것을 확인하는 것으로 대체  인증된 개인 사용자는 자신의 비공식 기록을 입력 및 조회할 수 있습니다.인증된 개인 사용자는 특정 대회에 참가 신청을 할 수 있습니다.  대회 주최자는 대회 참가자를 조회할 수 있습니다.  대회 주최자는 대회 참가자들에 대한 공식 기록을 입력 및 조회할 수 있습니다.  대회 주최자에 의해 입력된 공식 기록에 따라 해당 참가자의 point 데이터에 점수가 추가됩니다.예시 : 10km 참가자는 10점, half 참가자는 20점, full 참가자는 42점 추가개인 사용자는 점수를 확인할 수 있습니다.예시 : 전체 점수 또는 상위 몇개의 랭킹, 인증된 개인의 개별 점수    인프라 요구사항    시스템 전반에 가용성, 내결함성, 확장성, 보안성이 고려된 서비스들이 포함되어야 합니다.  하나 이상의 컴퓨팅 유닛에 대한 CI/CD 파이프라인이 구성되어야합니다.  유저 데이터를 저장하고 있는 유저 데이터베이스는 다른 데이터베이스와 분리되어있어야 합니다.  기록 데이터를 기반으로 사용자별 점수를 기록하는 시스템은 데이터 유실을 막기 위해 느슨하게 결합되어야합니다.  시스템 메트릭 또는 저장된 데이터에 대한 하나 이상의 시각화된 모니터링 시스템이 구축되어야합니다.아키텍처 다이어그램 완성"
  },
  
  {
    "title": "성능 테스트",
    "url": "/posts/2023-06-07/",
    "categories": "dev",
    "tags": "",
    "date": "2023-06-07 00:00:00 +0900",
    





    
    "snippet": "## 성능 테스트 발표 Q.AWS에서는 인스턴스나 볼륨에 대해서 버스트 기능을 제공합니다. 이는 평소에 사용하지 않을 때의 성능을 모아두고, 부하가 발생할 경우 일시적으로 성능을 올리는 기능입니다. 이것이 어떤 메커니즘으로 작동하는지 연구하세요.aws가 intel을 인수 하셨다Burstable Instance 버스트 가능 성능 인스턴스  간헐적으로 c...",
    "content": "## 성능 테스트 발표 Q.AWS에서는 인스턴스나 볼륨에 대해서 버스트 기능을 제공합니다. 이는 평소에 사용하지 않을 때의 성능을 모아두고, 부하가 발생할 경우 일시적으로 성능을 올리는 기능입니다. 이것이 어떤 메커니즘으로 작동하는지 연구하세요.aws가 intel을 인수 하셨다Burstable Instance 버스트 가능 성능 인스턴스  간헐적으로 cpu를 많이 사용하는 대부분의 범용 워크로드에 최적화      오토스케일을 안달거나 테스트용으로 잠시 cpu를 올릴때 크레딧만큼 성능을 올려준다 쓴만큼비용청구ec2같은경우 시간당 과금이 성능이 크레딧 만큼 올라간다 비용이 절감된다    필요한 경우 높은 수준의 cpu 사용을 무한정 유지할 수 있는 기능 디폴트 리미티드,언리미티드  적당한 cpu 사용량이 오퍼링에 포함 지속적으로 높은 cpu 사용량을 위해, 추가 cpu 크레딧도 다썼을때 쓴만큼 과금credit      cpu 기준 미만으로 유지되면 지속적으로 크레딧을 얻음        기준선 이상으로 버스트될때 크레딧을 지속적으로 소비        적립되거나 소비되는 크레딧 금액은 인스턴스의 cpu 사용률에 따라 달라짐  인스턴스 종류가 워낙 많아서 선택하는 것도 쉬운 일은 아니지만 서비스에 맞는 타입을 고르지 않으면 낭비되는 리소스가 발생하고 비용과 직결되는 부분이기 때문에 깊은 고민이 필요합니다.https://instances.vantage.sh/  위 사이트를 통해 ec2. 1년간의 비용을 알아보자  &lt;img width=\"1845\" alt=\"스크린샷 2023-06-07 오후 11 52 40\" src=\"https://github.com/leesanghoon94/leesanghoon94.github.io/assets/127801771/4f419f37-eb8e-4ea4-b013-0a7e4b4880da\"&gt; t2.micro  &lt;img width=\"1845\" alt=\"스크린샷 2023-06-07 오후 11 52 37\" src=\"https://github.com/leesanghoon94/leesanghoon94.github.io/assets/127801771/392e8ae0-2c0c-4d62-ab11-bc684b9d5bb8\"&gt; t3.xlarge인스턴스 디테일에 다른점이 많은데 자세한건 잘 모르겠다 파이널때 다시 이용해봐야겠다cpu utilization  가상화 공유 자원을 운용하는 클라우드 특성상 CPU가 1% ~ 100%를 넘나들며 사용량이 예측불가능한 서버들이 많아지게 되면 해당 가상서버가 아닌 물리적 자원을 공유하는 다른 서버에도 영향을 줄 수 있다. 그래서 CPU 사용률이 5~20% 이내로 유지되는 수준으로 서비스를 운영하고, 이를 넘어설 정도로 서비스가 커진다면 그에 걸맞는 높은 용량의 서버를 사용하도록 하는 것이다. 그래도 피크 시간대나 특정 작업에서 CPU가 많이 사용될 수 있으므로, 어느정도의 CPU 초과는 허용해주되, 많이는 초과하지 말라는 것이다.  정석대로라면 평균 CPU 사용률이 20%를 넘어가는 것은 바람직하지 않으므로, 바람직한 서버 운영을 도모한다고 볼 수도 있으나. 기존에 서버를 직접 운영하거나 가상서버 호스팅을 사용했을 떄에 비하면 사용자 입장에서 상당히 큰 제약이다. 기존엔 비수기엔 CPU가 1~2%대로 유지되다가 성수기나 이벤트 시기엔 20~30%정도로 몰릴 수도 있는데 그렇다고 서버거 과부화로 죽는 상황까진 이르지 않는다. 하지만 AWS의 이런 제약 아래선 성수기에 CPU가 높은 수준으로 며칠 이상 유지될 경우 CPU 버스트 크레딧이 모두 소진되어 갑자기 CPU 성능이 급감하고, 특정 서버의 성능이 급감을 하게 되면 연쇄적인 시스템 장애로 번질 수 있다. 실제로 이런 사고를 한번 겪고 나서 CPU 버스트에 대해 알게 되는 경우도 많다.  사용자는 당연히 CPU의 100%를 사용할 수 있을 것이라 생각하고 서비스를 신청했는데 실제로는 CPU의 10~20%밖에 못쓰도록 제한이 있는 것이니 과대포장 같은 느낌이기도 하다.baseline zone 40% 을 권장 50%이상으로 설정해놓으면 100%으로 금방된다 .https://itwiki.kr/w/AWS_CPU_%EB%B2%84%EC%8A%A4%ED%8A%B8  T 타입의 인스턴스는 쉽게 이야기하면 마치 인스턴스의 scale-up으로 표현할 수 있습니다. 인스턴스의 스펙을 (수직) 확장하기 위해서는 머신을 중지(STOP) 해야 하는 게 일반적인데요, T 타입은 baseline을 정해두고 CPU 사용률을 제한하다가 일시적으로 스파이크 치는 트래픽을 대응하기 위해 순간적으로 CPU 사용률을 높일 수 있습니다. 마치 scale-up 하는 것처럼요. 하지만 스케일업도 위에서 살펴본 것처럼 획득한 크레딧 내에서 일시적으로 가능한 수준입니다. 평소 트래픽이 많고 CPU 부하가 일정 수준 이상으로 유지되는 서비스라면 T 타입 인스턴스는 적합하지 않죠. 주기적인 배치 작업이나 특정 시점에만 트래픽이 몰리는 서비스, 혹은 밤에는 사용률이 거의 없다가 낮이 돼야 사용률이 올라가는 그런 서비스에 아주 적합하겠습니다.https://jybaek.tistory.com/916"
  },
  
  {
    "title": "모니터링",
    "url": "/posts/2023-06-04/",
    "categories": "dev",
    "tags": "",
    "date": "2023-06-05 00:37:41 +0900",
    





    
    "snippet": "서비스 디스커버리|  | pull | push || — | — | — || 장점 | 중앙 집중식 구성서비스 검색로드 관리 | 대기 시간 단축네트워크 경계 통과 용이 || 단점 | 네트워크 접근성대기 시간 증가 | 분산형 구성서비스 검색로드 관리 || 모니터링 도구 | 프로메테우스influxdb | aws cloudwatchgraphite |latenc...",
    "content": "서비스 디스커버리|  | pull | push || — | — | — || 장점 | 중앙 집중식 구성서비스 검색로드 관리 | 대기 시간 단축네트워크 경계 통과 용이 || 단점 | 네트워크 접근성대기 시간 증가 | 분산형 구성서비스 검색로드 관리 || 모니터링 도구 | 프로메테우스influxdb | aws cloudwatchgraphite |latencysresite reliability engineering시스템 안정성을 보장하기 위한 사고 방식직무 역일메트릭규범적 방범sre 의 주요 원칙error budgets 가용성의 양 오류가 발생했을때 오류 예산을 줄이기 위해scls (service level indicator) 대기시간slos(service level objective) sli의 지표값 slo는 비즈니스, 개발자 및 운영자가 합의한 일정한 기간 동안의 SLI 목표값slas(service level agreement) 100 - slo 값99.99, 99.95가 좋은거임cpu 사용량 50도 안넘기게 실무에선mttd 장애 인지 시간mtti 장애 식별mttr 장애 복구 시간kibanaopen search마이크로서비스 모니터링"
  },
  
  {
    "title": "프로메테우스란?",
    "url": "/posts/2023-06-02/",
    "categories": "dev",
    "tags": "",
    "date": "2023-06-02 21:18:41 +0900",
    





    
    "snippet": "프로메테우스p8s대표적인 오픈소스 모니터링, 경보 툴킷애플리케이션과 인프라가 어떻게 수행되고 있는지 분석할 수 있는 도구GO언어로 만들어짐promql 매우 간단한 쿼리 언어 사용  일기 전용  시계열에 저장된 모든 레이블에서 집계 가능분산 스토리지에 의존 하지 않음윈도우, 리눅스, MYSQl등의 기본 라이브러리와 서버 모두 프로케테우스를 이용할수있음g...",
    "content": "프로메테우스p8s대표적인 오픈소스 모니터링, 경보 툴킷애플리케이션과 인프라가 어떻게 수행되고 있는지 분석할 수 있는 도구GO언어로 만들어짐promql 매우 간단한 쿼리 언어 사용  일기 전용  시계열에 저장된 모든 레이블에서 집계 가능분산 스토리지에 의존 하지 않음윈도우, 리눅스, MYSQl등의 기본 라이브러리와 서버 모두 프로케테우스를 이용할수있음go,java 또는 scala, python, ruby 및 기타 여러 언어와 같이 PROMETheus 클라이언트 라이브러리를 통해 ㅗㅋ드 계측 추가 가능자체 ALERTMANAGER를 갖춘 본격적인 모니터링 시스템alert manager  정의된 규칙에서 벗어나면 경고가 발생  경고가 발생하면 조치를 취해야 함  프로메테우스 자체는 이 작업의 책임이 없음  이러한 규칙을 처리하기 위해target  스크랩하고 모니터ㅣㅇ하려는 메트릭이 있는 객체instance  스크랩하는 엔드포인트, 스크랩 하려는 주소job  동인한 목적을 가진 인스턴스 모음sample  시계열의 특정 시점에서 검색된 메트릭의 단일 값promtetheus 쿼릿 언어 -promql  selectors &amp;matchermatcher types  (=) : 제공된 문자열과 정확이 둥일한 레이블 선택operators 연산자  집계 연산자 : 정보를 결합하는 데 사용되는 특수 수학 함수  binorquanterpremetheus 쿼리 언어 PRImeql  function          rate      irate      changed      deriv      predict_;inear        주말에는 아키텍처 하나씩 깔아보기  nginx 인그레스 컨트롤러란?ChatGPTNginx Ingress Controller는 Kubernetes 클러스터 내에서 동작하는 오픈 소스 프로젝트입니다. 이 컨트롤러는 Ingress 리소스를 사용하여 클러스터 내부에 로드 밸런싱과 라우팅을 수행하는 역할을 합니다.Kubernetes에서 Ingress는 클러스터 외부에서 내부로의 HTTP 및 HTTPS 트래픽을 관리하기 위한 API 개체입니다. Ingress는 외부 요청을 적절한 백엔드 서비스로 전달하는 규칙을 정의할 수 있습니다. 그러나 Ingress 리소스 자체는 단순히 규칙을 정의하는 용도이며, 요청을 처리할 실제 로드 밸런서가 필요합니다. 이때 Nginx Ingress Controller가 사용됩니다.Nginx Ingress Controller는 Ingress 리소스에 정의된 라우팅 규칙을 기반으로 Nginx를 사용하여 로드 밸런싱 및 프록시 기능을 수행합니다. 클러스터 내부에 배포된 Nginx Ingress Controller는 외부로 들어오는 요청을 수신하고, 요청을 적절한 서비스로 라우팅하여 클러스터 내의 서비스에 접근할 수 있도록 합니다.또한, Nginx Ingress Controller는 프로메테우스(metrics)를 위한 엔드포인트를 노출하여 클러스터 내에서 Nginx의 성능 및 상태 정보를 수집할 수 있게 해줍니다. 이를 통해 모니터링 및 분석 도구인 프로메테우스가 Nginx의 메트릭 데이터를 수집하여 시각화하거나 경고를 생성할 수 있습니다."
  },
  
  {
    "title": "aws 모니터링 서비스",
    "url": "/posts/2023-06-01/",
    "categories": "dev",
    "tags": "",
    "date": "2023-06-02 21:13:06 +0900",
    





    
    "snippet": "cloudwatch  모니터링을 위한 시간 경과에 따른 메트릭  애플리케이션 로그 저장을 위한 로그  예상치 못한 메트릭 발생시 알림 전송aws x-ray  요금제 연간 구독  성능 병목(병목 현상)지점 식별  iam, 권한  서비스 문제 정확히 파악가능  api 요청 동작 검토  오류 및 예외 찾기  시간 SLA 를 준수하고 있는지 확인  어디가 스...",
    "content": "cloudwatch  모니터링을 위한 시간 경과에 따른 메트릭  애플리케이션 로그 저장을 위한 로그  예상치 못한 메트릭 발생시 알림 전송aws x-ray  요금제 연간 구독  성능 병목(병목 현상)지점 식별  iam, 권한  서비스 문제 정확히 파악가능  api 요청 동작 검토  오류 및 예외 찾기  시간 SLA 를 준수하고 있는지 확인  어디가 스로틀링되고 있는지 확인  영향을 받는 사용자 식별  자동화된 추적 분석 및 중앙서비스 맴 시각화  지연시간, 오류 및 결함 분석  분산된 시스템 전반의 요청 추적  호환되는 리소스          람다      엘라스틱 빈      aws cloudtrail  콘솔 계정 기본적으로 활성화  cli, sdk  s3에 저장해서 많이 씀  aws 계정에 대한 거버넌스, 규정 준수 및 감사 제공  90 days retention 90일유지  insights를 붙이면 ?  api 호출 감시  무단 호출 또는 변경의 근본 원인을 감지하는데 유용"
  },
  
  {
    "title": "프로젝트3 회고",
    "url": "/posts/2023-05-30/",
    "categories": "writing",
    "tags": "",
    "date": "2023-05-30 08:22:37 +0900",
    





    
    "snippet": "Day3평가항목  실습과제3 아키텍처 다이어그램 설명  평가질문지 답변  추가 시나리오 아키텍처 구성 설명클라이언트 Sales api 주문 재고 -1 데이터베이스 저장재고 0 일때 주문이 또 들어오면 sns 주문요청 메세지sqs 대기열 메세지를 factory api 가 읽고 생산factoryapi가 increase lambda에게 메세지를 보냄incr...",
    "content": "Day3평가항목  실습과제3 아키텍처 다이어그램 설명  평가질문지 답변  추가 시나리오 아키텍처 구성 설명클라이언트 Sales api 주문 재고 -1 데이터베이스 저장재고 0 일때 주문이 또 들어오면 sns 주문요청 메세지sqs 대기열 메세지를 factory api 가 읽고 생산factoryapi가 increase lambda에게 메세지를 보냄increase lambda가 데이터베이스에 재고 증가 저장Sqs      내구성있는 스토리지가 필요한 경우 큐를 쓴다        더 나은 내결함성을 확보하는 연결구조를 갖기 위해서                            standard          fifo                                      처리량이 높다          처리량 낮다                          비용 낮다          비용 높다                          최소 1회 중복처리될수도있음          순서대로 한번처리                    lambda  생성비용 없고 백만건 이후 함수 실행시간에따른 비용  람다는 자동으로 오토스케일링 서버리스Step 4 : 데이터베이스의 재고를 증가시키는 Lambda 함수 생성axios는 node.js에서 HTTP 명령을 보내는 라이브러리입니다. (fetch와 유사)  코드 맨 윗줄에 const axios = require('axios').default를 추가합니다.exports.handler = async (event) =&gt; {  const payload = {    MessageGroupId: \"stock-arrival-group\",    MessageAttributeProductId: \"e5b4bc11-faca-11ed-8f43-0e2f76dd43b0\",    MessageAttributeProductCnt: \"3\",    MessageAttributeFactoryId: \"FF-500293\",    MessageAttributeRequester: \"asdf\",    CallbackUrl: \"https://1ft5lpkkuj.execute-api.ap-northeast-2.amazonaws.com/product/donut\"  }    const result = await axios.post('http://project3-factory.coz-devops.click/api/manufactures', payload)  console.log(result)}"
  },
  
  {
    "title": "프로젝트3 회고",
    "url": "/posts/2023-05-29/",
    "categories": "writing",
    "tags": "",
    "date": "2023-05-30 03:52:33 +0900",
    





    
    "snippet": "Day2목표  메시지 큐의 Pub/Sub 패턴과 Producer/Consumer 패턴의 차이를 이해한다  DB와 서버와의 통신이 가능하도록 연결한다  특정 상황에서 SNS, SQS로 메시지가 전달되도록 시스템을 구성한다  SQS에 들어온 메시지를 레거시 시스템(Factory API)으로 전달하는 시스템을 구성한다  레거시 시스템(Factory API)...",
    "content": "Day2목표  메시지 큐의 Pub/Sub 패턴과 Producer/Consumer 패턴의 차이를 이해한다  DB와 서버와의 통신이 가능하도록 연결한다  특정 상황에서 SNS, SQS로 메시지가 전달되도록 시스템을 구성한다  SQS에 들어온 메시지를 레거시 시스템(Factory API)으로 전달하는 시스템을 구성한다  레거시 시스템(Factory API)의 콜백 대상이 되는 리소스를 생성해 데이터베이스에 접근할 수 있게 한다Lambda 서버(Sales API) - DB 연결HOSTNAME=project3db.cpajpop7ewnt.ap-northeast-2.rds.amazonaws.comUSERNAME=team0(0 대신 팀 번호)PASSWORD=team0(0 대신 팀 번호)DATABASE=team0(0 대신 팀 번호)      데이터베이스의 호스트네임, 유저네임, 비밀번호, 데이터베이스 를 수정 한다.        데이터베이스가 개별 제공됩니다. 로컬에서는 .env 파일을 활용하며, 배포 시에는 AWS 콘솔에서 직접 입력합니다. 코드에 credential을 넣지 않도록 주의하세요.  (advanced) serverless를 통해 lambda를 생성한다면 환경변수로 등록하는 방법을 고려해 볼 수 있습니다.“재고 없음” 메시지 전달 시스템 구성  DB에 재고가 없을 경우 재고가 없다는 정보를 알리기 위한 SNS 토픽(stock_empty) 생성  stock_empty 토픽을 구독하는 SQS(stock_queue) 생성  다음 code snippet을 활용하여 재고 부족 메시지를 SNS에 발행 await req.conn.end()      console.log(req.body)      const now = new Date().toString()      const message = `도너츠 재고가 없습니다. 제품을 생산해주세요! \\n메시지 작성 시각: ${now}`      const params = {        Message: message,        Subject: '도너츠 재고 부족',        MessageAttributes: {          MessageAttributeProductId: {            StringValue: product.product_id,            DataType: \"String\",          },          MessageAttributeFactoryId: {            StringValue: req.body.MessageAttributeFactoryId,            DataType: \"String\",          },          MessageAttributeProductCnt: {            StringValue: `${req.body.stock}`,            DataType: \"Number\",          },          MessageAttributeRequester: {            StringValue: req.body.requester,            DataType: \"String\",          }        },        TopicArn: process.env.TOPIC_ARN}console.log(\"보내는 메시지 결과물 : \", params)      await sns.publish(params).promise()      return res.status(200).json({ message: `구매 실패! 남은 재고: ${product.stock}, 생산요청 진행중`});ARN은 Amazon Resource Numbersns의 arn 을 적어준다 arn:aws:sns:ap-northeast-2:124121153800:stock-lambda"
  },
  
  {
    "title": "프로젝트3 회고",
    "url": "/posts/2023-05-26/",
    "categories": "writing",
    "tags": "",
    "date": "2023-05-26 21:34:13 +0900",
    





    
    "snippet": "Day1목표  Serveless를 이용한 AWS 리소스 생성  메시지 Queue가 사용되는 구조 이해Tutorial - Step 1service: tutorial-step-1    #Root propertiesframeworkVersion: '3'provider:                   #ProviderGeneral settings      ...",
    "content": "Day1목표  Serveless를 이용한 AWS 리소스 생성  메시지 Queue가 사용되는 구조 이해Tutorial - Step 1service: tutorial-step-1    #Root propertiesframeworkVersion: '3'provider:                   #ProviderGeneral settings                            name: aws  runtime: nodejs18.x                            #리전 변경 ap-northeast-2 (default: us-east-1)  region: ap-northeast-2   functions:  api:​    handler: index.handler​    events:​      \\- httpApi:​          path: /​          method: post 배포 버킷서버리스 프레임워크는 배포용 아티팩트를 저장하기 위해 S3 버킷이 필요합니다. 해당 버킷은 Serverless에서 자동으로 생성되고 관리되지만 필요한 경우 명시적으로 구성할 수 있습니다.  추가 도전과제: body가 { input: 숫자 } 가 맞는지 검증하고, 검증에 실패하면 응답코드 400 및 에러 메시지를 반환하는 코드를 넣어봅시다.$ curl -X POST https://API_GATEWAY_ID.execute-api.ap-northeast-2.amazonaws.com \\--header 'Content-type: application/json' \\--data-raw '{ \"input\": 1 }'      -x 옵션은 cURL이 프록시 서버를 통해 요청을 전송할 때 사용되는 옵션입니다. “x”는 “proxy”의 줄임말로, 프록시 서버와 관련된 옵션을 나타냅니다.        –header ‘Content-type: application/json’은 요청 헤더에 포함될 내용으로, 이 경우 Content-type 헤더를 application/json으로 설정하여 요청 본문이 JSON 형식임을 명시합니다.        –data-raw ‘{ “input”: 1 }’은 요청 본문에 포함될 데이터입니다. 여기서는 JSON 형식으로 { “input”: 1 }을 전송합니다. 이는 서버에 1이라는 입력 값을 포함하는 JSON 데이터를 보내는 것을 의미합니다.  Step 2: Serverless를 이용한 Lambda - SQS - Lambda 구조 생성service: tutorial-step-2frameworkVersion: '3'provider:  name: aws  runtime: nodejs18.x  region: ap-northeast-2constructs:  jobs:    type: queue    worker:      handler: index.consumerfunctions:  producer:    handler: index.producer    events:      - httpApi:          method: post          path: /produce    environment:      QUEUE_URL: ${construct:jobs.queueUrl}plugins:  - serverless-liftSQS 대기열 배포위의 예는 기존 SQS 대기열에서 메시지를 사용하는 방법을 보여줍니다. SQS 대기열을 생성하려면 serverless.yml사용자 지정 CloudFormation을 작성하거나 Lift를 사용할 수 있습니다. Lift 는 “ 구축 “ 을 통해 애플리케이션 배포를 단순화하는 서버리스 프레임워크 플러그인입니다. 리프트는 다음을 통해 설치할 수 있습니다. queue구성을 사용하여 Lambda 소비자와 함께 SQS 대기열을 배포 할 수 있습니다. 구성은 다음 queue을 배포합니다.SQS 대기열Lambda worker함수: 이 함수는 대기열로 전송된 메시지를 처리합니다.SQS “ 데드 레터 큐 “: 이 큐는 처리에 실패한 모든 메시지를 저장합니다.queue구성 설명서를 읽고 코드가 있는 전체 예제를 찾고 배치 크기, 재시도 및 기타 옵션을 구성하는 방법을 알아보세요.https://www.serverless.com/framework/docs/providers/aws/events/sqs#deploying-sqs-queuesTODO: Step 1을 참고하여, +1 를 하는 코드를 넣으세요프로듀서를 여러 번 반복해서 실행쉘 스크립트의 반복문을 이용해 반복적으로 실행할 수 있습니다.DLQ 연결 및 K6 성능테스트,Visibility Timeout 조절과 DLQconsumer에 실행 시간을 늘리는 코드 추가function delay(time) {  return new Promise(resolve =&gt; setTimeout(resolve, time));}const consumer = async (event) =&gt; {  await delay(15000) // 15초 딜레이  for (const record of event.Records) {    // 생략  }}queue의 visibility timeout 을 잘 못 설정하면 두개 이상의 컨슈머가 소비하게 되는 상황 메세지 내용이 금융거래와 같은 메세지라면 중복으로 처리하면 문제 람다 함수 실행시간이 15초인데 큐의 visibility timeout이 15초 보다 작다면 람다 함수가 실행되기전에 큐는 실패 처리를 해서 dlq로 메세지를 넘겨 버리게 된다.요구사항 분석 및 초기 다이어그램 작성"
  },
  
  {
    "title": "인스턴스 스토어와 EBS 볼륨의 차이점은 무엇인가요? ",
    "url": "/posts/2023-05-23/",
    "categories": "dev",
    "tags": "",
    "date": "2023-05-23 23:56:52 +0900",
    





    
    "snippet": "인스턴스 스토어와 EBS 볼륨의 차이점은 무엇인가요?Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스와 연결된 데이터를 저장하고 싶습니다. 인스턴스 스토어를 사용해야 하는지 아니면 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용해야 하는지 잘 모르겠습니다.차이점데이터를 영속적으로...",
    "content": "인스턴스 스토어와 EBS 볼륨의 차이점은 무엇인가요?Amazon Elastic Compute Cloud(Amazon EC2) 인스턴스와 연결된 데이터를 저장하고 싶습니다. 인스턴스 스토어를 사용해야 하는지 아니면 연결된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 사용해야 하는지 잘 모르겠습니다.차이점데이터를 영속적으로 저장하는 것이 가능합니다.해결 방법일부 Amazon EC2 인스턴스 유형은 직접 연결된 블록 디바이스 스토리지 형태인 인스턴스 스토어라는 스토리지를 제공합니다. 인스턴스 스토어를 임시 스토리지로 사용하세요. 인스턴스 스토어 볼륨에 저장된 데이터는 인스턴스 중지, 종료 또는 하드웨어 장애 시 유지되지 않습니다.데이터를 장기적으로 유지하거나 암호화하려는 경우에는 Amazon EBS 볼륨을 사용하세요. EBS 볼륨에는 다음과 같은 특징이 있습니다.EBS 볼륨은 인스턴스 중지 및 종료 시에도 데이터를 보존합니다.EBS 스냅샷으로 EBS 볼륨을 백업할 수 있습니다.한 인스턴스에서 EBS 볼륨을 제거하고 다른 인스턴스에 다시 연결할 수 있습니다.EBS 볼륨은 전체 볼륨 암호화를 지원합니다.의도하지 않은 변경이나 데이터 손실을 방지하려면 스냅샷을 자주 생성하는 것이 좋습니다. AWS Backup을 사용하여 스냅샷 생성을 자동화할 수 있습니다.참고: Amazon EBS에서는 인스턴스의 루트 볼륨에 대한 DeleteOnTermination 속성이 기본적으로 true로 설정됩니다. 이 속성을 변경하지 않으면 인스턴스가 종료될 때 인스턴스의 루트 볼륨이 삭제됩니다https://repost.aws/ko/knowledge-center/instance-store-vs-ebs볼륨컨테이너 내의 디스크에 있는 파일은 임시적이며, 컨테이너에서 실행될 때 애플리케이션에 적지 않은 몇 가지 문제가 발생한다. 한 가지 문제는 컨테이너가 크래시될 때 파일이 손실된다는 것이다. kubelet은 컨테이너를 다시 시작하지만 초기화된 상태이다. 두 번째 문제는 Pod에서 같이 실행되는 컨테이너간에 파일을 공유할 때 발생한다Stateful한 애플리케이션을 관리하려면파드 명세에 PV를 정의해서 직접 연결하는 것은 좋은 방법이 아닙니다.  Q. 왜 파드와 PV를 직접 연결하는 것이 좋지 않은가요?  파드와 PV(영구 볼륨)를 직접 연결하는 것은 보통 권장되지 않습니다. 이는 파드와 PV 간의 결합을 느슨하게 유지하여 애플리케이션을 더 유연하게 관리하기 위함입니다. 다음은 파드와 PV를 직접 연결하는 것이 권장되지 않는 이유입니다:  결합도와 유연성: 파드와 PV를 직접 연결하면 파드가 특정 PV에 종속되어 해당 PV를 사용할 수 있는 파드에만 스케줄링될 수 있습니다. 이는 파드의 결합도를 높이고 유연성을 제한할 수 있습니다. 만약 다른 PV로 마이그레이션하려는 경우, 모든 파드를 다시 스케줄링해야 할 수도 있습니다.  리소스 활용: 파드와 PV를 분리함으로써 여러 파드가 동일한 PV를 공유할 수 있습니다. 이는 리소스 활용을 향상시킬 수 있습니다. 예를 들어, 여러 파드가 동일한 PV를 통해 데이터를 읽고 쓸 수 있으며, PV의 용량을 최대한 활용할 수 있습니다.  스토리지 관리: PV를 중앙에서 관리하고 파드는 스토리지에 대한 세부 사항을 알 필요가 없도록 분리하는 것이 유리합니다. 이를 통해 스토리지 관리 및 유지보수 작업을 보다 효율적으로 수행할 수 있습니다. PV를 독립적으로 관리하면 스토리지 클래스, 볼륨 스냅샷, 보안 등과 같은 스토리지 관련 기능을 쉽게 구성하고 관리할 수 있습니다.  호환성과 이식성: 파드와 PV 사이의 중간 계층인 볼륨 추상화 계층을 유지함으로써, 다양한 스토리지 백엔드와의 호환성 및 이식성을 갖출 수 있습니다. PV가 파드와 직접 결합되지 않으면 클라우드 공급자나 스토리지 시스템 변경 시에도 애플리케이션을 쉽게 이식하고 업그레이드할 수 있습니다.  요약하면, 파드와 PV를 직접 연결하는 것은 결합도를 높이고 유연성을 제한할 수 있으며, 리소스 활용과 스토리지 관리의 효율성을 저하시킬 수 있습니다.이때 이러한 의존도를 줄이기 위해, 퍼시스턴스 볼륨 클레임(Persistence Volume Claim, 이하 PVC)을 이용하여 PV와 연결합니다. PVC는 파드가 볼륨의 세부 사항을 몰라도 볼륨을 사용할 수 있게 도와줍니다.PV는 실제로 데이터가 저장되는 공간입니다.PVC는 PV를 선택, 연결해 주는 요청 그 자체입니다.  Q. PVC는 어떻게 작동되나요?이 문서에서는 수명이 긴 데이터가 필요한 애플리케이션을 위한 클러스터 범위의 영구 스토리지를 관리하기 위한 모델을 제안합니다.PV는 클러스터 리소스이다. PVC는 해당 리소스에 대한 요청이며 리소스에 대한 클레임 검사 역할을 한다. PV와 PVC 간의 상호 작용은 다음 라이프사이클을 따른다.추상적인두 가지 새로운 API 종류:A PersistentVolume(PV)는 관리자가 프로비저닝한 스토리지 리소스입니다. 노드와 유사합니다. 사용 방법은 Persistent Volume Guide를 참조하십시오 .A PersistentVolumeClaim(PVC)는 포드에서 사용할 영구 볼륨에 대한 사용자의 요청입니다. pod와 유사합니다.클러스터 관리자는 스토리지클래스(StorageClasses)를 사용하여 동적 프로비저닝을 설정할 수도 있다.파드는 퍼시스턴트볼륨클레임을 사용하여 물리적인 스토리지를 요청한다.퍼시스턴트볼륨에 자동으로 바인딩파드는 클레임을 볼륨으로 사용한다. 클러스터는 클레임을 검사하여 바인딩된 볼륨을 찾고 해당 볼륨을 파드에 마운트한다. 여러 접근 모드를 지원하는 볼륨의 경우 사용자는 자신의 클레임을 파드에서 볼륨으로 사용할 때 원하는 접근 모드를 지정한다.일단 사용자에게 클레임이 있고 그 클레임이 바인딩되면, 바인딩된 PV는 사용자가 필요로 하는 한 사용자에게 속한다. 사용자는 파드의 volumes 블록에 persistentVolumeClaim을 포함하여 파드를 스케줄링하고 클레임한 PV에 접근한다. 이에 대한 자세한 내용은 볼륨으로 클레임하기를 참고하길 바란다.https://github.com/kubernetes/design-proposals-archive/blob/main/storage/persistent-storage.mdhttps://kubernetes.io/ko/docs/concepts/storage/persistent-volumes/"
  },
  
  {
    "title": "쿠버네티스 / namespace",
    "url": "/posts/2023-05-22/",
    "categories": "dev",
    "tags": "",
    "date": "2023-05-23 03:47:10 +0900",
    





    
    "snippet": "쿠버네티스 / namespace  클러스터 하나를 여러 개의 논리 적인 단위로 나눠서 사용  쿠버네티스 클러스터 하나를 여러 팀이나 사용자가 함계 공유  용도에 따라 실행해야 하는 앱을 구분할때 사용마스터 워커노드네임스페이스 사용하기namespace 생성      cli        yaml  namespace 관리getdelete네임스페이스 4개가 ...",
    "content": "쿠버네티스 / namespace  클러스터 하나를 여러 개의 논리 적인 단위로 나눠서 사용  쿠버네티스 클러스터 하나를 여러 팀이나 사용자가 함계 공유  용도에 따라 실행해야 하는 앱을 구분할때 사용마스터 워커노드네임스페이스 사용하기namespace 생성      cli        yaml  namespace 관리getdelete네임스페이스 4개가 기본으로 설정쿠버네티스 운영에 필요한 네임 스페이스base namespace 는 default디폴트 네임스페이스를 변경할수있다기본으로 사용하는 namespace를 default가 아닌 다른 이름의 namespcae 로 switch  namespace를 포함한 context 등록          kubectl config set-context  —cluster= —namespace=      kubectl config  view        등록된 namespce로 context 변경          kubectl config use-context NAME      "
  },
  
  {
    "title": "쿠버네티스 컴포넌트",
    "url": "/posts/2023-05-19/",
    "categories": "dev",
    "tags": "",
    "date": "2023-05-19 23:46:10 +0900",
    





    
    "snippet": "쿠버네티스 컴포넌트쿠버네티스를 배포하면 클러스터를 얻는다.쿠버네티스 클러스터는 컨테이너화된 애플리케이션을 실행하는 노드라고 하는 워커 머신의 집합. 모든 클러스터는 최소 한 개의 워커 노드를 가진다.워커 노드는 애플리케이션의 구성요소인 파드를 호스트한다. 컨트롤 플레인은 워커 노드와 클러스터 내 파드를 관리한다. 프로덕션 환경에서는 일반적으로 컨트롤 ...",
    "content": "쿠버네티스 컴포넌트쿠버네티스를 배포하면 클러스터를 얻는다.쿠버네티스 클러스터는 컨테이너화된 애플리케이션을 실행하는 노드라고 하는 워커 머신의 집합. 모든 클러스터는 최소 한 개의 워커 노드를 가진다.워커 노드는 애플리케이션의 구성요소인 파드를 호스트한다. 컨트롤 플레인은 워커 노드와 클러스터 내 파드를 관리한다. 프로덕션 환경에서는 일반적으로 컨트롤 플레인이 여러 컴퓨터에 걸쳐 실행되고, 클러스터는 일반적으로 여러 노드를 실행하므로 내결함성과 고가용성이 제공된다.이 문서는 완전히 작동하는 쿠버네티스 클러스터를 갖기 위해 필요한 다양한 컴포넌트들에 대해 요약하고 정리한다.쿠버네티스 클러스터 구성 요소워크로드워크로드는 쿠버네티스에서 구동되는 애플리케이션이다. 워크로드가 단일 컴포넌트이거나 함께 작동하는 여러 컴포넌트이든 관계없이, 쿠버네티스에서는 워크로드를 일련의 파드 집합 내에서 실행한다. 쿠버네티스에서 Pod 는 클러스터에서 실행 중인 컨테이너 집합을 나타낸다.쿠버네티스 파드에는 정의된 라이프사이클이 있다. 예를 들어, 일단 파드가 클러스터에서 실행되고 나서 해당 파드가 동작 중인 노드에 심각한 오류가 발생하면 해당 노드의 모든 파드가 실패한다. 쿠버네티스는 이 수준의 실패를 최종(final)으로 취급한다. 사용자는 향후 노드가 복구되는 것과 상관 없이 Pod 를 새로 생성해야 한다.그러나, 작업이 훨씬 쉽도록, 각 Pod 를 직접 관리할 필요는 없도록 만들었다. 대신, 사용자를 대신하여 파드 집합을 관리하는 워크로드 리소스 를 사용할 수 있다. 이러한 리소스는 지정한 상태와 일치하도록 올바른 수의 올바른 파드 유형이 실행되고 있는지 확인하는 컨트롤러를 구성한다.쿠버네티스 워크로드상태를 체크 -&gt; 차이점발견 -&gt; 조치를 하는 무한루프라고 생각하면 된다.desired state상태 체크 observe현재 상태 == 원하는 상태current state == desired state차이점 발견 diff현재 상태 ≠ 원하는 상태current state ≠ desired state조치 act현재 상태 → 원하는 상태current state → desired state상태 체크는 scheduler서버가 여러개면 스케줄러를 따로api server 는 교통 정리같은 일을 한다etcd 데이터베이스의 역할 기록해놓는다cdc (change date capture) 데이터값이 변한것만 기록한다.master 상세 -etcd모든 상태와 데이터를 저장분산 시스템으로 구성하여 안전성을 높임(고가용성)가볍고 빠르면서 정확하게 설계(일관성)key(directory)-value 형태로 데이터 저장ttl(time to live), watch 같은 부가 기능 제공백업은 필수 (회사에서 자체적으로 버전을 백업해놓고 저장한다고 한다.)master 상세 -api server쿠버네티스가 자랑하는 잘만든 서버상태를 바꾸거나 조회etcd와 유일하게 통신하는 모듈rest api 형태로 제공권한을 체크하여 적절한 권한이 없을 경우 요청을 차단관리자 요청 뿐통제는 controller managercontroller논리적으로 다양한 컨트롤러가 존재복제, 노드, 엔드 포인트끊임 없이 상태를 체크하고 원하는 상태를 유지예를들어      replication controller        endpoint controller        namespace controller        custom controller        mlcontroller  "
  },
  
  {
    "title": "미니큐브",
    "url": "/posts/2023-05-18/",
    "categories": "dev",
    "tags": "",
    "date": "2023-05-18 23:37:33 +0900",
    





    
    "snippet": "미니큐브 시작minikube는 쿠버네티스를 쉽게 배우고 개발할 수 있도록 하는 데 중점을 둔 로컬 쿠버네티스입니다.필요한 것은 Docker(또는 이와 유사하게 호환되는) 컨테이너 또는 가상 머신 환경이며 Kubernetes는 단일 명령입니다.minikube start필요한 것  CPU 2개 이상  2GB의 여유 메모리  20GB의 여유 디스크 공간  ...",
    "content": "미니큐브 시작minikube는 쿠버네티스를 쉽게 배우고 개발할 수 있도록 하는 데 중점을 둔 로컬 쿠버네티스입니다.필요한 것은 Docker(또는 이와 유사하게 호환되는) 컨테이너 또는 가상 머신 환경이며 Kubernetes는 단일 명령입니다.minikube start필요한 것  CPU 2개 이상  2GB의 여유 메모리  20GB의 여유 디스크 공간  인터넷 연결  컨테이너 또는 가상 머신 관리자(예: Docker , QEMU , Hyperkit , Hyper-V , KVM , Parallels , Podman , VirtualBox 또는 VMware Fusion/Workstation )##필요한 것  CPU 2개 이상  2GB의 여유 메모리  20GB의 여유 디스크 공간  인터넷 연결  컨테이너 또는 가상 머신 관리자(예: Docker , QEMU , Hyperkit , Hyper-V , KVM , Parallels , Podman , VirtualBox 또는 VMware Fusion/Workstation )설치Homebrew 패키지 관리자 가 설치된 경우 :brew install minikube복사양조를 통한 설치 후 실패 하면 which minikube이전 minikube 링크를 제거하고 새로 설치된 바이너리를 연결해야 할 수 있습니다.brew unlink minikubebrew link minikube클러스터 시작관리자 액세스 권한이 있는 터미널에서(루트로 로그인하지 않음) 다음을 실행합니다.minikube start클러스터와 상호 작용kubectl이 이미 설치되어 있으면 이제 이를 사용하여 반짝이는 새 클러스터에 액세스할 수 있습니다.kubectl get po -A복사또는 minikube에서 적절한 버전의 kubectl을 다운로드하여 다음과 같이 사용할 수 있습니다.minikube kubectl -- get po -A복사쉘 구성에 다음을 추가하여 삶을 더 쉽게 만들 수도 있습니다.alias kubectl=\"minikube kubectl --\"복사처음에는 storage-provisioner와 같은 일부 서비스가 아직 Running 상태가 아닐 수 있습니다. 이는 클러스터를 불러오는 동안 정상적인 상태이며 일시적으로 해결됩니다. 클러스터 상태에 대한 추가 통찰력을 위해 Minikube는 Kubernetes 대시보드를 번들로 제공하므로 새로운 환경에 쉽게 적응할 수 있습니다.minikube dashboard애플리케이션 배포  서비스  로드밸런서  입구샘플 배포를 만들고 포트 8080에 노출합니다.kubectl create deployment hello-minikube --image=kicbase/echo-server:1.0kubectl expose deployment hello-minikube --type=NodePort --port=8080시간이 다소 걸릴 수 있지만 다음을 실행하면 배포가 곧 표시됩니다.kubectl get services hello-minikube이 서비스에 액세스하는 가장 쉬운 방법은 minikube가 웹 브라우저를 실행하도록 하는 것입니다.minikube service hello-minikube또는 kubectl을 사용하여 포트를 전달합니다.kubectl port-forward service/hello-minikube 7080:8080짜잔! 이제 http://localhost:7080/ 에서 애플리케이션을 사용할 수 있습니다 .애플리케이션 출력에서 요청 메타데이터를 볼 수 있어야 합니다. 요청 경로를 변경하고 변경 사항을 관찰하십시오. 마찬가지로 POST 요청을 수행하고 본문이 출력에 표시되는 것을 관찰할 수 있습니다.클러스터 관리배포된 애플리케이션에 영향을 주지 않고 Kubernetes를 일시 중지합니다.minikube pause일시중지된 인스턴스를 일시중지 해제합니다.minikube unpause클러스터를 중지합니다.minikube stop기본 메모리 제한 변경(다시 시작해야 함):minikube config set memory 9001쉽게 설치되는 Kubernetes 서비스의 카탈로그를 찾아보십시오.minikube addons list이전 Kubernetes 릴리스를 실행하는 두 번째 클러스터를 만듭니다.minikube start -p aged --kubernetes-version=v1.16.1모든 minikube 클러스터를 삭제합니다.minikube delete --all출처https://minikube.sigs.k8s.io/docs/start/설치 에러덮어쓰기 해줬다.brew link --overwrite kubernetes-cli"
  },
  
  {
    "title": "쿠버네티스란 무엇인가?",
    "url": "/posts/2023-05-17/",
    "categories": "dev",
    "tags": "",
    "date": "2023-05-17 23:25:23 +0900",
    





    
    "snippet": "2023-05-18쿠버네티스란 무엇인가?쿠버네티스는 컨테이너화된 워크로드와 서비스를 관리하기 위한 이식성이 있고, 확장가능한 오픈소스 플랫폼이다. 쿠버네티스는 선언적 구성과 자동화를 모두 용이하게 해준다.쿠버네티스는 전통적인, 모든 것이 포함된 Platform as a Service(PaaS)가 아니다. 쿠버네티스는 하드웨어 수준보다는 컨테이너 수준에...",
    "content": "2023-05-18쿠버네티스란 무엇인가?쿠버네티스는 컨테이너화된 워크로드와 서비스를 관리하기 위한 이식성이 있고, 확장가능한 오픈소스 플랫폼이다. 쿠버네티스는 선언적 구성과 자동화를 모두 용이하게 해준다.쿠버네티스는 전통적인, 모든 것이 포함된 Platform as a Service(PaaS)가 아니다. 쿠버네티스는 하드웨어 수준보다는 컨테이너 수준에서 운영되기 때문에, PaaS가 일반적으로 제공하는 배포, 스케일링, 로드 밸런싱과 같은 기능을 제공하며, 사용자가 로깅, 모니터링 및 알림 솔루션을 통합할 수 있다. 하지만, 쿠버네티스는 모놀리식(monolithic)이 아니어서, 이런 기본 솔루션이 선택적이며 추가나 제거가 용이하다. 쿠버네티스는 개발자 플랫폼을 만드는 구성 요소를 제공하지만, 필요한 경우 사용자의 선택권과 유연성을 지켜준다.이것은 일부 대표적인 Container Orchestration Platform 애플리케이션의 예시입니다. Container Orchestration Platform은 계속 발전하고 새로운 솔루션이 등장할 수 있으므로, 현재의 상태에 대한 최신 정보를 확인하는 것이 중요합니다.  Kubernetes: 가장 널리 사용되는 컨테이너 오케스트레이션 플랫폼으로, 컨테이너화된 애플리케이션의 배포, 관리, 확장을 담당합니다.  Docker Swarm: Docker 컨테이너 클러스터링과 오케스트레이션 플랫폼으로, Docker 컨테이너의 배포 및 관리를 위한 기능을 제공합니다.  Apache Mesos: 대규모 클러스터 관리를 위한 오픈 소스 플랫폼으로, 다양한 작업로드(컨테이너, 가상 머신 등)를 관리하고 스케줄링합니다.  Nomad: HashiCorp에서 개발한 오픈 소스 작업 스케줄러로, 다양한 유형의 작업(컨테이너, 가상 머신, 스크립트 등)을 관리하고 배포합니다.  OpenShift: Red Hat에서 개발한 Kubernetes 기반의 PaaS 플랫폼으로, 애플리케이션의 빌드, 배포, 관리를 위한 통합 도구와 기능을 제공합니다.  Amazon Elastic Kubernetes Service (EKS): Amazon Web Services (AWS)에서 제공하는 완전 관리형 Kubernetes 서비스로, Kubernetes 클러스터를 간편하게 배포하고 운영할 수 있습니다.  Google Kubernetes Engine (GKE): Google Cloud의 완전 관리형 Kubernetes 서비스로, Google 인프라에서 Kubernetes 클러스터를 관리하고 배포할 수 있습니다.쿠버네티스가 왜 필요하고 무엇을 할 수 있나  서비스 디스커버리와 로드 밸런싱  스토리지 오케스트레이션  자동화된 롤아웃과 롤백  자동화된 빈 패킹(bin packing)  자동화된 복구(self-healing)  시크릿과 구성 관리### 대형 클러스터에 대한 고려 사항클러스터는 컨트롤 플레인에서 관리하는 쿠버네티스 에이전트를 실행하는 노드(물리 또는 가상 머신)의 집합이다. 쿠버네티스 v1.27는 노드 5,000개까지의 클러스터를 지원한다. 보다 정확하게는, 쿠버네티스는 다음 기준을 모두 만족하는 설정을 수용하도록 설계되었다.  노드 당 파드 110 개 이하  노드 5,000개 이하  전체 파드 150,000개 이하  전체 컨테이너 300,000개 이하노드를 추가하거나 제거하여 클러스터를 확장할 수 있다. 이를 수행하는 방법은 클러스터 배포 방법에 따라 다르다.출처https://kubernetes.io/ko/docs/home/"
  },
  
  {
    "title": "serverless Lambda",
    "url": "/posts/2023-05-11/",
    "categories": "dev",
    "tags": "",
    "date": "2023-05-11 23:38:34 +0900",
    





    
    "snippet": "서비스로서의 컴포넌트화AWS LambdaFaaS (function as a service)함수로써 서비스를 제공 한다.  AWS console 에서 함수 생성후 트리거 해서 함수를 호출  sam-cli 를 통해서 로컬에서 함수 생성, 템플릿을 이용해서 build, deploy 를 할 수 있다.템플릿 사이트  serverless  serverlessla...",
    "content": "서비스로서의 컴포넌트화AWS LambdaFaaS (function as a service)함수로써 서비스를 제공 한다.  AWS console 에서 함수 생성후 트리거 해서 함수를 호출  sam-cli 를 통해서 로컬에서 함수 생성, 템플릿을 이용해서 build, deploy 를 할 수 있다.템플릿 사이트  serverless  serverlessland템플릿이 잘되어있어서 코딩을 못하는 저도 스프린트1을 끝낼수있었다.람다의 요금 책정 방식이 궁금하면 밑에 공식 홈페이지를 보세요 , 실무에서 람다 요금 계산을 할 수도있다고 한다.https://aws.amazon.com/ko/lambda/pricing/AWS Lambda는 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있는 서버리스 컴퓨팅 서비스입니다. 워크로드 인식 클러스터 크기 조정 로직을 생성하고 이벤트 통합을 유지 관리하며 간편하게 런타임을 관리합니다. Lambda에서는 사실상 모든 유형의 애플리케이션이나 백엔드 서비스에 대한 코드를 별도의 관리 없이 실행할 수 있으며, 사용한 만큼만 비용을 지불합니다. 함수 요청 수와 코드를 실행하는 데 걸리는 기간에 따라 요금이 청구됩니다."
  },
  
  {
    "title": "macOS IP 확인하는 방법",
    "url": "/posts/2023-05-10/",
    "categories": "dev",
    "tags": "mac",
    "date": "2023-05-10 17:38:08 +0900",
    





    
    "snippet": "macOS IP 확인하는 방법% ipconfig getifaddr en0curl http://ipconfig.me",
    "content": "macOS IP 확인하는 방법% ipconfig getifaddr en0curl http://ipconfig.me"
  },
  
  {
    "title": "대체 마이크로 서비스가 뭔가?",
    "url": "/posts/2023-05-09/",
    "categories": "dev",
    "tags": "msa",
    "date": "2023-05-09 21:00:06 +0900",
    





    
    "snippet": "오늘은 마이크로서비스로 쪼개는 방법론 이론적인 배경을 배웠습니다대체 마이크로 서비스가 뭔가?모놀리틱이랑 이랑 모놀리식이랑 다른점“모놀리틱”과 “모놀리식”은 같은 의미를 갖는 용어입니다. 이 용어는 하나의 큰 소프트웨어 시스템을 묘사하는 데 사용됩니다.모놀리식 소프트웨어 시스템은 하나의 큰 응용 프로그램으로 구성되어 있습니다. 이러한 응용 프로그램은 일...",
    "content": "오늘은 마이크로서비스로 쪼개는 방법론 이론적인 배경을 배웠습니다대체 마이크로 서비스가 뭔가?모놀리틱이랑 이랑 모놀리식이랑 다른점“모놀리틱”과 “모놀리식”은 같은 의미를 갖는 용어입니다. 이 용어는 하나의 큰 소프트웨어 시스템을 묘사하는 데 사용됩니다.모놀리식 소프트웨어 시스템은 하나의 큰 응용 프로그램으로 구성되어 있습니다. 이러한 응용 프로그램은 일반적으로 여러 개의 모듈로 구성됩니다. 모듈은 서로 강하게 결합되어 있으며, 일부 모듈의 수정이 다른 모듈의 기능을 영향을 줄 수 있습니다. 또한, 모듈 간에 공유하는 데이터베이스나 라이브러리 등이 있을 수 있습니다.  반면에 모놀리틱 소프트웨어 시스템은 “모놀리식”과 같은 의미를 갖지만, 주로 분산 시스템에서 사용됩니다. 이러한 시스템은 하나의 대규모 응용 프로그램으로 구성될 수 있지만, 일반적으로 서로 다른 기능을 수행하는 여러 개의 서비스로 구성됩니다. 이러한 서비스는 독립적으로 배포되고 실행될 수 있으며, 서로 다른 서비스를 호출하여 작업을 수행할 수 있습니다.따라서, 모놀리식과 모놀리틱은 같은 의미를 가지지만, 모놀리틱은 보통 분산 시스템에서 사용되며, 모놀리식은 하나의 대규모 응용 프로그램으로 구성된다는 것을 강조합니다.도메인 주도 개발      마이크로서비스를 어떤 기준으로 쪼개야 되는가에 대한        도메인 주도 개발을 통해서 어떤 도메인을 한정해서 거대란 서비스가 쪼개졌을때 마이크로서비스가 의미가 있다.        https://miro.com/ 을 이용해 이벤트 드리븐 아키텍처(Event-Driven Architecture, EDA)을 만들어봤다..  서비스간 어떻게 통신하는지동기 커뮤니케이션              http - 요청 응답만 있는 -비동기 커뮤니케이션          메세지 큐  느슨한결합일수록 커뮤니케이션 더 잘해야됨"
  },
  
  {
    "title": "두가지 패턴의 프로세스 간 통신 (IPC)",
    "url": "/posts/2023-05-08/",
    "categories": "dev",
    "tags": "",
    "date": "2023-05-08 23:08:40 +0900",
    





    
    "snippet": "두가지 패턴의 프로세스 간 통신 (IPC)일반적인 모놀리식에서 같은 앱 내에서 함수를 호출함으로써 다른 서비스를 호출할 수 있었다면 msa로 바뀌면서 함수를 호출하는 방식이 api 통신으로 바뀌고 하나의 서비스들을 하나의 서버에서 돌아가는 프로세스라고 부른다면 이통신을 IPC 통신이라고함  동기 커뮤니케이션  애플리케이션 -&gt; 애플리케이션  주문...",
    "content": "두가지 패턴의 프로세스 간 통신 (IPC)일반적인 모놀리식에서 같은 앱 내에서 함수를 호출함으로써 다른 서비스를 호출할 수 있었다면 msa로 바뀌면서 함수를 호출하는 방식이 api 통신으로 바뀌고 하나의 서비스들을 하나의 서버에서 돌아가는 프로세스라고 부른다면 이통신을 IPC 통신이라고함  동기 커뮤니케이션  애플리케이션 -&gt; 애플리케이션  주문 서비스 -&gt; 배송 서비스  비동기 커뮤니케이션(이벤트 기반)  애플리케이션 -&gt; 큐 -&gt; 애플리케이션  주문 서비스 -&gt; 큐 -&gt; 배송 서비스msa에 유리한 비동기적 방식을 구현할때 큐를 사용하게됨큐(Queue)의 개념—      컴퓨터의 기본적인 자료 구조의 한가지로, 먼저 집어 넣은 데이터가 먼저 나오는 FIFO(First In First Out)구조로 저장하는 형식        queue라는 영단어 자체가 티켓 등의 표따위를 구매하기 위해 줄을 서는 것을 의미합니다.        데이터가 들어오는 위치는 대기열의 가장 뒤에서 들어오고 그것을 Rear 혹은 back 이라고 합니다.    데이터가 나가는 위치는 대기열의 가장 앞이고 이를 Front라고 하고, 때문에 가장 먼저 들어노는 데이터가 먼저 나가게 됩니다.  우선순위 큐, 원형 큐 등의 큐의 변화적인 형태들이 존재합니다.  입력은 Enqueue 라고 하며 출력은 Dequeue    라고 표현, fornt에 위치한 데이터 조회는 Peek로 읽습니다.https://gmlwjd9405.github.io/2018/08/02/data-structure-queue.html느슨한 결합(loose coupling)이 주는 장점  프로세스간의 의존성을 줄일 수 있음          시스템을 유지보수하기 쉽게 만듦      시스템의 유연성이 증가됨      보다 쉽게 서비스를 테스트할 수 있음      일부 시스템의 실패가 전체 시스템의 실패로 이어지지 않음        프로그래밍 세계에서는 항상 느슨한 결합이 주된 관심사          UI: 컴포넌트화(frontend에서 각각의 ui가 연관성 없이 따로 동작한다.)      객체 지향 프로그래밍: 의존성 주입(DEpendency Ingection)      마이크로서비스: 메세징 시스템을 이용한 비동기 커뮤니케이션      "
  },
  
  {
    "title": "마크다운 markdown 작성법",
    "url": "/posts/2023-05-07-markdown/",
    "categories": "dev",
    "tags": "",
    "date": "2023-05-07 20:56:16 +0900",
    





    
    "snippet": "마크다운 markdown 작성법  영어지만, 조금 더 상세하게 마크다운 사용법을 안내하고 있는  “Markdown Guide (https://www.markdownguide.org/)” 를 보시는 것을 추천합니다. ^^  아, 그리고 마크다운만으로 표현이 부족하다고 느끼신다면, HTML 태그를 활용하시는 것도 좋습니다.1. 마크다운에 관하여1.1. 마...",
    "content": "마크다운 markdown 작성법  영어지만, 조금 더 상세하게 마크다운 사용법을 안내하고 있는  “Markdown Guide (https://www.markdownguide.org/)” 를 보시는 것을 추천합니다. ^^  아, 그리고 마크다운만으로 표현이 부족하다고 느끼신다면, HTML 태그를 활용하시는 것도 좋습니다.1. 마크다운에 관하여1.1. 마크다운이란?Markdown은 텍스트 기반의 마크업언어로 2004년 존그루버에 의해 만들어졌으며 쉽게 쓰고 읽을 수 있으며 HTML로 변환이 가능하다. 특수기호와 문자를 이용한 매우 간단한 구조의 문법을 사용하여 웹에서도 보다 빠르게 컨텐츠를 작성하고 보다 직관적으로 인식할 수 있다.마크다운이 최근 각광받기 시작한 이유는 깃헙(https://github.com) 덕분이다. 깃헙의 저장소Repository에 관한 정보를 기록하는 README.md는 깃헙을 사용하는 사람이라면 누구나 가장 먼저 접하게 되는 마크다운 문서였다. 마크다운을 통해서 설치방법, 소스코드 설명, 이슈 등을 간단하게 기록하고 가독성을 높일 수 있다는 강점이 부각되면서 점점 여러 곳으로 퍼져가게 된다.1.2. 마크다운의 장-단점1.2.1. 장점1. 간결하다.2. 별도의 도구없이 작성가능하다.3. 다양한 형태로 변환이 가능하다.4. 텍스트(Text)로 저장되기 때문에 용량이 적어 보관이 용이하다.5. 텍스트파일이기 때문에 버전관리시스템을 이용하여 변경이력을 관리할 수 있다.6. 지원하는 프로그램과 플랫폼이 다양하다.1.2.2. 단점1. 표준이 없다.2. 표준이 없기 때문에 도구에 따라서 변환방식이나 생성물이 다르다.3. 모든 HTML 마크업을 대신하지 못한다.2. 마크다운 사용법(문법)2.1. 헤더Headers  큰제목: 문서 제목      This is an H1  =============        This is an H1  =============    작은제목: 문서 부제목      This is an H2  -------------        This is an H2  ————-    글머리: 1~6까지만 지원    # This is a H1## This is a H2### This is a H3#### This is a H4##### This is a H5###### This is a H6        This is a H1    This is a H2    This is a H3    This is a H4    This is a H5    This is a H6    ####### This is a H7(지원하지 않음)  2.2. BlockQuote이메일에서 사용하는 &gt; 블럭인용문자를 이용한다.&gt; This is a first blockqute.&gt;\t&gt; This is a second blockqute.&gt;\t&gt;\t&gt; This is a third blockqute.  This is a first blockqute.\t&gt; This is a second blockqute.\t&gt;\t&gt; This is a third blockqute.이 안에서는 다른 마크다운 요소를 포함할 수 있다.  This is a H3      List        code            2.3. 목록● 순서있는 목록(번호)순서있는 목록은 숫자와 점을 사용한다.1. 첫번째2. 두번째3. 세번째  첫번째  두번째  세번째현재까지는 어떤 번호를 입력해도 순서는 내림차순으로 정의된다.1. 첫번째3. 세번째2. 두번째  첫번째  세번째  두번째딱히 개선될 것 같지는 않다. 존 그루버가 신경안쓰고 있다고…● 순서없는 목록(글머리 기호: *, +, - 지원)* 빨강  * 녹색    * 파랑+ 빨강  + 녹색    + 파랑- 빨강  - 녹색    - 파랑  빨강          녹색                  파랑                      빨강          녹색                  파랑                      빨강          녹색                  파랑                    혼합해서 사용하는 것도 가능하다(내가 선호하는 방식)* 1단계  - 2단계    + 3단계      + 4단계  1단계          2단계                  3단계                          4단계                                          2.4. 코드4개의 공백 또는 하나의 탭으로 들여쓰기를 만나면 변환되기 시작하여 들여쓰지 않은 행을 만날때까지 변환이 계속된다.2.4.1. 들여쓰기This is a normal paragraph:    This is a code block.    end code block.실제로 적용해보면,적용예:This is a normal paragraph:This is a code block.end code block.*****  한줄 띄어쓰지 않으면 인식이 제대로 안되는 문제가 발생합니다.This is a normal paragraph:    This is a code block.end code block.적용예:This is a normal paragraph:    This is a code block.end code block.*****2.4.1. 코드블럭코드블럭은 다음과 같이 2가지 방식을 사용할 수 있습니다:  &lt;pre&gt;&lt;code&gt;{code}&lt;/code&gt;&lt;/pre&gt; 이용방식&lt;pre&gt;&lt;code&gt;public class BootSpringBootApplication {  public static void main(String[] args) {    System.out.println(\"Hello, Honeymon\");  }}&lt;/code&gt;&lt;/pre&gt;public class BootSpringBootApplication {  public static void main(String[] args) {    System.out.println(\"Hello, Honeymon\");  }}  코드블럭코드(“```”) 을 이용하는 방법```public class BootSpringBootApplication {  public static void main(String[] args) {    System.out.println(\"Hello, Honeymon\");  }}```public class BootSpringBootApplication {  public static void main(String[] args) {    System.out.println(\"Hello, Honeymon\");  }}깃헙에서는 코드블럭코드(“```”) 시작점에 사용하는 언어를 선언하여 문법강조(Syntax highlighting)이 가능하다.```javapublic class BootSpringBootApplication {  public static void main(String[] args) {    System.out.println(\"Hello, Honeymon\");  }}```public class BootSpringBootApplication {  public static void main(String[] args) {    System.out.println(\"Hello, Honeymon\");  }}2.5. 수평선 &lt;hr/&gt;아래 줄은 모두 수평선을 만든다. 마크다운 문서를 미리보기로 출력할 때 페이지 나누기 용도로 많이 사용한다.* * *********- - ----------------------------------------  적용예            *      2.6. 링크  참조링크[link keyword][id][id]: URL \"Optional Title here\"// codeLink: [Google][googlelink][googlelink]: https://google.com \"Go google\"Link: Google  외부링크    사용문법: [Title](link)적용예: [Google](https://google.com, \"google link\")        Link: Google        자동연결```일반적인 URL 혹은 이메일주소인 경우 적절한 형식으로 링크를 형성한다.    외부링크: http://example.com/      이메일링크: address@example.com```    외부링크: http://example.com/  이메일링크: address@example.com2.7. 강조*single asterisks*_single underscores_**double asterisks**__double underscores__~~cancelline~~  single asterisks  single underscores  double asterisks  double underscores  cancelline  문장 중간에 사용할 경우에는 **띄어쓰기** 를 사용하는 것이 좋다. 문장 중간에 사용할 경우에는 띄어쓰기를 사용하는 것이 좋다.2.8. 이미지![Alt text](/path/to/img.jpg)![Alt text](/path/to/img.jpg \"Optional title\")사이즈 조절 기능은 없기 때문에 &lt;img width=\"\" height=\"\"&gt;&lt;/img&gt;를 이용한다.예&lt;img src=\"/path/to/img.jpg\" width=\"450px\" height=\"300px\" title=\"px(픽셀) 크기 설정\" alt=\"RubberDuck\"&gt;&lt;/img&gt;&lt;br/&gt;&lt;img src=\"/path/to/img.jpg\" width=\"40%\" height=\"30%\" title=\"px(픽셀) 크기 설정\" alt=\"RubberDuck\"&gt;&lt;/img&gt;&lt;/img&gt;&lt;/img&gt;2.9. 줄바꿈3칸 이상 띄어쓰기( )를 하면 줄이 바뀐다.* 줄 바꿈을 하기 위해서는 문장 마지막에서 3칸이상을 띄어쓰기해야 한다. 이렇게* 줄 바꿈을 하기 위해서는 문장 마지막에서 3칸이상을 띄어쓰기해야 한다.___\\\\ 띄어쓰기이렇게      줄 바꿈을 하기 위해서는 문장 마지막에서 3칸이상을 띄어쓰기해야 한다. 이렇게        줄 바꿈을 하기 위해서는 문장 마지막에서 3칸이상을 띄어쓰기해야 한다.    이렇게  3. 마크다운 사용기3.1. 위지윅(WSYWIG) 에디터우리가 흔하게 접하는 웹에서 사용되는 에디터(네이버, 다음, 구글 등)이 대부분 위지윅 에디터에 속하며 기본적으로 HTML을 이용하여 스타일을 적용하여 문장을 꾸미는 형태를 취하게 된다. 그래서 하루패드와 같은 마크다운 에디터의 View 영역의 내용을 복사하여 붙여넣기를 하면 대체적으로 View영역에서 보이는 그대로 복사되는 편이다. 다만, 붙여넣기 이후에 문장들을 수정하려고 할 때 문제가 되는데, 이는 스타일이 포함된 태그가 수정과정에서 변형되면서 전체적인 영향을 끼치는 탓이다. 티스토리 블로그에서는 쉽지 않고… 워드프레스의 경우에는 마크다운으로 작성된 포스트를 HTML로 변환해주는 기능을 활용하는 것이 좋다.결론은, 복사해서 붙여넣기하면 가급적이면 본문은 수정하지 않는 것이 좋다.3.2. 깃헙Github, 비트버킷Bitbucket과 요비Yobi 등최근 유행하는 협업개발플랫폼의 경우에는 마크다운을 변환하는 컨버터 기능을 기본탑재하고 있기 때문에 마크다운 문법으로 작성한 텍스트를 그대로 복사해서 붙여넣거나 업로드하는 것만으로 마크다운의 적용이 가능하다.3.3. MS워드 적용View 영역의 항목을 그대로 붙여넣거나 HTML 내보내기 등으로 생성한 파일을 불러오는 형태로 사용가능하다. 적용한 헤더를 워드가 읽어드리면서 목차에 적용하기 때문에 이를 활용하면 목차까지도 손쉽게 적용이 가능해진다.4. 정리마크다운은 기본문법만 알고있다면 일반 텍스트편집기에서도 손쉽게 작성이 가능한 마크업언어다. 현재 다양한 도구와 플랫폼에서 지원하고 있기 때문에 더욱 손쉽게 스타일적용된 문서를 작성할 수 있어 점점 널리 사용되고 있다.  마크다운을 이해하고 사용하면서 쉽고 빠르게 스타일문서를 작성해보세요.저는 Dropbox 프로를 구매해서 집-랩탑-스마트폰이 각각 연동을 시켜서 사용하고 있습니다. 드랍박스에 저장된 마크다운 문서는 Dropbox 웹서비스 상에서 제공하기 때문에 웹상에서 바로 열람할 수도 있어 링크를 걸어서 다른 사람과 공유하는 형식으로 사용하고 있다.  링크 예: Markdown 설명P.S.최근에는 여러 기능이 포함되며 무거워지는Notion 을 대신해서 옵시디언(Obsidian) 조금씩 사용중이다. Notion 에서 작성한 문서는 Atom(https://atom.io/), Visual Studio Code(https://code.visualstudio.com/), Notepad++(https://notepad-plus-plus.org/)텍스트 편집기에 복붙(복사하고 붙여넣기)하면 마크다운문법으로 작성된 문장이 기입되고 이지윅 에디터를 제공하는 웹에디터에 붙여넣기 하면 거의 완벽한 형태로 복사된다. 그래서 애용중이다.○ 참고문서  78 Tools for writing and previewing Markdown  John gruber 마크다운 번역  깃허브 취향의 마크다운 번역  허니몬의 마크다운 작성법  Notion.so(https://www.notion.so/product)  Atom(https://atom.io/)  Visual Studio Code(https://code.visualstudio.com/)  Notepad++(https://notepad-plus-plus.org/)"
  },
  
  {
    "title": "aws ACM 무한 대기중",
    "url": "/posts/aws-acm-%EB%AC%B4%EA%B8%B0%EC%A4%91/",
    "categories": "dev",
    "tags": "",
    "date": "2023-04-18 00:00:00 +0900",
    





    
    "snippet": "인증서의 상태가..?!  click 도메인을 사고 클라우드프론트 배포까지 하고 클린업할때 발급받은 인증서를 지웠다가 다시 클라우드 배포 할 일이 생겨서 다시 인증을 요청한 상태  클린업을 하면서 vpc 호스팅 영역도 같이 지운상태Amazon Route 53에서 퍼블릭 호스팅 영역에 대해 생성하는 NS 및 SOA 레코드Amazon Route 53는 생성...",
    "content": "인증서의 상태가..?!  click 도메인을 사고 클라우드프론트 배포까지 하고 클린업할때 발급받은 인증서를 지웠다가 다시 클라우드 배포 할 일이 생겨서 다시 인증을 요청한 상태  클린업을 하면서 vpc 호스팅 영역도 같이 지운상태Amazon Route 53에서 퍼블릭 호스팅 영역에 대해 생성하는 NS 및 SOA 레코드Amazon Route 53는 생성하는 각 퍼블릭 호스팅 영역에 대해 NS(이름 서버) 레코드 및 SOA(권한 시작) 레코드를 자동으로 생성합니다. 이러한 레코드는 거의 변경할 필요가 없습니다.https://docs.aws.amazon.com/ko_kr/Route53/latest/DeveloperGuide/SOA-NSrecords.htmlNS(이름 서버) 레코드Amazon Route 53는 호스팅 영역과 이름이 동일한 NS(이름 서버) 레코드를 자동으로 생성하고, 호스팅 영역에 대한 신뢰할 수 있는 이름 서버 네 개를 나열합니다. 드문 경우를 제외하고 이 레코드에서 이름 서버를 추가, 변경 또는 삭제하지 않는 것이 좋습니다.다음 예는 Route 53 이름 서버의 이름 형식을 보여줍니다(이것은 예시일 뿐이므로 등록자의 이름 서버 레코드를 업데이트할 때 사용하면 안 됩니다).  ns-2048.awsdns-64.com  ns-2049.awsdns-65.net  ns-2050.awsdns-66.org  ns-2051.awsdns-67.co.ukvpc 지웠다 다시 생성했으므로 전에 만들었던 ns 주소가 달라졌기에 검증이 무한 대기중이라 생각![Alt text](image-5.png)aws 호스팅 영역을 지웠다가 다시 생성했던 사람은 ns의 값이 바뀐다바뀐 ns 값을 edit 해주면 acm 검증이 바로 될줄알았는데... 안돼서 도메인 하나 샀다;;"
  },
  
  {
    "title": "자바스크립트 동작원리",
    "url": "/posts/%EC%9E%90%EB%B0%94%EC%8A%A4%ED%81%AC%EB%A6%BD%ED%8A%B8-%EB%8F%99%EC%9E%91%EC%9B%90%EB%A6%AC/",
    "categories": "dev",
    "tags": "",
    "date": "2023-04-16 00:00:00 +0900",
    





    
    "snippet": "코드 잘짜고 싶으면 문법말고 브라우저 동작원리도 …⚠️ 왜 .js, .css 을 해석해주는게 브라우저 이니까print(1+1)time.sleep(1)print(2+2)한줄 한줄 코드 실행해준다console(1+1)setTimeout(function(){ console.log(2+2) }, 1000)console.log(3+3) &lt; 자바스크립트는 ...",
    "content": "코드 잘짜고 싶으면 문법말고 브라우저 동작원리도 …⚠️ 왜 .js, .css 을 해석해주는게 브라우저 이니까print(1+1)time.sleep(1)print(2+2)한줄 한줄 코드 실행해준다console(1+1)setTimeout(function(){ console.log(2+2) }, 1000)console.log(3+3) &lt; 자바스크립트는 병렬처리가 안된다…바로 실행이 안되는 setTimeoutdms는 Queue 대기 &gt;&lt; 자바스크립트가 queue에 보내는 코드들 &gt;"
  }
  
]

