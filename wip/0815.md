엘라스틱서치 비밀번호

kubectl get secrets --namespace=default elasticsearch-master-credentials -ojsonpath='{.data.password}' | base64 -d

---

오픈소스를 활용한 모니터링

Prometheus
시스템 이벤트 모니터링 및 경고를 제공하는 시계열 오픈소스 모니터링
pull 방식의 데이터 수집 push 방식도 가능
각 서버는 안정성을 위해 독립적이며 로컬 저장소에만 의존
Promql을 통한 강력한

메트릭 수집 구조
pull type
온디맨드형태
push type
지표를 주기적으로 쏘는

---

데이터 검색

검색 쿼리 또는 쿼리는 Elasticsearch 데이터 스트림 또는 인덱스의 데이터에 대한 정보를 요청하는 것입니다.

쿼리는 Elasticsearch가 이해하는 방식으로 작성된 질문으로 생각할 수 있습니다. 데이터에 따라 쿼리를 사용하여 다음과 같은 질문에 대한 답변을 얻을 수 있습니다.

내 서버에서 응답하는 데 500밀리초 이상 걸리는 프로세스는 무엇입니까?
내 네트워크의 어떤 사용자가 지난 주에 regsvr32.exe를 실행했습니까?
내 웹사이트의 어떤 페이지에 특정 단어나 문구가 포함되어 있나요?
Elasticsearch는 여러 검색 방법을 지원합니다.

정확한 값 검색 search for exact values
숫자, 날짜, IP 또는 문자열의 정확한 값이나 범위를 검색합니다.
전체 텍스트 검색 full-text search
전체 텍스트 쿼리를 사용하여 구조화되지 않은 텍스트 데이터를 쿼리하고 쿼리 용어와 가장 잘 일치하는 문서를 찾습니다.
벡터 검색 vector search
Elasticsearch에 벡터를 저장하고 ANN(근접 이웃) 또는 kNN(k-최근접 이웃) 검색을 사용하여 유사한 벡터를 찾고 의미 체계 검색과 같은 사용 사례를 지원합니다.

---

분석

인덱스 분석 모듈은 문자열 필드를 다음과 같은 개별 용어로 변환하는 데 사용할 수 있는 구성 가능한 분석기 레지스트리 역할을 합니다.

문서를 검색 가능하게 만들기 위해 반전된 색인에 추가됨
일치 쿼리와 같은 상위 수준 쿼리에서 검색어를 생성하는 데 사용됩니다.
구성 세부정보는 텍스트 분석을 참조하세요.

---

인덱스 샤드 할당
index shard allocation

이 모듈은 노드에 대한 샤드 할당을 제어하기 위한 인덱스별 설정을 제공합니다.

샤드 할당 필터링: 어떤 샤드가 어떤 노드에 할당되는지 제어합니다.
지연 할당: 노드 이탈로 인해 할당되지 않은 샤드의 할당이 지연됩니다.
노드당 총 샤드: 노드당 동일한 인덱스의 샤드 수에 대한 엄격한 제한입니다.
데이터 계층 할당: 데이터 계층에 대한 인덱스 할당을 제어합니다.

---

인덱스 수준 샤드 할당 필터링
편집하다
샤드 할당 필터를 사용하여 Elasticsearch가 특정 인덱스의 샤드를 할당하는 위치를 제어할 수 있습니다. 이러한 인덱스별 필터는 클러스터 전체 할당 필터링 및 할당 인식과 함께 적용됩니다.

샤드 할당 필터는 사용자 정의 노드 속성 또는 내장된 \_name, \_host_ip, \_publish_ip, \_ip, \_host, \_id, \_tier 및 \_tier_preference 속성을 기반으로 할 수 있습니다. 인덱스 수명 주기 관리는 사용자 정의 노드 속성을 기반으로 하는 필터를 사용하여 단계 간 이동할 때 샤드를 재할당하는 방법을 결정합니다.

Cluster.routing.allocation 설정은 동적이므로 기존 인덱스를 한 노드 집합에서 다른 노드 집합으로 즉시 이동할 수 있습니다. 샤드는 동일한 노드에 기본 샤드와 복제본 샤드를 할당하지 않는 등 다른 라우팅 제약 조건을 위반하지 않고 가능한 경우에만 재배치됩니다.

예를 들어 사용자 정의 노드 속성을 사용하여 노드의 성능 특성을 나타내고 샤드를 사용할 수 있습니다. 특정 인덱스에 대한 샤드를 가장 적절한 하드웨어 클래스로 라우팅하는 할당 필터링.

---

인덱스 수준 샤드 할당 필터링 활성화편집
사용자 정의 노드 속성을 기준으로 필터링하려면 다음을 수행하십시오.

1. 각 노드의 elasticsearch.yml 구성 파일에서 사용자 정의 노드 속성을 사용하여 필터 특성을 지정합니다. 예를 들어 소형, 중형, 대형 노드가 있는 경우 노드 크기를 기준으로 필터에 크기 속성을 추가할 수 있습니다.

node.attr.size: 중간
노드를 시작할 때 사용자 정의 속성을 설정할 수도 있습니다.

./bin/elasticsearch -Enode.attr.size=medium  
2. 인덱스에 라우팅 할당 필터를 추가합니다. index.routing.allocation 설정은 세 가지 유형의 필터(포함, 제외, 필수)를 지원합니다. 예를 들어 Elasticsearch에 테스트 인덱스의 샤드를 대형 또는 중형 노드에 할당하도록 지시하려면 index.routing.allocation.include를 사용하세요.

PUT 테스트/\_설정
{ "index.routing.allocation.include.size": "큰, 중간"
}

컬로 복사
Elastic에서 사용해 보세요
&nbsp;
여러 필터를 지정하는 경우 샤드가 다음 조건을 동시에 충족해야 합니다. 그곳으로 옮겨지세요:

요구 유형 조건이 지정된 경우 해당 조건을 모두 충족해야 합니다.
제외 유형 조건이 지정된 경우 해당 조건 중 어느 것도 충족되지 않을 수 있습니다.
포함 유형 조건이 지정된 경우 해당 조건 중 하나 이상을 충족해야 합니다.
예를 들어, 테스트 인덱스를 랙1의 큰 노드로 이동하려면 다음을 지정할 수 있습니다.

````console
PUT test/_settings
{
  "index.routing.allocation.require.size": "big",
  "index.routing.allocation.require.rack": "rack1"
}```
---
인덱스 할당 필터 설정편집
index.routing.allocation.include.{속성}
{attribute}에 쉼표로 구분된 값이 하나 이상 포함된 노드에 인덱스를 할당합니다.
index.routing.allocation.require.{속성}
{attribute}에 쉼표로 구분된 값이 모두 포함된 노드에 인덱스를 할당합니다.
index.routing.allocation.exclude.{속성}
{attribute}에 쉼표로 구분된 값이 없는 노드에 인덱스를 할당합니다.
인덱스 할당 설정은 다음과 같은 기본 제공 속성을 지원합니다.

_이름

노드 이름으로 노드 일치

_호스트_ip

호스트 IP 주소(호스트 이름과 연결된 IP)로 노드 일치

_publish_ip

게시 IP 주소로 노드 일치

_ip

_host_ip 또는 _publish_ip와 일치

_주인

호스트 이름으로 노드 일치

_ID

노드 ID로 노드 일치

_층

노드의 데이터 계층 역할에 따라 노드를 일치시킵니다. 자세한 내용은 데이터 계층 할당 필터링을 참조하세요.

_tier 필터링은 노드 역할을 기반으로 합니다. 역할의 하위 집합만 데이터 계층 역할이며 일반 데이터 역할은 모든 계층과 일치합니다. 필터링.

 속성 값을 지정할 때 와일드카드를 사용할 수 있습니다. 예를 들면 다음과 같습니다.

 PUT 테스트/_설정
 { "index.routing.allocation.include._ip": "192.168.2.*"
 }
---

검색 API

검색은 결합되어 Elasticsearch로 전송되는 하나 이상의 쿼리로 구성됩니다. 검색 쿼리와 일치하는 문서는 응답의 히트 또는 검색 결과로 반환됩니다.

검색에는 쿼리를 더 잘 처리하는 데 사용되는 추가 정보가 포함될 수도 있습니다. 예를 들어, 검색은 특정 인덱스로 제한되거나 특정 개수의 결과만 반환될 수 있습니다.

검색 API를 사용하여 Elasticsearch 데이터 스트림이나 인덱스에 저장된 데이터를 검색하고 집계할 수 있습니다. API의 쿼리 요청 본문 매개변수는 Query DSL로 작성된 쿼리를 허용합니다.

---

집계
편집하다
집계는 데이터를 지표, 통계 또는 기타 분석으로 요약합니다. 집계는 다음과 같은 질문에 답하는 데 도움이 됩니다.

내 웹사이트의 평균 로드 시간은 얼마나 됩니까?
거래량을 기준으로 볼 때 가장 가치 있는 고객은 누구입니까?
내 네트워크에서 대용량 파일로 간주되는 것은 무엇입니까?
각 제품 카테고리에는 몇 개의 제품이 있나요?

Elasticsearch는 집계를 다음 세 가지 범주로 구성합니다.

필드 값에서 합계 또는 평균과 같은 지표를 계산하는 지표 집계입니다.
필드 값, 범위 또는 기타 기준에 따라 문서를 버킷(빈이라고도 함)으로 그룹화하는 버킷 집계입니다.
문서나 필드 대신 다른 집계에서 입력을 받는 파이프라인 집계입니다.

---
```
curl -X GET "localhost:9200/_search?pretty"
{
  "took" : 144,
  "timed_out" : false,
  "_shards" : {
    "total" : 4,
    "successful" : 4,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 4684,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "books",
        "_id" : "PdCJVpEBDU2D85kaarYB",
        "_score" : 1.0,
        "_source" : {
          "name" : "Snow Crash",
          "author" : "Neal Stephenson",
          "release_date" : "1992-06-01",
          "page_count" : 470
        }
      },
      {
        "_index" : "books",
        "_id" : "PtCKVpEBDU2D85kaebbc",
        "_score" : 1.0,
        "_source" : {
          "name" : "Revelation Space",
          "author" : "Alastair Reynolds",
          "release_date" : "2000-03-15",
          "page_count" : 585
        }
      },
      {
        "_index" : "books",
        "_id" : "P9CKVpEBDU2D85kaebbc",
        "_score" : 1.0,
        "_source" : {
          "name" : "1984",
          "author" : "George Orwell",
          "release_date" : "1985-06-01",
          "page_count" : 328
        }
      },
      {
        "_index" : "books",
        "_id" : "QNCKVpEBDU2D85kaebbc",
        "_score" : 1.0,
        "_source" : {
          "name" : "Fahrenheit 451",
          "author" : "Ray Bradbury",
          "release_date" : "1953-10-15",
          "page_count" : 227
        }
      },
      {
        "_index" : "books",
        "_id" : "QdCKVpEBDU2D85kaebbc",
        "_score" : 1.0,
        "_source" : {
          "name" : "Brave New World",
          "author" : "Aldous Huxley",
          "release_date" : "1932-06-01",
          "page_count" : 268
        }
      },
      {
        "_index" : "books",
        "_id" : "QtCKVpEBDU2D85kaebbc",
        "_score" : 1.0,
        "_source" : {
          "name" : "The Handmaids Tale",
          "author" : "Margaret Atwood",
          "release_date" : "1985-06-01",
          "page_count" : 311
        }
      },
      {
        "_index" : "data",
        "_id" : "1",
        "_score" : 1.0,
        "_source" : {
          "count" : 5
        }
      },
      {
        "_index" : "kibana_sample_data_ecommerce",
        "_id" : "XoVTVZEBaBqnt6dm2-I0",
        "_score" : 1.0,
        "_source" : {
          "category" : [
            "Women's Accessories",
            "Women's Clothing"
          ],
          "currency" : "EUR",
          "customer_first_name" : "rania",
          "customer_full_name" : "rania Evans",
          "customer_gender" : "FEMALE",
          "customer_id" : 24,
          "customer_last_name" : "Evans",
          "customer_phone" : "",
          "day_of_week" : "Sunday",
          "day_of_week_i" : 6,
          "email" : "rania@evans-family.zzz",
          "manufacturer" : [
            "Tigress Enterprises"
          ],
          "order_date" : "2024-08-25T14:16:48+00:00",
          "order_id" : 583581,
          "products" : [
            {
              "base_price" : 10.99,
              "discount_percentage" : 0,
              "quantity" : 1,
              "manufacturer" : "Tigress Enterprises",
              "tax_amount" : 0,
              "product_id" : 19024,
              "category" : "Women's Accessories",
              "sku" : "ZO0082400824",
              "taxless_price" : 10.99,
              "unit_discount_amount" : 0,
              "min_price" : 5.17,
              "_id" : "sold_product_583581_19024",
              "discount_amount" : 0,
              "created_on" : "2016-12-25T14:16:48+00:00",
              "product_name" : "Snood - white/grey/peach",
              "price" : 10.99,
              "taxful_price" : 10.99,
              "base_unit_price" : 10.99
            },
            {
              "base_price" : 32.99,
              "discount_percentage" : 0,
              "quantity" : 1,
              "manufacturer" : "Tigress Enterprises",
              "tax_amount" : 0,
              "product_id" : 19260,
              "category" : "Women's Clothing",
              "sku" : "ZO0071900719",
              "taxless_price" : 32.99,
              "unit_discount_amount" : 0,
              "min_price" : 17.15,
              "_id" : "sold_product_583581_19260",
              "discount_amount" : 0,
              "created_on" : "2016-12-25T14:16:48+00:00",
              "product_name" : "Cardigan - grey",
              "price" : 32.99,
              "taxful_price" : 32.99,
              "base_unit_price" : 32.99
            }
          ],
          "sku" : [
            "ZO0082400824",
            "ZO0071900719"
          ],
          "taxful_total_price" : 43.98,
          "taxless_total_price" : 43.98,
          "total_quantity" : 2,
          "total_unique_products" : 2,
          "type" : "order",
          "user" : "rani",
          "geoip" : {
            "country_iso_code" : "EG",
            "location" : {
              "lon" : 31.3,
              "lat" : 30.1
            },
            "region_name" : "Cairo Governorate",
            "continent_name" : "Africa",
            "city_name" : "Cairo"
          },
          "event" : {
            "dataset" : "sample_ecommerce"
          }
        }
      },
      {
        "_index" : "kibana_sample_data_ecommerce",
        "_id" : "X4VTVZEBaBqnt6dm2-I0",
        "_score" : 1.0,
        "_source" : {
          "category" : [
            "Women's Clothing",
            "Women's Shoes"
          ],
          "currency" : "EUR",
          "customer_first_name" : "Elyssa",
          "customer_full_name" : "Elyssa Wells",
          "customer_gender" : "FEMALE",
          "customer_id" : 27,
          "customer_last_name" : "Wells",
          "customer_phone" : "",
          "day_of_week" : "Sunday",
          "day_of_week_i" : 6,
          "email" : "elyssa@wells-family.zzz",
          "manufacturer" : [
            "Pyramidustries",
            "Low Tide Media"
          ],
          "order_date" : "2024-08-25T10:30:43+00:00",
          "order_id" : 583360,
          "products" : [
            {
              "base_price" : 11.99,
              "discount_percentage" : 0,
              "quantity" : 1,
              "manufacturer" : "Pyramidustries",
              "tax_amount" : 0,
              "product_id" : 12266,
              "category" : "Women's Clothing",
              "sku" : "ZO0157301573",
              "taxless_price" : 11.99,
              "unit_discount_amount" : 0,
              "min_price" : 6.23,
              "_id" : "sold_product_583360_12266",
              "discount_amount" : 0,
              "created_on" : "2016-12-25T10:30:43+00:00",
              "product_name" : "Vest - black",
              "price" : 11.99,
              "taxful_price" : 11.99,
              "base_unit_price" : 11.99
            },
            {
              "base_price" : 64.99,
              "discount_percentage" : 0,
              "quantity" : 1,
              "manufacturer" : "Low Tide Media",
              "tax_amount" : 0,
              "product_id" : 17125,
              "category" : "Women's Shoes",
              "sku" : "ZO0379803798",
              "taxless_price" : 64.99,
              "unit_discount_amount" : 0,
              "min_price" : 31.2,
              "_id" : "sold_product_583360_17125",
              "discount_amount" : 0,
              "created_on" : "2016-12-25T10:30:43+00:00",
              "product_name" : "Boots - cognac",
              "price" : 64.99,
              "taxful_price" : 64.99,
              "base_unit_price" : 64.99
            }
          ],
          "sku" : [
            "ZO0157301573",
            "ZO0379803798"
          ],
          "taxful_total_price" : 76.98,
          "taxless_total_price" : 76.98,
          "total_quantity" : 2,
          "total_unique_products" : 2,
          "type" : "order",
          "user" : "elyssa",
          "geoip" : {
            "country_iso_code" : "US",
            "location" : {
              "lon" : -74,
              "lat" : 40.8
            },
            "region_name" : "New York",
            "continent_name" : "North America",
            "city_name" : "New York"
          },
          "event" : {
            "dataset" : "sample_ecommerce"
          }
        }
      },
      {
        "_index" : "kibana_sample_data_ecommerce",
        "_id" : "YIVTVZEBaBqnt6dm2-I0",
        "_score" : 1.0,
        "_source" : {
          "category" : [
            "Women's Accessories",
            "Women's Shoes"
          ],
          "currency" : "EUR",
          "customer_first_name" : "Selena",
          "customer_full_name" : "Selena Alvarez",
          "customer_gender" : "FEMALE",
          "customer_id" : 42,
          "customer_last_name" : "Alvarez",
          "customer_phone" : "",
          "day_of_week" : "Sunday",
          "day_of_week_i" : 6,
          "email" : "selena@alvarez-family.zzz",
          "manufacturer" : [
            "Pyramidustries",
            "Angeldale"
          ],
          "order_date" : "2024-08-25T11:38:24+00:00",
          "order_id" : 583410,
          "products" : [
            {
              "base_price" : 16.99,
              "discount_percentage" : 0,
              "quantity" : 1,
              "manufacturer" : "Pyramidustries",
              "tax_amount" : 0,
              "product_id" : 21173,
              "category" : "Women's Accessories",
              "sku" : "ZO0193401934",
              "taxless_price" : 16.99,
              "unit_discount_amount" : 0,
              "min_price" : 7.82,
              "_id" : "sold_product_583410_21173",
              "discount_amount" : 0,
              "created_on" : "2016-12-25T11:38:24+00:00",
              "product_name" : "Scarf - taupe/offwhite/rose",
              "price" : 16.99,
              "taxful_price" : 16.99,
              "base_unit_price" : 16.99
            },
            {
              "base_price" : 84.99,
              "discount_percentage" : 0,
              "quantity" : 1,
              "manufacturer" : "Angeldale",
              "tax_amount" : 0,
              "product_id" : 20498,
              "category" : "Women's Shoes",
              "sku" : "ZO0676206762",
              "taxless_price" : 84.99,
              "unit_discount_amount" : 0,
              "min_price" : 42.49,
              "_id" : "sold_product_583410_20498",
              "discount_amount" : 0,
              "created_on" : "2016-12-25T11:38:24+00:00",
              "product_name" : "Ankle boots - black",
              "price" : 84.99,
              "taxful_price" : 84.99,
              "base_unit_price" : 84.99
            }
          ],
          "sku" : [
            "ZO0193401934",
            "ZO0676206762"
          ],
          "taxful_total_price" : 101.98,
          "taxless_total_price" : 101.98,
          "total_quantity" : 2,
          "total_unique_products" : 2,
          "type" : "order",
          "user" : "selena",
          "geoip" : {
            "country_iso_code" : "MA",
            "location" : {
              "lon" : -8,
              "lat" : 31.6
            },
            "region_name" : "Marrakech-Tensift-Al Haouz",
            "continent_name" : "Africa",
            "city_name" : "Marrakesh"
          },
          "event" : {
            "dataset" : "sample_ecommerce"
          }
        }
      }
    ]
  }
}
```
Elasticsearch의 검색 결과에서 보이는 `took`, `_shards`, 그리고 `hits`는 각각 다음과 같은 의미를 가집니다:

### 1. `took`
- **의미**: 요청이 처리되는 데 걸린 시간(밀리초 단위)입니다.
- **예시**: `took: 20`이면 검색 요청이 20 밀리초 걸렸다는 의미입니다.

### 2. `_shards`
- **의미**: Elasticsearch에서 인덱스는 샤드로 나뉘어 저장됩니다. 이 필드는 검색 요청을 처리하는 데 사용된 샤드에 대한 정보를 제공합니다.
  - `total`: 전체 샤드 수.
  - `successful`: 요청을 성공적으로 처리한 샤드 수.
  - `skipped`: 건너뛴 샤드 수. 이 값이 0이면 모든 샤드가 처리되었다는 의미입니다.
  - `failed`: 요청을 처리하는 데 실패한 샤드 수.
- **예시**: `"_shards": { "total": 1, "successful": 1, "skipped": 0, "failed": 0 }`는 총 1개의 샤드가 처리되었고, 모두 성공적으로 처리되었다는 의미입니다.

### 3. `hits`
- **의미**: 검색 결과의 실제 도큐먼트들에 대한 정보를 포함합니다.
  - `total`: 검색 결과로 반환된 도큐먼트의 총 수.
  - `max_score`: 가장 높은 점수(정확도)를 가진 도큐먼트의 점수.
  - `hits`: 실제 검색 결과로 반환된 도큐먼트들의 배열입니다. 각 도큐먼트는 `_index`, `_id`, `_score`, 그리고 `_source` 필드를 포함합니다.
    - `_index`: 도큐먼트가 저장된 인덱스의 이름.
    - `_id`: 도큐먼트의 ID.
    - `_score`: 해당 도큐먼트의 관련성 점수.
    - `_source`: 도큐먼트의 실제 내용.

### 요약
- **took**: 요청 처리 시간.
- **_shards**: 요청 처리에 사용된 샤드 정보.
- **hits**: 검색 결과의 도큐먼트 리스트.

`relation` 필드는 `hits.total` 내에 나타나는 하위 필드로, 검색 결과의 총 도큐먼트 수가 어떻게 계산되었는지를 나타냅니다. 이 값은 두 가지 중 하나일 수 있습니다:

### 1. `eq` (equal)
- **의미**: 검색된 도큐먼트의 총 수(`hits.total.value`)가 정확히 몇 개인지 보여줍니다.
- **예시**: `"relation": "eq"`일 경우, `hits.total.value`에 표시된 숫자가 정확한 도큐먼트의 수입니다.

### 2. `gte` (greater than or equal)
- **의미**: 검색된 도큐먼트의 총 수가 `hits.total.value`보다 크거나 같음을 의미합니다. Elasticsearch에서 성능을 위해 정확한 수 대신 추정치를 반환할 때 사용됩니다.
- **예시**: `"relation": "gte"`일 경우, 실제 도큐먼트 수가 `hits.total.value`보다 더 많을 수 있습니다.

### 요약
- **`relation: "eq"`**: 정확한 도큐먼트 수.
- **`relation: "gte"`**: 도큐먼트 수가 이 숫자보다 크거나 같음.

Elasticsearch의 설정에 따라 결과를 최적화하고 성능을 높이기 위해 `gte`를 사용하는 경우가 있습니다.
---

동적 매핑
dynamic mapping
Elasticsearch의 가장 중요한 기능 중 하나는 방해가 되지 않도록 노력하고 가능한 한 빨리 데이터 탐색을 시작할 수 있도록 한다는 것입니다. 문서를 색인화하기 위해 먼저 색인을 생성하고, 매핑 유형을 정의하고, 필드를 정의할 필요가 없습니다. 문서를 색인화하기만 하면 색인, 유형 및 필드가 자동으로 표시됩니다.

---

dynamic field mapping
Elasticsearch는 문서에서 새 필드를 감지하면 기본적으로 해당 필드를 유형 매핑에 동적으로 추가합니다. 동적 매개변수는 이 동작을 제어합니다.

동적 매개변수를 true 또는 런타임으로 설정하여 들어오는 문서를 기반으로 필드를 동적으로 생성하도록 Elasticsearch에 명시적으로 지시할 수 있습니다. 동적 필드 매핑이 활성화되면 Elasticsearch는 다음 표의 규칙을 사용하여 각 필드에 대한 데이터 유형을 매핑하는 방법을 결정합니다.

> note 다음 표의 필드 데이터 유형은 Elasticsearch가 동적으로 감지하는 유일한 필드 데이터 유형입니다. 다른 모든 데이터 유형은 명시적으로 매핑해야 합니다.

동적 템플릿
dynamic templates
동적 템플릿을 사용하면 Elasticsearch가 기본 동적 필드 매핑 규칙을 넘어 데이터를 매핑하는 방법을 더 효과적으로 제어할 수 있습니다. 동적 매개변수를 true 또는 런타임으로 설정하여 동적 매핑을 활성화합니다. 그런 다음 동적 템플릿을 사용하여 일치 조건에 따라 동적으로 추가된 필드에 적용할 수 있는 사용자 정의 매핑을 정의할 수 있습니다.

match_mapping_type 및 unmatch_mapping_type은 Elasticsearch가 감지하는 데이터 유형에 대해 작동합니다.
일치 및 일치 해제 패턴을 사용하여 필드 이름과 일치
path_match 및 path_unmatch는 필드에 대한 전체 점선 경로에서 작동합니다.
동적 템플릿이 match_mapping_type, match 또는 path_match를 정의하지 않으면 어떤 필드와도 일치하지 않습니다. 대량 요청의 동적_템플릿 섹션에서 이름으로 템플릿을 계속 참조할 수 있습니다.
매핑 사양의 {name} 및 {dynamic_type} 템플릿 변수를 자리 표시자로 사용합니다.

동적 필드 매핑은 필드에 구체적인 값이 포함된 경우에만 추가됩니다. 엘라스틱서치는 그렇지 않다 필드에 null 또는 빈 배열이 포함된 경우 동적 필드 매핑을 추가합니다. null_value 옵션이 Dynamic_template에서 사용되는 경우 해당 필드에 대한 구체적인 값이 있는 첫 번째 문서가 인덱싱된 후에만 적용됩니다.

---

Elk
Log data 수집 및 Process, monitoring을 위한 기술 스택
elasticsearch , logstatshm kibana의 약자를 따서 Elk stackdlfkrh qnffla
로그의 수집을 Logstash에서 하고

Elasticsearch
apache lucene기반으로 개발한 분산
logstash 다양한 입력에 포함되는 데이터와 로그를 가공하여
beats Agent형태로 설치되어, logstash혹은 Elasticsearch로 여러 유형의 데이터를 전송하는 단일
Kibana 데이터를 처리한 후 결과를 시각화하기

데이터 파이프라인 흐름
beats-> elasticsearch->kibana
beats-> logstash->elasticsearch->kibana

---

elasticsearch component
아파치 루씬 기반의 오픈소스 실시간 분산 검색 엔진
정형 데이터와 비정형 데이터 검색 및 분석 가능
Iverte

데이터구조
rdbms elasticsearch
database index
partition shard
table type
schema mapping
row documnent
column field

document elasticsearch 데이터 최소
field documnet
mapping field와 field의
index Rdb

master node/data node
master node는 master-eligible 노드중 하나가 선택
전체적인 Index나 node를 담당하는

Datanode
데이터가 분산 저장되는 물리적인 공간인 Shard가 배치되는 Node

## elasticsaerch split brain

## index 와 shard

Index

- documnet들의 집합
- scale0out 을 위해 Index를 여러

## 실습

---

### beats의 개념

agent 형태로 설치되어 데이터를 수집하는 엔진, Elasticsearch 혹은 Logstash로 보내는 data shipper 역할
logstash의 다양한 목적으로 인해 agent가 큰 부분을 차지
데이터 수집을 경량화 하기 위한 목적으로 개발
기존의 logstash역할을 분담하기 위한 목적

### beats 종류

Filebeat
metricbeat
packetbeat
winlogbeat
auditbeat 보안 감사
heartbeat 어플리케이션
functionbeat 서버리스

filebeat to elasticsearch

### logstash 개념

소스로 부터 들어온 데이터 가공을 거쳐

### Logstash input

file
syslog
redis
beats
jdbc

### logstash filter

logstash에서 처리의 대상이 되는 데이터
gurok
grok 패턴을 사용해 메시지를 구조화된 형태로 분석하는 플러그인
mutate 특정 필드를 가공하기 위해 사용되는 플러그인
convert
copy
gsub
join
split
lowercase,uppercase
capitalize
merge
coerce
update
replace
strip
rename
drop
clone
geoip

### logstash output

처리이후 결과물이 보내지는 형태
Elasticsearch
graphite
file
statd
````

---

elasticsearch 데이터 구조
각 인덱스 별로 프라이머리 샤드와 복제본 세트 수 설정

```console
curl -X GET "localhost:9200/books/_settings?pretty"
{
  "books" : {
    "settings" : {
      "index" : {
        "routing" : {
          "allocation" : {
            "include" : {
              "_tier_preference" : "data_content"
            }
          }
        },
        "number_of_shards" : "1",
        "provided_name" : "books",
        "creation_date" : "1723733731537",
        "number_of_replicas" : "1",
        "uuid" : "2C2BBOiKT5CTath9J7_btQ",
        "version" : {
          "created" : "8060299"
        }
      }
    }
  }
}

curl -X PUT "localhost:9200/books/_settings?pretty"

"index.number_of_shards":3
"index.number_of_replicas":2
```

replicas는 변경가능하지만 프라이머리 샤드 수는 기본적으로 처음 인덱스 생성 시점에서 설정 이후 변경 불가능

데이터 색인시 인덱스의 모든 샤드에 round-robin 방식으로 입력
사용자는 어떤 도큐먼트가 어떤 샤드에 적재되는지 알 수 없음

검색을 할 떄도 요청을 받은 노드가 해당되는 모든 샤드에 검색명령을 전달
검색은 각 샤드별로 분산 실행되고 결과는 다시 요청 받은 노드로 전달 , 취합되어 클라이언트로 응답
쿼리를 요청받아 전달하고 다시취함, 응답하는 노드를 코디네이터 노드 라고 함 ( coordinate node )
기본 샤드 개수 - Settings: {index.number_of_shards}
인덱스 용량에 따라 적절한 수의 샤드로 구성해야됨
인덱스를 선언하지 않아도 도큐 먼트를 입력하면 자동으로 인덱스 생성 -Schemless
인덱스 당 설정 가능한 최대 샤드 개수: 1,024개
6.x 버전 까지는 디폴트로 프라이머리 샤드 5개
7.0부터는 디폴트 프라이머리 샤드 1개

멀티테넌시 multitenancy
Elasticsearch에서는 서로 다른 인덱스를 묶어서 한꺼번에 검색가능
쉼표, 로 나열하거나 와일드카드\* 사용가능
로그 데이터 같은 경우 날짜 일월등 단위로 데이터를 쌓는 것이 여러 모로 용이함

Oversharding 문제
초기 Es는 무결성과 분산성을 위해 인덱스를 적절한 수의 샤드로 나누는것을 권장
es 활용 노하우가 많이 알려지면서 인덱스로 나눈 멀티 테너시 활용이 많아짐
샤드당 권장 사이즈는 시스템 사양에 따라 다르지만 보통 10~50gb 수용가능
6.x 이하 버전에서 디폴트로 샤드 5개
filebeat등에서는 용량과 상관없이 날짜별로 인덱스를 생성
6종류의 인덱스를 180일간 보관하는 경우
6(index)*5(shards)*180(days)=5400개의 샤드 유지
샤드를 충분히 나누지 않아 활용 못하는 경우보다 샤드 수가 너무 많아 발생하는 문제가 많아짐

---

alias api
하나의 alias에 복수개의 인덱스 연결가능
여러개의 인덱스가 연결된 경우 조회만 가능
alias와 인덱스가 1:1인 경우 색인 가능
입력은 색인 alias, 검색은 조회 alias 로 하면 클라이언트 설정 필요없음

---

elasticsearch, kibana version 일치해야된다

bin/elasticsearch -d
bin/elasticsearch -p es.pid
kill `cat es.pid`

---

elasticsearch set configuration

jvm.options 파일에서 java heap mem 설정
elasticsaerch.yaml 환경 설정 파일
yaml 문법 설명
cluster.name : 클러스터명
node.name: 노드명
path.data, path.log: 데이터, 로그 저장 경로
log4j2.properties - 로그 관련 옵션
실행 명령에서 -E 옵션으로 환경 설정

---

2.3.1 jvm.options
이 문서의 허가되지 않은 무단 복제나 배포 및 출판을 금지합니다. 본 문서의 내용 및 도표 등을 인용하고자 하는 경우 출처를 명시하고 김종민(kimjmin@gmail.com)에게 사용 내용을 알려주시기 바랍니다.

Elasticsearch는 Java의 가상머신 위에서 실행이 되는데 7.0 기준으로 1gb의 힙메모리가 기본으로 설정되어 있습니다. 이 설정들은 jvm.options 파일에서 아래 내용들을 수정하여 변경할 수 있습니다.

config/jvm.options
Copy
-Xms1g
-Xmx1g
이 밖에도 Elasticsearch를 실행할 때 java와 관련된 환경변수들은 대부분 jvm.options 파일에서 설정이 가능합니다.
log.level": "INFO", "message":"heap size [512mb], compressed ordinary object pointers [true]"
30gb 이상 설정 금지

---

elasticsearch 클러스터와 노드 바인딩

elasticsearch 클러스터 구성도
여러서버에서 각 노드 실행
하나의 서버에서 여러 노드 실행
다수의 노드가 차례대로 바인딩되는 과정 메모
노드 디스커버리 과정 설명

클러스터가 바인딩 되려면 클러스터 네임이 같아야한다.
/config/elasticsearch.yml
cluseter.name: cluster-1
node.name: node-1
cluseter.name: cluster-1
node.name: node-2

---

network.host: [ "_local_", "_site_" ]
엘라스틱서치는 로컬에서 실행하지 않으면 운영모드로 부트스트랩된다.

file descripter
ulimit -n 65535
the new limit is only applied during the current session.
you can cnsult all currently applied limits with ulimt -a

/etc/security/limits.conf
elasticsaerch - nofile 65535

---

discovery

network seed.host
init

---

클러스터 아키텍쳐 구성도
클러스터 구성 3개 노드
실행 로그에서 바인딩 되는 과정 확인
\_cat.nodes명령으로 구성된 노드 정보 확인

---

교환 비활성화
disable swapping
대부분의 운영 체제는 파일 시스템 캐시에 최대한 많은 메모리를 사용하고 사용하지 않는 애플리케이션 메모리를 적극적으로 교체하려고 합니다. 이로 인해 JVM 힙의 일부 또는 실행 가능 페이지가 디스크로 교체될 수 있습니다.

스와핑은 성능과 노드 안정성에 매우 좋지 않으므로 어떤 대가를 치르더라도 피해야 합니다. 이로 인해 가비지 수집이 밀리초가 아닌 몇 분 동안 지속될 수 있으며 노드의 응답 속도가 느려지거나 클러스터와의 연결이 끊어질 수도 있습니다. 탄력적인 분산 시스템에서는 운영 체제가 노드를 종료하도록 하는 것이 더 효과적입니다.

스와핑을 비활성화하는 방법에는 세 가지가 있습니다. 선호되는 옵션은 스왑을 완전히 비활성화하는 것입니다. 이것이 옵션이 아닌 경우 메모리 잠금과 스왑 최소화를 선호하는지 여부는 환경에 따라 다릅니다.

모든 스왑 파일 비활성화
일반적으로 Elasticsearch는 상자에서 실행되는 유일한 서비스이며 메모리 사용량은 JVM 옵션에 의해 제어됩니다. 스왑을 활성화할 필요는 없습니다.

Linux 시스템에서는 다음을 실행하여 일시적으로 스왑을 비활성화할 수 있습니다.

sudo swapoff -a
Elasticsearch를 다시 시작할 필요는 없습니다.

영구적으로 비활성화하려면 /etc/fstab 파일을 편집하고 swap이라는 단어가 포함된 모든 줄을 주석 처리해야 합니다.
swappoff 확인법

스와핑이 활성화되었는지 확인하려면 다음과 같은 명령어를 사용할 수 있습니다.

1. **현재 스왑 사용량 확인**:

   ```sh
   swapon --show
   ```

   이 명령어는 현재 활성화된 스왑 공간을 보여줍니다. 결과가 아무것도 출력되지 않으면 스왑이 비활성화된 것입니다.

2. **스왑 사용량 확인 (메모리 정보)**:

   `free` 명령어를 사용하여 메모리와 스왑 사용량을 확인할 수 있습니다:

   ```sh
   free -h
   ```

   출력된 결과에서 `Swap` 부분을 확인하세요. 만약 `0B`로 나타나면 스왑이 비활성화된 상태입니다.

3. **스왑 디바이스 확인**:

   `/proc/swaps` 파일을 확인할 수 있습니다:

   ```sh
   cat /proc/swaps
   ```

   이 파일이 비어 있으면 스왑이 비활성화된 상태입니다.

이 방법들로 스와핑이 활성화되어 있는지, 그리고 어느 정도 사용 중인지 확인할 수 있습니다.
Windows에서는 시스템 속성 → 고급 → 성능 → 고급 → 가상 메모리를 통해 페이징 파일을 완전히 비활성화하면 동일한 효과를 얻을 수 있습니다.
Elasticsearch를 시작한 후 이 요청의 출력에서 ​​mlockall 값을 확인하여 이 설정이 성공적으로 적용되었는지 확인할 수 있습니다.
curl -X GET "localhost:9200/\_nodes?filter_path=\*\*.mlockall&pretty"

---

elasticsearch.yaml 에서 보안 기능 설정
xpack.security - 보안 기능 활성
transport.ssl 노드들간의 통신에 Tls보안 적용

암호화/ 복호화 키 생성
키를 만들기 위해 elastic 에서 제공하는 도구

Elasticsearch-certutil 사용
pkcs#12(.p12)방식의 키 저장소 생성
키 저장소를 이용한 private 키 생성
elasticsearch-keystore 사용
elasticsearch.yml 에 입력할수 없는 민감한 환경 변수 값(패스워드 등)을 저장하기 위한 도구
./bin/elasticsearch-keystore add xpack.security.transport.ssl.keystore.secure_password
./bin/elasticsearch-keystore add xpack.security.transport.ssl.truststore.secure_password

클러스터 보안 설정
refernece/security-settings

XPack.security.enabled: true
xpack.security.transport.ssl.enabled: true
xpack.security.transport.ssl.keystore.path: /certs/elastic-stack-ca.p12
xpack.security.transport.ssl.truststore.path: /certs/ elastic-certificates.p12

bin/elasticsarch-setup-passwords {option}
xpack.security.enabled: true

- auto : 주요 시스템 계정 패스워드 자동 생성
- interactive: 주요 시스템 계정 패스워드 각각 (2번씩)입력해서 설정
  새로 세팅하려면
- data 디렉토리 삭제 후 패스워드 다시 생성
- bin/elasticsarch-user useradd {user} -p {password} -r {role} : 해당 노드에서만 사용가능ㅇ.
  Elasticsearch-suers도구는 file realm 에 기록되기 때문에 data 디렉토리 삭제 후에도 계정 살아있음.
  클러스터링 하려면 노드들 간의 통신도 보안 적용 해야됨
  /Refernec/encrypting-intermode
  certutil을 이용해서 인증서 생서
  refernce/encrypting=communications=certificates

---

클러스터 보안 설정2
사용자 암호설정
Elasticsaerch-keystore을 이용하여
[global 하게 사용]elasticsaerch-setup-password기능을 이용해서 사용자 계정 암호정ㅇ보를 클러스터 설정에 저장 native realm
[특정 노드에서만 가능]Elasticsearch-users기능을 이용하여 사용자 계정/암호 정보를 파일에 저장 (File realm)

---

Kibana
Elasticsearch와 http통신

---

Kibana를 시작하는 다양한 방법
bin/kibana(.bat) 스크립트 실행
node.js 를 이용하여 src/cli/cli.js 실행

Pm2를 이용해서 kibana를 데몬으로 실행하기
nvm 을 이용한 노드 버전 관리
pm2 설치 및 실행 옵션 설명
kibana를 데몬으로 실행/종료 하기 위한 스크립트 파일 생성

키바나는 노드로 실행됨 cat /package.json 노드의 버전을 확인

---

인덱스와 샤드
프라이머리 샤드 (primary shard)와 복제본(replica)
인덱스의 settings 설정에서 샤드 갯수 지정
\_Cat/shards api 를 이용한 샤드 상태 조회

모니터링 도구를 이용한 클러스터 모니터링
kibana의 모니터링 도구 실행 및 확인
\_cluster/settings api 를 이용한 모니터링 실행/중지

elasticsearch에서는 단일 데이터 단위를 document라고 하며 도큐먼트를 모아놓은 집합을 Index
인덱스라는 단어가 여러 뜻으로 사용되기 때문에 데이터 저장 단위인 인덱스는 인디시즈(indices) 라고 표현하기도 합니다. 이 책에서는 데이터를 Elasticsearch에 저장하는 행위는 색인, 그리고 도큐먼트의 집합 단위는 인덱스 라고 하겠습니다.

인덱스는 기본적으로 샤드(shard)라는 단위로 분리되고 각 노드에 분산되어 저장이 됩니다. 샤드는 루씬의 단일 검색 인스턴스 입니다. 다음은 하나의 인덱스가 5개의 샤드로 저장되도록 설정한 예 입니다.
프라이머리 샤드(Primary Shard)와 복제본(Replica)
인덱스를 생성할 때 별도의 설정을 하지 않으면 7.0 버전부터는 디폴트로 1개의 샤드로 인덱스가 구성되며 6.x 이하 버전에서는 5개로 구성됩니다. 클러스터에 노드를 추가하게 되면 샤드들이 각 노드들로 분산되고 디폴트로 1개의 복제본을 생성합니다. 처음 생성된 샤드를 프라이머리 샤드(Primary Shard), 복제본은 리플리카(Replica) 라고 부릅니다. 예를 들어 한 인덱스가 5개의 샤드로 구성어 있고, 클러스터가 4개의 노드로 구성되어 있다고 가정하면 각각 5개의 프라이머리 샤드와 복제본, 총 10개의 샤드들이 전체 노드에 골고루 분배되어 저장됩니다.
같은 샤드와 복제본은 동일한 데이터를 담고 있으며 반드시 서로 다른 노드에 저장이 됩니다. 만약에 위 그림에서 Node-3 노드가 시스템 다운이나 네트워크 단절등으로 사라지면 이 클러스터는 Node-3 에 있던 0번과 4번 샤드들을 유실하게 됩니다. 하지만 아직 다른 노드들 Node-1, Node-2 에 0번, 4번 샤드가 남아있으므로 여전히 전체 데이터는 유실이 없이 사용이 가능합니다.
처음에 클러스터는 먼저 유실된 노드가 복구 되기를 기다립니다. 하지만 타임아웃이 지나 더 유실된 노드가 복구되지 않는다고 판단이 되면 Elasticsearch는 복제본이 사라져 1개만 남은 0번, 4번 샤드들의 복제를 시작합니다. 처음에 4개였던 노드가 3개로 줄어도 복제가 끝나면 0~4번 까지의 프라이머리 샤드, 복제본이 각각 5개씩 총 10개의 데이터로 유지됩니다.
렇게 프라이머리 샤드와 리플리카를 통해 Elasticsearch는 운영 중에 노드가 유실 되어도 데이터를 잃어버리지 않고 데이터의 가용성과 무결성을 보장합니다.

프라이머리 샤드가 유실된 경우에는 새로 프라이머리 샤드가 생성되는 것이 아니라, 남아있던 복제본이 먼저 프라이머리 샤드로 승격이 되고 다른 노드에 새로 복제본을 생성하게 됩니다.

mapping 데이터가 들어가면 보임
settings shards는 바꿀수없음 Replicas는 수정가능

키바나 stack monitoring mericbeat를 설치하는걸 추천
모니터링 결과 엘라스틱 서치에 저장

모니터링 끄기

```
Get _cluster/settings
{
  "persistent": {
    "xpack": {
      "monitoring" : {
        "collection" : {
          "enable" : "false", "null", "true"
        }
      }
    }
  }
}
```

---

document cruds
입력,조회, 수정 , 삭제, 검색
rest api로 접근
put, get , delete {\_index}/\_doc/{\_id}
post {\_index}/\_update/{\_id}
벌크 명령: post \_bulk

\_search api 검색
url Rjator: ?q=...query...
데이터 본문 검색: {"query": {...쿼리...}}

---

query dsl: 풀텍스트
full text query
match
match_phrase
query_string

relevancy(연관성, 정확도)
tf/idf

---

# Query DSL (Domain Specific Language)

## Query and Filter Context

Elasticsearch 쿼리는 `query context`와 `filter context`에서 사용됩니다. `query context`에서는 각 문서가 쿼리 조건에 얼마나 부합하는지를 점수화하여 계산하고, `filter context`에서는 문서의 점수를 계산하지 않고, 참/거짓으로만 평가합니다. 점수 계산이 필요하지 않다면 필터를 사용하는 것이 더 효율적입니다.

## Compound Queries

복합 쿼리는 다른 여러 쿼리를 결합하여 더 복잡한 논리적 쿼리를 작성할 수 있도록 합니다. 주요 복합 쿼리에는 `bool`, `dis_max`, `function_score`, `boosting` 등이 있습니다. 예를 들어, `bool` 쿼리는 여러 쿼리를 조합하여 AND, OR, NOT 같은 논리적 연산을 수행합니다.

## Full Text Queries

전체 텍스트 쿼리는 텍스트 필드에서 자유형 텍스트 검색을 수행합니다. 여기에는 `match`, `match_phrase`, `multi_match` 등의 쿼리가 포함됩니다. 이러한 쿼리들은 텍스트를 분석하여 저장된 텀과 일치시키는 방식으로 작동합니다.

## Geo Queries

지리적 쿼리는 지리적 데이터를 사용하여 검색을 수행합니다. 예를 들어, `geo_distance` 쿼리는 특정 지점으로부터의 거리 기반으로 문서를 필터링합니다. 그 외에도 `geo_bounding_box`, `geo_polygon` 쿼리 등이 있습니다.

## Shape Queries

Shape 쿼리는 지정된 지리적 모양(예: 다각형, 원 등)과 일치하는 문서를 찾습니다. `geo_shape`와 `shape` 쿼리가 대표적입니다. 이 쿼리들은 위치 기반 검색을 위한 복잡한 도형을 다룰 수 있습니다.

## Joining Queries

조인 쿼리는 관계형 데이터베이스의 조인과 유사하게 여러 인덱스나 문서 간의 관계를 쿼리합니다. 대표적인 예로 `nested` 쿼리와 `has_child`, `has_parent` 쿼리가 있습니다.

## Match All

`match_all` 쿼리는 모든 문서를 일치시켜 반환합니다. 점수는 문서의 `_score` 필드로 결정되며, 기본적으로 동일하게 설정됩니다.

## Span Queries

Span 쿼리는 텍스트 필드에서 구간 내의 텀(term)을 찾는 데 사용됩니다. `span_term`, `span_near`, `span_or`, `span_not` 등의 쿼리가 있습니다. 이러한 쿼리는 고급 텍스트 매칭에 유용합니다.

## Vector Queries

벡터 쿼리는 벡터 필드에서 근접 탐색을 수행합니다. 특히, 이미지 검색이나 자연어 처리 모델의 임베딩 벡터에 사용됩니다. `knn` 쿼리가 대표적이며, 유사한 벡터를 기반으로 검색을 수행합니다.

## Specialized Queries

특정 목적을 위한 특수 쿼리로, 특정 필드나 상황에 맞게 설계된 쿼리입니다. 예를 들어, `script` 쿼리는 커스텀 스크립트를 실행하여 문서를 필터링하거나 점수를 계산합니다.

## Term-level Queries

Term 수준 쿼리는 구조화된 데이터에서 정확히 일치하는 문서를 찾는 데 사용됩니다. 대표적인 쿼리로는 `term`, `terms`, `range`, `exists`, `prefix` 등이 있으며, 필드의 분석 과정을 거치지 않고 원시 값과 일치시킵니다.

## minimum_should_match Parameter

`minimum_should_match` 파라미터는 `bool` 쿼리에서 `should` 절에 해당하는 최소 매칭 개수를 지정합니다. 이를 통해 검색 결과의 범위를 조절할 수 있습니다.

## Rewrite Parameter

`rewrite` 파라미터는 쿼리를 최적화하는 방식입니다. 예를 들어, `multi-term` 쿼리에서 이 파라미터를 사용하여 `constant_score`, `scoring_boolean`, `top_terms_boost`, `top_terms_blended_freqs` 등 다양한 방식으로 쿼리를 최적화할 수 있습니다.

## Regular Expression Syntax

정규 표현식 쿼리는 필드 값이 특정 패턴과 일치하는 문서를 찾습니다. Elasticsearch는 Lucene 기반의 정규 표현식 문법을 사용하며, 다양한 특수 문자를 사용하여 복잡한 패턴 매칭을 수행할 수 있습니다. 정규 표현식 쿼리는 리소스 소모가 클 수 있으므로 주의해서 사용해야 합니다.

---

full text query
match_all
match_all 은 별다른 조건 없이 해당 인덱스의 모든 도큐먼트를 검색하는 쿼리입니다. 검색 시 쿼리를 넣지 않으면 elasticsearch는 자동으로 match_all을 적용해서 해당 인덱스의 모든 도큐먼트를 검색합니다. 다음 두 예제는 결과가 동일합니다.

쿼리 없이 실행
match_all 쿼리로 실행
Copy
GET my_index/\_search
match
match 쿼리는 풀 텍스트 검색에 사용되는 가장 일반적인 쿼리입니다. 다음은 match 쿼리를 이용하여 my_index 인덱스의 message 필드에 dog 가 포함되어 있는 모든 문서를 검색합니다.

request
response
match 쿼리로 message 필드에서 dog 검색
Copy
GET my_index/\_search
{
"query": {
"match": {
"message": "dog"
}
}
}
dog가 포함된 총 4개의 도큐먼트가 검색 결과로 나타납니다.

match 검색에 여러 개의 검색어를 집어넣게 되면 디폴트로 OR 조건으로 검색이 되어 입력된 검색어 별로 하나라도 포함된 모든 문서를 모두 검색합니다. 다음은 검색어로 quick dog 를 검색 한 결과입니다.

request
response
match 쿼리로 message 필드에서 quick dog 검색
Copy
GET my_index/\_search
{
"query": {
"match": {
"message": "quick dog"
}
}
}
quick과 dog중 어떤 단어라도 포함한 도큐먼트 총 5개가 검색되었습니다.

검색어가 여럿일 때 검색 조건을 OR 가 아닌 AND 로 바꾸려면 operator 옵션을 사용할 수 있습니다. 이 경우 문법이 조금 달라지는데,
<필드명>:<검색어>
형식으로 하던 것을
<필드명>: { "query":<검색어>, "operator": }
와 같이 입력해야 합니다. quick dog 를 AND 조건으로 검색하려면 다음과 같습니다.

request
response
match 쿼리 AND 조건으로 quick dog 검색
Copy
GET my_index/\_search
{
"query": {
"match": {
"message": {
"query": "quick dog",
"operator": "and"
}
}
}
}
match_phrase
match 쿼리에서 quick 과 dog 검색어를 AND 조건으로 검색하는 방법을 알아보았습니다. 그런데 "quick dog" 라는 구문을 공백을 포함해 정확히 일치하는 내용을 검색하려면 어떻게 해야 할까요? 바로 match_phrase 쿼리를 사용하면 됩니다. match_phrase 쿼리는 입력된 검색어를 순서까지 고려하여 검색을 수행합니다. 다음은 lazy dog 라는 구문을 검색하는 match_phrase 쿼리입니다.

request
response
match_phrase 쿼리로 "lazy dog" 구문 검색
Copy
GET my_index/\_search
{
"query": {
"match_phrase": {
"message": "lazy dog"
}
}
}
"lazy dog" 라는 정확한 문장이 포함된 도큐먼트 1개만 검색이 되었습니다.

match_phrase 쿼리는 slop 이라는 옵션을 이용하여 slop에 지정된 값 만큼 단어 사이에 다른 검색어가 끼어드는 것을 허용할 수 있습니다. slop을 1로 하고 검색을 하면 다음과 같은 결과가 나옵니다.

request
response
match_phrase 쿼리에 slop:1 로 "lazy dog" 구문 검색
Copy
GET my_index/\_search
{
"query": {
"match_phrase": {
"message": {
"query": "lazy dog",
"slop": 1
}
}
}
}
slop의 크기를 1로 했기 때문에 lazy와dog 사이에 jumping이 있는 "Lazy jumping dog" 값도 검색이 됩니다. slop을 2로 한다면 아마도 lazy jumping brow dog 같은 문장도 검색에 포함될 수 있을 것입니다.

이처럼 match_phrase 쿼리와 slop을 이용하면 정확도를 조절 해 가며 원하는 검색 결과의 범위를 넓힐 수 있습니다. slop을 너무 크게 하면 검색 범위가 넓어져 관련이 없는 결과가 나타날 확률도 높아지기 때문에 1 이상은 사용하지 않는 것을 권장 드립니다.

query_string
4.4 검색 API 장에서 URL의 q 파라메터를 이용해서 검색을 수행하는 것을 설명했습니다. URL검색에 사용하는 루씬의 검색 문법을 본문 검색에 이용하고 싶을 때 query_string 쿼리를 사용할 수 있습니다.

다음은 message 필드에서 lazy와 jumping을 모두 포함하거나 또는 "quick dog" 구문을 포함하는 도큐먼트를 검색하는 쿼리입니다. match_phrase 처럼 구문 검색을 할 때는 검색할 구문을 쌍따옴표 \" 안에 넣습니다.

request
response
query_string 쿼리 검색
Copy
GET my_index/\_search
{
"query": {
"query_string": {
"default_field": "message",
"query": "(jumping AND lazy) OR \"quick dog\""
}
}
}
"Lazy jumping dog" 도큐먼트와 "quick dog" 값을 포함하는 도큐먼트 두개가 결과로 리턴된 것을 확인할 수 있습니다.

---

정확도 - Relevancy
이 문서의 허가되지 않은 무단 복제나 배포 및 출판을 금지합니다. 본 문서의 내용 및 도표 등을 인용하고자 하는 경우 출처를 명시하고 김종민(kimjmin@gmail.com)에게 사용 내용을 알려주시기 바랍니다.

RDBMS 같은 시스템에서는 쿼리 조건에 부합하는 지만 판단하여 결과를 가져올 뿐 각 결과들이 얼마나 정확한지에 대한 판단은 보통 불가능합니다. Elasticsearch 와 같은 풀 텍스트 검색엔진은 검색 결과가 입력된 검색 조건과 얼마나 정확하게 일치하는 지를 계산하는 알고리즘을 가지고 있어 이 정확도를 기반으로 사용자가 가장 원하는 결과를 먼저 보여줄 수 있습니다. 이 정확한 정도를 relevancy 라고 합니다 (렐러번시 라고 읽습니다). 한국어로 번역하면 연관성 또는 관련성 이라고 번역이 되는데, 이 책에서는 이해를 돕기 위해 정확도 라는 표현을 쓰겠습니다. 스터디 또는 강연 등에서 언급 하실 때는 원래 용어 relevancy 로 사용하실 것을 권장 드립니다.

검색을 할 때 사용자는 찾고자 하는 정확한 결과만 보고싶어 합니다. 검색 조건에 포함 되더라도 사용자가 찾으려는 결과와 상관 없는 결과는 보여주지 않는 것이 좋습니다. 구글 또는 네이버 같은 웹 검색엔진들도 검색을 하면 찾은 결과들 중에 어떤 것이 사용자가 입력한 검색어와 가장 연관성이 있는지를 계산하여 정확도가 가장 높은 결과들 부터 보여줍니다.

스코어 (score) 점수
Elasticsearch의 검색 결과에는 스코어 점수가 표시가 됩니다. 이 점수는 검색된 결과가 얼마나 검색 조건과 일치하는지를 나타내며 점수가 높은 순으로 결과를 보여줍니다. 다음의 match 쿼리 결과를 살펴보겠습니다.

request
response
quick dog 를 포함한 도큐먼트 검색

```
GET my_index/_search
{
  "query": {
    "match": {
      "message": "quick dog"
    }
  }
}
```

각 검색 결과의 \_score 항목에 스코어 점수가 표시되고 이 점수가 높은 결과부터 나타납니다. 그리고 상단의 max_score에는 전체 결과 중에서 가장 높은 점수가 표시됩니다. Elasticsearch 는 이 점수를 계산하기 위해 BM25 라는 알고리즘을 이용합니다. BM은 Best Matching 을 뜻합니다.

다음은 BM25의 계산식입니다.
정확도 RELevancy
Term frequency : 도큐먼트 내에 검색된 텀(term)이 더 많을수록 점수가 높아지는 것을 Term Frequency 라고 합니다.

IDF (Inverse Document Frequency): 검색한 텀을 포함하고 있는 도큐먼트 개수가 많을수록 그 텀의 자신의 점수가 감소하는 것을 Inverse Document Frequency 라고 합니다.

field length: 도큐먼트에서 필드 길이가 큰 필드 보다는 짧은 필드에 있는 텀의 비중이 클 것입니다. 검색 하려는 단어가 제목과 내용 필드에 모두 있는 경우 텍스트 길이가 긴 내용 필드 보다는 텍스트 길이가 짧은 제목 필드에 검색어가 더 점수가 높게 나타납니다.

가장 연관성이 높은 데이터를 보여줌 \_score 계산하는

---

복합 (bool) 쿼리

앞의 query_string 쿼리는 여러 조건을 조합하기에는 용이한 문법이지만 옵션이 한정되어 있습니다. 본문 검색에서 여러 쿼리를 조합하기 위해서는 상위에 bool 쿼리를 사용하고 그 안에 다른 쿼리들을 넣는 식으로 사용이 가능합니다. bool 쿼리는 다음의 4개의 인자를 가지고 있으며 그 인자 안에 다른 쿼리들을 배열로 넣는 방식으로 동작합니다.

must : 쿼리가 참인 도큐먼트들을 검색합니다.

must_not : 쿼리가 거짓인 도큐먼트들을 검색합니다.

should : 검색 결과 중 이 쿼리에 해당하는 도큐먼트의 점수를 높입니다.

filter : 쿼리가 참인 도큐먼트를 검색하지만 스코어를 계산하지 않습니다. must 보다 검색 속도가 빠르고 캐싱이 가능합니다.

---

범위 쿼리 - Range Query
이 문서의 허가되지 않은 무단 복제나 배포 및 출판을 금지합니다. 본 문서의 내용 및 도표 등을 인용하고자 하는 경우 출처를 명시하고 김종민(kimjmin@gmail.com)에게 사용 내용을 알려주시기 바랍니다.

지금까지는 문자열 필드들의 검색에 대해 살펴보았습니다. Elasticsearch는 이 외에도 숫자나 날짜 형식들의 저장이 가능합니다. 숫자, 날짜 형식은 range 쿼리를 이용해서 검색을 합니다.

range 쿼리의 예제를 위해 먼저 아래의 phones 인덱스를 추가하겠습니다.

```console
curl -X POST "localhost:9200/phones/\_bulk" -H "Content-Type: application/json" -d '
{"index":{"\_id":1}}
{"model":"Samsung Galaxy S5","price":475,"date":"2014-02-24"}
{"index":{"\_id":2}}
{"model":"Samsung Galaxy S6","price":795,"date":"2015-03-15"}
{"index":{"\_id":3}}
{"model":"Samsung Galaxy S7","price":859,"date":"2016-02-21"}
{"index":{"\_id":4}}
{"model":"Samsung Galaxy S8","price":959,"date":"2017-03-29"}
{"index":{"\_id":5}}
{"model":"Samsung Galaxy S9","price":1059,"date":"2018-02-25"}
```

---

inverted index
analyzer
character filters -> tokenizer -> token filter
텍스트 데이터가 입력되면 가장 먼저 필요에 따라 전체 문장에서 특정 문자를 대치하거나 제거하는데 이 과정을 담당하는 기능이 캐릭터 필터
문장에 속한 단어들을 텀 단위로 하나씩 분리 해 내는 처리 과정을 거치는데 이 과정을 담당하는 기능이 토크나이저
토크나이저는 반드시 1개만 적용이 가능
whitespace 토크 나이저를 이용해서 공백을 기준으로 분리

분리된 텀들을 하나씩 가공하는 과정을 거치는데 이과정을 담당하는 기능이 토큰 필터. 토큰 필터는 0개 부터 여러개를 적용할수있음
