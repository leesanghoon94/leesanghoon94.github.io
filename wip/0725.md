Linux ì œì–´ ê·¸ë£¹ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ ë¦¬ì†ŒìŠ¤ ì œì–´.

í¬ê´„ì ì¸ ê°€ì´ë“œëŠ” ì•„ë‹ˆì§€ë§Œ Linux cgroupì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡œì„¸ìŠ¤ì˜ CPU ë° RAM ì†Œë¹„ë¥¼ ì œí•œí•˜ëŠ” ë°©ë²•ì— ëŒ€í•œ ì‹¤ì œ ì˜ˆì…ë‹ˆë‹¤. ì´ ê¸°ìˆ ì€ ë‹¤ìŒê³¼ ê°™ì€ ìš©ë„ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
íŠ¹íˆ ë¦¬ì†ŒìŠ¤ë¥¼ ë§ì´ ì‚¬ìš©í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¡œë¶€í„° ì‹œìŠ¤í…œì„ ë³´í˜¸í•©ë‹ˆë‹¤.
ì—¬ëŸ¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ê°„ì— ê³µì •í•œ ë¦¬ì†ŒìŠ¤ ë¶„ë°° ë³´ì¥
ì œí•œëœ ë¦¬ì†ŒìŠ¤ì—ì„œ ì• í”Œë¦¬ì¼€ì´ì…˜ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
ë©€í‹° í…Œë„ŒíŠ¸ í™˜ê²½ì—ì„œ ë¦¬ì†ŒìŠ¤ ê°€ìš©ì„± ë³´ì¥
ê°€ì¥ ê¸°ë³¸ì ì¸(ê·¸ë¦¬ê³  ë…¸ë™ ì§‘ì•½ì ì¸) ë°©ë²•, ì¦‰ ê°€ìƒ íŒŒì¼ ì‹œìŠ¤í…œ cgroupfsë¥¼ ì¡°ì‘í•˜ì—¬ cgroupì— í”„ë¡œì„¸ìŠ¤ë¥¼ ìƒì„±, êµ¬ì„± ë° ì¶”ê°€í•˜ëŠ” ê²ƒë¶€í„° ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. ê·¸ëŸ° ë‹¤ìŒ libcgroupì˜ cgcreate ë° cgexec ë˜ëŠ” systemdì˜ systemd-run ë° ìŠ¬ë¼ì´ìŠ¤ ì¥ì¹˜ì™€ ê°™ì€ ìƒìœ„ ìˆ˜ì¤€ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•íˆ ë™ì¼í•œ ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.
í”„ë¡œì„¸ìŠ¤ ë¦¬ì†ŒìŠ¤ë¥¼ ì œì–´í•˜ëŠ” â€‹â€‹Linux ê¸°ë°˜ ë°©ë²•ì— ì¤‘ì ì„ ë‘ì§€ë§Œ, ë‹¤ë£¨ëŠ” ê¸°ìˆ ì€ ì»¨í…Œì´ë„ˆ ë° Podì˜ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ì—ë„ ì§ì ‘ ì ìš©í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ íŠœí† ë¦¬ì–¼ì€ Docker ë° Podë¥¼ ì‹¤í–‰í•˜ëŠ” ì‚¬ëŒë“¤ì—ê²Œë„ ê´€ë ¨ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤.

ì´ ê²Œì‹œë¬¼ì˜ ì˜ˆëŠ” cgroup v2ë¥¼ í™œìš©í•˜ì§€ë§Œ ì¼ë°˜ì ì¸ ì•„ì´ë””ì–´ëŠ” cgroup v1ì—ì„œë„ ì‘ë™í•´ì•¼ í•©ë‹ˆë‹¤.
![alt text](image-1.png)

> Control groups, usually referred to as cgroups, are a Linux
> kernel feature which allow processes to be organized into
> hierarchical groups whose usage of various types of resources can
> then be limited and monitored.

cgroupì€ ê°€ì§œ íŒŒì¼ ì‹œìŠ¤í…œ í´ë” ë° íŒŒì¼ì„ í†µí•´ ê´€ë¦¬ë˜ë¯€ë¡œ íŠ¹ì • í´ë”(ë˜ëŠ” í•´ë‹¹ íŒŒì¼)ì— ëŒ€í•œ ì“°ê¸° ì•¡ì„¸ìŠ¤ ê¶Œí•œì„ ë¶€ì—¬í•˜ë©´ ë£¨íŠ¸ê°€ ì•„ë‹Œ ì‚¬ìš©ìê°€ í•˜ìœ„ cgroup ìƒì„±ì„ í¬í•¨í•˜ì—¬ cgroupì„ êµ¬ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•˜ìœ„ cgroupì— ì‚¬ìš© ê°€ëŠ¥í•œ ì»¨íŠ¸ë¡¤ëŸ¬ ì„¸íŠ¸ë¥¼ ì¶”ê°€ë¡œ ì œí•œí•´ì•¼ í•˜ëŠ” ê²½ìš° ìƒìœ„ cgroup.subtree_control íŒŒì¼ì— ì‘ì„±í•˜ì—¬ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

Configuring a cgroup using cgroupfs
First, let's create a new cgroup by making a directory in the cgroup filesystem. This will be the group where we can set limits on CPU and memory usage for our resource-hungry process.
mkdir /sys/fs/cgroup/hog_pen
Copy to clipboard
Next, we'll set limits on CPU and memory usage. Let's say we want to limit the CPU usage to 50% and the memory usage to 100MB.
To limit CPU usage, we'll write the <cpu_quota> and <cpu_period> values to the cpu.max file:
echo "50000 100000" > /sys/fs/cgroup/hog_pen/cpu.max
Copy to clipboard
Here, 50000 is the maximum allowed CPU time per period (in microseconds), and 100000 is the period duration. This effectively limits the CPU usage to 50%.

PIDë¥¼ cgroup.procsì— ê¸°ë¡í•˜ì—¬ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¸ í”„ë¡œì„¸ìŠ¤ë¥¼ cgroupì— ì¶”ê°€í•˜ëŠ” ê²ƒì€ í¸ë¦¬í•˜ì§€ë§Œ, í”„ë¡œì„¸ìŠ¤ ì‚¬ì´ì— ì§§ì€ ê°„ê²©ë„ ë‚¨ê¸°ì§€ ì•Šê³  í”„ë¡œì„¸ìŠ¤ì˜ ë¦¬ì†ŒìŠ¤ ì†Œë¹„ë¥¼ í•­ìƒ ì œí•œí•˜ë ¤ëŠ” ê²½ìš°ì—ëŠ” ì‘ë™í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. í”„ë¡œì„¸ìŠ¤ê°€ ì‹œì‘ë˜ê³  cgroupì— ì¶”ê°€ë©ë‹ˆë‹¤.
ë‹¤í–‰íˆ í”„ë¡œì„¸ìŠ¤ê°€ ì‹œì‘ë˜ë©´ ìƒìœ„ í”„ë¡œì„¸ìŠ¤ì˜ cgroupì„ ìƒì†í•˜ë¯€ë¡œ ìƒìœ„ í”„ë¡œì„¸ìŠ¤ë¥¼ í•„ìˆ˜ cgroupìœ¼ë¡œ ì´ë™í•œ ë‹¤ìŒ ì´ë¯¸ ì œí•œëœ í•˜ìœ„ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹œì‘í•˜ë„ë¡ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

create_bridge bridge1 br1
create_end_host host1 eth1 bridge1 br1
create_end_host host2 eth2 bridge1 br1
create_end_host host3 eth3 bridge1 br1

Inspect the traffic captured by the tcpdump processes. Notice how Ethernet frames (in particular, ARP requests) that belong to one subnet are actually visible to the hosts from another subnet.
First of all, the above example proves that it's indeed possible to have multiple IP subnets over a shared L2 segment. However, it also shows that there is a lack of isolation and the traffic destined to one of the subnets is visible to the nodes from another subnet. It happens because nodes from both subnets share the same L2 broadcast domain. This may be undesirable, in particular, due to security concerns (see ARP spoofing). In such a situation, configuring multiple VLANs on the shared bridge can bring the proper isolation.

---

ìƒˆë¡œìš´ ìœ ì € ì¶”ê°€ kubernetesì˜ Rbacì„ í†µí•´ ê¶Œí•œì„

Kubernetesì˜ ì—­í•  ê¸°ë°˜ ì•¡ì„¸ìŠ¤ëŠ” Kubernetes API ë¦¬ì†ŒìŠ¤ì— ëŒ€í•´ ì‚¬ìš©ì ë˜ëŠ” ì„œë¹„ìŠ¤ ê³„ì •ì´ ìˆ˜í–‰í•˜ëŠ” ì‘ì—…ì„ í—ˆìš©í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤. RBACì—ëŠ” "ê±°ë¶€" ê·œì¹™ì´ ì—†ìœ¼ë¯€ë¡œ í•´ë‹¹ ì‚¬ìš©ì ë˜ëŠ” ì„œë¹„ìŠ¤ ê³„ì •ì— ê¼­ í•„ìš”í•œ ì‘ì—…ì„ ì„¤ì •í•˜ë„ë¡ ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤.

ì§€ì •ëœ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì˜ Kubernetes ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤(ì˜ˆ: ê°€ì ¸ì˜¤ê¸°, ë‚˜ì—´, ì‚­ì œ ë“±)ë¥¼ í• ë‹¹í•˜ê¸° ìœ„í•´ Kubernetesì—ì„œ ì—­í• ì´ ìƒì„±ë©ë‹ˆë‹¤.

RoleBindingì€ ì„œë¹„ìŠ¤ ê³„ì •ì´ë‚˜ ì‚¬ìš©ìì—ê²Œ í•´ë‹¹ ë¦¬ì†ŒìŠ¤ì˜ ê¶Œí•œì„ í• ë‹¹í•˜ê¸° ìœ„í•´ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë‚´ì— ìƒì„±ë˜ê³  ì—­í• ì— ì—°ê²°ë©ë‹ˆë‹¤.

Create a certificate signing request
Since Kubernetes doesn't have a "user" resource, all that's required is a client certificate and key with the common name (CN) to match the user's name.

In our case, when we created the RoleBinding, we assigned it to the user "carlton", so that user will assume the permissions from the Role for that resource.

As long as the CN in the key is "carlton", we will be able to use this to access the Kubernetes API.

To create a private key, we can use the openssl command-line tool. We'll use 2048 bit encryption and we'll name it carlton.key

openssl genrsa -out carlton.key 2048

Kubernetes itself is a certificate authority, therefore, it can approve and generate certificates. How convenient!

Let's create a Certificate Signing Request (CSR) for the Kubernetes API using our private key and insert the common name and output that to a file named carlton.csr with the following command

openssl req -new -key carlton.key -subj "/CN=carlton" -out carlton.csr

ğŸ›‘IMPORTANTğŸ›‘: Make sure to insert the Common Name (CN) into your CSR, or else the certificate will become invalid
Listing the contents of your current directory should look like this:

Submit CSR to Kubernetes API
Now that we have a CSR, we can submit it to the Kubernetes API for approval.

First, let's store the value of the CSR in an environment variable named "REQUEST"

export REQUEST=$(cat carlton.csr | base64 -w 0)

Then, we can create a YAML manifest and sumbit it to the Kubernetes API. Insert the $REQUEST variable next to "request: " like so

cat <<EOF | kubectl apply -f -
apiVersion: certificates.k8s.io/v1
kind: CertificateSigningRequest
metadata:
name: carlton
spec:
groups:

- system:authenticated
  request: $REQUEST
  signerName: kubernetes.io/kube-apiserver-client
  usages:
- client auth
  EOF
  The output of the command k get csr should result in the following:

$ k get csr

Let's assume the role that we set for our new user and test access to Kubernetes!

In order to get our client certificate that we can use in our kubeconfig, we'll approve the CSR we submitted to the Kubernetes API

k certificate approve carlton

The output of the command k get csr should now have the condition "Approved,Issued":

$ k get csr
NAME AGE SIGNERNAME REQUESTOR REQUESTEDDURATION CONDITION
csr-hs6d2 16d kubernetes.io/kube-apiserver-client-kubelet system:node:controlplane <none> Approved,Issued
carlton 6m48s kubernetes.io/kube-apiserver-client kubernetes-admin <none> Approved,Issued
We can extract the client certificate out from the "k get csr" command, decode it and save it to a file named carlton.crt

k get csr carlton -o jsonpath='{.status.certificate}' | base64 -d > carlton.crt

Now that we have the key and certificate, we can set the credentials in our kubeconfig and embed the certs within

k config set-credentials carlton --client-key=carlton.key --client-certificate=carlton.crt --embed-certs

ğŸ”¥TIPğŸ”¥: You can remove the --embed-certs and they will remain pointers to the key and certificate files. Try it out!
The output of k config view will now show carlton as one of the users

Next, we'll set and use the context in which kubectl uses to access the Kubernetes API

k config set-context carlton --user=carlton --cluster=kubernetes

k config use-context carlton

Finally, we can test if our carlton user can get pods in the web namespace

k -n web get po
